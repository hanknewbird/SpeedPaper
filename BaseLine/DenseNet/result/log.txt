C:\Users\yts32\.conda\envs\pytorch_1.4_gpu\python.exe F:/cv_paper/lesson/I_DenseNet/src/train_densenet.py
Training: Epoch[001/300] Iteration[050/782] Loss: 2.0904 Acc:21.78%
Training: Epoch[001/300] Iteration[100/782] Loss: 1.9872 Acc:24.42%
Training: Epoch[001/300] Iteration[150/782] Loss: 1.9087 Acc:27.53%
Training: Epoch[001/300] Iteration[200/782] Loss: 1.8569 Acc:29.62%
Training: Epoch[001/300] Iteration[250/782] Loss: 1.8084 Acc:31.40%
Training: Epoch[001/300] Iteration[300/782] Loss: 1.7645 Acc:33.22%
Training: Epoch[001/300] Iteration[350/782] Loss: 1.7244 Acc:34.77%
Training: Epoch[001/300] Iteration[400/782] Loss: 1.6886 Acc:36.39%
Training: Epoch[001/300] Iteration[450/782] Loss: 1.6523 Acc:37.91%
Training: Epoch[001/300] Iteration[500/782] Loss: 1.6191 Acc:39.25%
Training: Epoch[001/300] Iteration[550/782] Loss: 1.5911 Acc:40.46%
Training: Epoch[001/300] Iteration[600/782] Loss: 1.5621 Acc:41.66%
Training: Epoch[001/300] Iteration[650/782] Loss: 1.5355 Acc:42.74%
Training: Epoch[001/300] Iteration[700/782] Loss: 1.5093 Acc:43.81%
Training: Epoch[001/300] Iteration[750/782] Loss: 1.4853 Acc:44.86%
Epoch[001/300] Train Acc: 45.40% Valid Acc:57.27% Train loss:1.4706 Valid loss:1.2430 LR:0.1
Training: Epoch[002/300] Iteration[050/782] Loss: 1.1200 Acc:59.50%
Training: Epoch[002/300] Iteration[100/782] Loss: 1.0952 Acc:60.69%
Training: Epoch[002/300] Iteration[150/782] Loss: 1.0871 Acc:61.07%
Training: Epoch[002/300] Iteration[200/782] Loss: 1.0800 Acc:61.49%
Training: Epoch[002/300] Iteration[250/782] Loss: 1.0764 Acc:61.74%
Training: Epoch[002/300] Iteration[300/782] Loss: 1.0696 Acc:61.89%
Training: Epoch[002/300] Iteration[350/782] Loss: 1.0579 Acc:62.30%
Training: Epoch[002/300] Iteration[400/782] Loss: 1.0497 Acc:62.55%
Training: Epoch[002/300] Iteration[450/782] Loss: 1.0398 Acc:62.78%
Training: Epoch[002/300] Iteration[500/782] Loss: 1.0344 Acc:62.88%
Training: Epoch[002/300] Iteration[550/782] Loss: 1.0268 Acc:63.18%
Training: Epoch[002/300] Iteration[600/782] Loss: 1.0189 Acc:63.38%
Training: Epoch[002/300] Iteration[650/782] Loss: 1.0099 Acc:63.69%
Training: Epoch[002/300] Iteration[700/782] Loss: 1.0046 Acc:63.89%
Training: Epoch[002/300] Iteration[750/782] Loss: 1.0002 Acc:64.05%
Epoch[002/300] Train Acc: 64.29% Valid Acc:64.39% Train loss:0.9943 Valid loss:1.0905 LR:0.1
Training: Epoch[003/300] Iteration[050/782] Loss: 0.9078 Acc:69.00%
Training: Epoch[003/300] Iteration[100/782] Loss: 0.9072 Acc:68.56%
Training: Epoch[003/300] Iteration[150/782] Loss: 0.9044 Acc:68.80%
Training: Epoch[003/300] Iteration[200/782] Loss: 0.8813 Acc:69.26%
Training: Epoch[003/300] Iteration[250/782] Loss: 0.8766 Acc:69.16%
Training: Epoch[003/300] Iteration[300/782] Loss: 0.8700 Acc:69.20%
Training: Epoch[003/300] Iteration[350/782] Loss: 0.8665 Acc:69.32%
Training: Epoch[003/300] Iteration[400/782] Loss: 0.8669 Acc:69.31%
Training: Epoch[003/300] Iteration[450/782] Loss: 0.8631 Acc:69.42%
Training: Epoch[003/300] Iteration[500/782] Loss: 0.8585 Acc:69.52%
Training: Epoch[003/300] Iteration[550/782] Loss: 0.8522 Acc:69.80%
Training: Epoch[003/300] Iteration[600/782] Loss: 0.8483 Acc:69.91%
Training: Epoch[003/300] Iteration[650/782] Loss: 0.8463 Acc:70.04%
Training: Epoch[003/300] Iteration[700/782] Loss: 0.8428 Acc:70.19%
Training: Epoch[003/300] Iteration[750/782] Loss: 0.8381 Acc:70.38%
Epoch[003/300] Train Acc: 70.48% Valid Acc:66.32% Train loss:0.8356 Valid loss:0.9875 LR:0.1
Training: Epoch[004/300] Iteration[050/782] Loss: 0.7683 Acc:73.75%
Training: Epoch[004/300] Iteration[100/782] Loss: 0.7728 Acc:73.22%
Training: Epoch[004/300] Iteration[150/782] Loss: 0.7670 Acc:73.16%
Training: Epoch[004/300] Iteration[200/782] Loss: 0.7586 Acc:73.80%
Training: Epoch[004/300] Iteration[250/782] Loss: 0.7479 Acc:74.16%
Training: Epoch[004/300] Iteration[300/782] Loss: 0.7457 Acc:74.11%
Training: Epoch[004/300] Iteration[350/782] Loss: 0.7483 Acc:74.06%
Training: Epoch[004/300] Iteration[400/782] Loss: 0.7441 Acc:74.24%
Training: Epoch[004/300] Iteration[450/782] Loss: 0.7416 Acc:74.35%
Training: Epoch[004/300] Iteration[500/782] Loss: 0.7374 Acc:74.46%
Training: Epoch[004/300] Iteration[550/782] Loss: 0.7376 Acc:74.45%
Training: Epoch[004/300] Iteration[600/782] Loss: 0.7353 Acc:74.49%
Training: Epoch[004/300] Iteration[650/782] Loss: 0.7283 Acc:74.69%
Training: Epoch[004/300] Iteration[700/782] Loss: 0.7267 Acc:74.80%
Training: Epoch[004/300] Iteration[750/782] Loss: 0.7253 Acc:74.83%
Epoch[004/300] Train Acc: 74.90% Valid Acc:72.00% Train loss:0.7225 Valid loss:0.8440 LR:0.1
Training: Epoch[005/300] Iteration[050/782] Loss: 0.6498 Acc:77.69%
Training: Epoch[005/300] Iteration[100/782] Loss: 0.6628 Acc:77.19%
Training: Epoch[005/300] Iteration[150/782] Loss: 0.6551 Acc:77.31%
Training: Epoch[005/300] Iteration[200/782] Loss: 0.6502 Acc:77.59%
Training: Epoch[005/300] Iteration[250/782] Loss: 0.6506 Acc:77.60%
Training: Epoch[005/300] Iteration[300/782] Loss: 0.6514 Acc:77.59%
Training: Epoch[005/300] Iteration[350/782] Loss: 0.6527 Acc:77.50%
Training: Epoch[005/300] Iteration[400/782] Loss: 0.6525 Acc:77.46%
Training: Epoch[005/300] Iteration[450/782] Loss: 0.6520 Acc:77.42%
Training: Epoch[005/300] Iteration[500/782] Loss: 0.6509 Acc:77.46%
Training: Epoch[005/300] Iteration[550/782] Loss: 0.6513 Acc:77.43%
Training: Epoch[005/300] Iteration[600/782] Loss: 0.6515 Acc:77.43%
Training: Epoch[005/300] Iteration[650/782] Loss: 0.6512 Acc:77.42%
Training: Epoch[005/300] Iteration[700/782] Loss: 0.6507 Acc:77.43%
Training: Epoch[005/300] Iteration[750/782] Loss: 0.6505 Acc:77.45%
Epoch[005/300] Train Acc: 77.46% Valid Acc:78.00% Train loss:0.6507 Valid loss:0.6445 LR:0.1
Training: Epoch[006/300] Iteration[050/782] Loss: 0.6110 Acc:78.41%
Training: Epoch[006/300] Iteration[100/782] Loss: 0.6086 Acc:78.69%
Training: Epoch[006/300] Iteration[150/782] Loss: 0.6100 Acc:78.77%
Training: Epoch[006/300] Iteration[200/782] Loss: 0.6096 Acc:78.82%
Training: Epoch[006/300] Iteration[250/782] Loss: 0.6097 Acc:78.89%
Training: Epoch[006/300] Iteration[300/782] Loss: 0.6119 Acc:78.79%
Training: Epoch[006/300] Iteration[350/782] Loss: 0.6101 Acc:78.93%
Training: Epoch[006/300] Iteration[400/782] Loss: 0.6129 Acc:78.83%
Training: Epoch[006/300] Iteration[450/782] Loss: 0.6089 Acc:78.93%
Training: Epoch[006/300] Iteration[500/782] Loss: 0.6087 Acc:78.93%
Training: Epoch[006/300] Iteration[550/782] Loss: 0.6091 Acc:78.93%
Training: Epoch[006/300] Iteration[600/782] Loss: 0.6077 Acc:78.96%
Training: Epoch[006/300] Iteration[650/782] Loss: 0.6073 Acc:79.00%
Training: Epoch[006/300] Iteration[700/782] Loss: 0.6054 Acc:79.11%
Training: Epoch[006/300] Iteration[750/782] Loss: 0.6043 Acc:79.14%
Epoch[006/300] Train Acc: 79.18% Valid Acc:79.77% Train loss:0.6033 Valid loss:0.5827 LR:0.1
Training: Epoch[007/300] Iteration[050/782] Loss: 0.5502 Acc:80.38%
Training: Epoch[007/300] Iteration[100/782] Loss: 0.5344 Acc:80.89%
Training: Epoch[007/300] Iteration[150/782] Loss: 0.5520 Acc:80.27%
Training: Epoch[007/300] Iteration[200/782] Loss: 0.5518 Acc:80.55%
Training: Epoch[007/300] Iteration[250/782] Loss: 0.5569 Acc:80.40%
Training: Epoch[007/300] Iteration[300/782] Loss: 0.5614 Acc:80.23%
Training: Epoch[007/300] Iteration[350/782] Loss: 0.5620 Acc:80.20%
Training: Epoch[007/300] Iteration[400/782] Loss: 0.5592 Acc:80.35%
Training: Epoch[007/300] Iteration[450/782] Loss: 0.5631 Acc:80.33%
Training: Epoch[007/300] Iteration[500/782] Loss: 0.5637 Acc:80.39%
Training: Epoch[007/300] Iteration[550/782] Loss: 0.5669 Acc:80.24%
Training: Epoch[007/300] Iteration[600/782] Loss: 0.5672 Acc:80.22%
Training: Epoch[007/300] Iteration[650/782] Loss: 0.5658 Acc:80.27%
Training: Epoch[007/300] Iteration[700/782] Loss: 0.5669 Acc:80.29%
Training: Epoch[007/300] Iteration[750/782] Loss: 0.5657 Acc:80.37%
Epoch[007/300] Train Acc: 80.39% Valid Acc:79.02% Train loss:0.5665 Valid loss:0.6377 LR:0.1
Training: Epoch[008/300] Iteration[050/782] Loss: 0.5301 Acc:82.12%
Training: Epoch[008/300] Iteration[100/782] Loss: 0.5347 Acc:81.34%
Training: Epoch[008/300] Iteration[150/782] Loss: 0.5370 Acc:81.17%
Training: Epoch[008/300] Iteration[200/782] Loss: 0.5400 Acc:81.11%
Training: Epoch[008/300] Iteration[250/782] Loss: 0.5399 Acc:81.22%
Training: Epoch[008/300] Iteration[300/782] Loss: 0.5421 Acc:81.15%
Training: Epoch[008/300] Iteration[350/782] Loss: 0.5406 Acc:81.17%
Training: Epoch[008/300] Iteration[400/782] Loss: 0.5409 Acc:81.16%
Training: Epoch[008/300] Iteration[450/782] Loss: 0.5387 Acc:81.27%
Training: Epoch[008/300] Iteration[500/782] Loss: 0.5388 Acc:81.24%
Training: Epoch[008/300] Iteration[550/782] Loss: 0.5393 Acc:81.21%
Training: Epoch[008/300] Iteration[600/782] Loss: 0.5411 Acc:81.15%
Training: Epoch[008/300] Iteration[650/782] Loss: 0.5445 Acc:81.11%
Training: Epoch[008/300] Iteration[700/782] Loss: 0.5442 Acc:81.16%
Training: Epoch[008/300] Iteration[750/782] Loss: 0.5410 Acc:81.28%
Epoch[008/300] Train Acc: 81.30% Valid Acc:78.27% Train loss:0.5405 Valid loss:0.6249 LR:0.1
Training: Epoch[009/300] Iteration[050/782] Loss: 0.5231 Acc:81.59%
Training: Epoch[009/300] Iteration[100/782] Loss: 0.5221 Acc:81.92%
Training: Epoch[009/300] Iteration[150/782] Loss: 0.5297 Acc:82.00%
Training: Epoch[009/300] Iteration[200/782] Loss: 0.5266 Acc:82.03%
Training: Epoch[009/300] Iteration[250/782] Loss: 0.5237 Acc:82.05%
Training: Epoch[009/300] Iteration[300/782] Loss: 0.5246 Acc:82.02%
Training: Epoch[009/300] Iteration[350/782] Loss: 0.5231 Acc:82.13%
Training: Epoch[009/300] Iteration[400/782] Loss: 0.5247 Acc:82.05%
Training: Epoch[009/300] Iteration[450/782] Loss: 0.5252 Acc:82.08%
Training: Epoch[009/300] Iteration[500/782] Loss: 0.5252 Acc:82.09%
Training: Epoch[009/300] Iteration[550/782] Loss: 0.5262 Acc:82.08%
Training: Epoch[009/300] Iteration[600/782] Loss: 0.5258 Acc:82.06%
Training: Epoch[009/300] Iteration[650/782] Loss: 0.5241 Acc:82.12%
Training: Epoch[009/300] Iteration[700/782] Loss: 0.5243 Acc:82.09%
Training: Epoch[009/300] Iteration[750/782] Loss: 0.5232 Acc:82.09%
Epoch[009/300] Train Acc: 82.08% Valid Acc:76.03% Train loss:0.5247 Valid loss:0.7074 LR:0.1
Training: Epoch[010/300] Iteration[050/782] Loss: 0.5205 Acc:82.28%
Training: Epoch[010/300] Iteration[100/782] Loss: 0.5075 Acc:82.84%
Training: Epoch[010/300] Iteration[150/782] Loss: 0.4953 Acc:83.07%
Training: Epoch[010/300] Iteration[200/782] Loss: 0.5045 Acc:82.82%
Training: Epoch[010/300] Iteration[250/782] Loss: 0.4957 Acc:83.06%
Training: Epoch[010/300] Iteration[300/782] Loss: 0.5015 Acc:82.72%
Training: Epoch[010/300] Iteration[350/782] Loss: 0.5011 Acc:82.83%
Training: Epoch[010/300] Iteration[400/782] Loss: 0.5000 Acc:82.80%
Training: Epoch[010/300] Iteration[450/782] Loss: 0.4984 Acc:82.84%
Training: Epoch[010/300] Iteration[500/782] Loss: 0.5002 Acc:82.78%
Training: Epoch[010/300] Iteration[550/782] Loss: 0.5003 Acc:82.75%
Training: Epoch[010/300] Iteration[600/782] Loss: 0.4997 Acc:82.80%
Training: Epoch[010/300] Iteration[650/782] Loss: 0.5000 Acc:82.80%
Training: Epoch[010/300] Iteration[700/782] Loss: 0.5020 Acc:82.71%
Training: Epoch[010/300] Iteration[750/782] Loss: 0.5031 Acc:82.70%
Epoch[010/300] Train Acc: 82.72% Valid Acc:82.20% Train loss:0.5037 Valid loss:0.5381 LR:0.1
Training: Epoch[011/300] Iteration[050/782] Loss: 0.4716 Acc:84.19%
Training: Epoch[011/300] Iteration[100/782] Loss: 0.4758 Acc:83.84%
Training: Epoch[011/300] Iteration[150/782] Loss: 0.4817 Acc:83.68%
Training: Epoch[011/300] Iteration[200/782] Loss: 0.4835 Acc:83.68%
Training: Epoch[011/300] Iteration[250/782] Loss: 0.4836 Acc:83.44%
Training: Epoch[011/300] Iteration[300/782] Loss: 0.4799 Acc:83.53%
Training: Epoch[011/300] Iteration[350/782] Loss: 0.4770 Acc:83.57%
Training: Epoch[011/300] Iteration[400/782] Loss: 0.4784 Acc:83.58%
Training: Epoch[011/300] Iteration[450/782] Loss: 0.4805 Acc:83.55%
Training: Epoch[011/300] Iteration[500/782] Loss: 0.4822 Acc:83.47%
Training: Epoch[011/300] Iteration[550/782] Loss: 0.4857 Acc:83.36%
Training: Epoch[011/300] Iteration[600/782] Loss: 0.4845 Acc:83.45%
Training: Epoch[011/300] Iteration[650/782] Loss: 0.4852 Acc:83.44%
Training: Epoch[011/300] Iteration[700/782] Loss: 0.4834 Acc:83.45%
Training: Epoch[011/300] Iteration[750/782] Loss: 0.4847 Acc:83.39%
Epoch[011/300] Train Acc: 83.39% Valid Acc:80.21% Train loss:0.4842 Valid loss:0.5944 LR:0.1
Training: Epoch[012/300] Iteration[050/782] Loss: 0.4966 Acc:83.00%
Training: Epoch[012/300] Iteration[100/782] Loss: 0.4732 Acc:83.66%
Training: Epoch[012/300] Iteration[150/782] Loss: 0.4862 Acc:83.14%
Training: Epoch[012/300] Iteration[200/782] Loss: 0.4858 Acc:83.29%
Training: Epoch[012/300] Iteration[250/782] Loss: 0.4904 Acc:83.19%
Training: Epoch[012/300] Iteration[300/782] Loss: 0.4842 Acc:83.28%
Training: Epoch[012/300] Iteration[350/782] Loss: 0.4810 Acc:83.27%
Training: Epoch[012/300] Iteration[400/782] Loss: 0.4777 Acc:83.40%
Training: Epoch[012/300] Iteration[450/782] Loss: 0.4775 Acc:83.43%
Training: Epoch[012/300] Iteration[500/782] Loss: 0.4798 Acc:83.41%
Training: Epoch[012/300] Iteration[550/782] Loss: 0.4814 Acc:83.37%
Training: Epoch[012/300] Iteration[600/782] Loss: 0.4800 Acc:83.47%
Training: Epoch[012/300] Iteration[650/782] Loss: 0.4804 Acc:83.48%
Training: Epoch[012/300] Iteration[700/782] Loss: 0.4782 Acc:83.56%
Training: Epoch[012/300] Iteration[750/782] Loss: 0.4763 Acc:83.64%
Epoch[012/300] Train Acc: 83.61% Valid Acc:82.48% Train loss:0.4775 Valid loss:0.5228 LR:0.1
Training: Epoch[013/300] Iteration[050/782] Loss: 0.4767 Acc:83.12%
Training: Epoch[013/300] Iteration[100/782] Loss: 0.4554 Acc:84.17%
Training: Epoch[013/300] Iteration[150/782] Loss: 0.4578 Acc:84.31%
Training: Epoch[013/300] Iteration[200/782] Loss: 0.4567 Acc:84.41%
Training: Epoch[013/300] Iteration[250/782] Loss: 0.4621 Acc:84.23%
Training: Epoch[013/300] Iteration[300/782] Loss: 0.4590 Acc:84.35%
Training: Epoch[013/300] Iteration[350/782] Loss: 0.4575 Acc:84.41%
Training: Epoch[013/300] Iteration[400/782] Loss: 0.4549 Acc:84.41%
Training: Epoch[013/300] Iteration[450/782] Loss: 0.4589 Acc:84.30%
Training: Epoch[013/300] Iteration[500/782] Loss: 0.4593 Acc:84.24%
Training: Epoch[013/300] Iteration[550/782] Loss: 0.4597 Acc:84.22%
Training: Epoch[013/300] Iteration[600/782] Loss: 0.4585 Acc:84.27%
Training: Epoch[013/300] Iteration[650/782] Loss: 0.4592 Acc:84.30%
Training: Epoch[013/300] Iteration[700/782] Loss: 0.4607 Acc:84.25%
Training: Epoch[013/300] Iteration[750/782] Loss: 0.4592 Acc:84.30%
Epoch[013/300] Train Acc: 84.34% Valid Acc:81.89% Train loss:0.4584 Valid loss:0.5543 LR:0.1
Training: Epoch[014/300] Iteration[050/782] Loss: 0.4405 Acc:85.19%
Training: Epoch[014/300] Iteration[100/782] Loss: 0.4491 Acc:84.52%
Training: Epoch[014/300] Iteration[150/782] Loss: 0.4374 Acc:84.89%
Training: Epoch[014/300] Iteration[200/782] Loss: 0.4340 Acc:85.10%
Training: Epoch[014/300] Iteration[250/782] Loss: 0.4392 Acc:84.96%
Training: Epoch[014/300] Iteration[300/782] Loss: 0.4424 Acc:84.88%
Training: Epoch[014/300] Iteration[350/782] Loss: 0.4453 Acc:84.75%
Training: Epoch[014/300] Iteration[400/782] Loss: 0.4440 Acc:84.73%
Training: Epoch[014/300] Iteration[450/782] Loss: 0.4454 Acc:84.68%
Training: Epoch[014/300] Iteration[500/782] Loss: 0.4484 Acc:84.53%
Training: Epoch[014/300] Iteration[550/782] Loss: 0.4477 Acc:84.58%
Training: Epoch[014/300] Iteration[600/782] Loss: 0.4498 Acc:84.51%
Training: Epoch[014/300] Iteration[650/782] Loss: 0.4506 Acc:84.45%
Training: Epoch[014/300] Iteration[700/782] Loss: 0.4508 Acc:84.44%
Training: Epoch[014/300] Iteration[750/782] Loss: 0.4516 Acc:84.45%
Epoch[014/300] Train Acc: 84.46% Valid Acc:81.55% Train loss:0.4526 Valid loss:0.5441 LR:0.1
Training: Epoch[015/300] Iteration[050/782] Loss: 0.4019 Acc:86.16%
Training: Epoch[015/300] Iteration[100/782] Loss: 0.3997 Acc:86.06%
Training: Epoch[015/300] Iteration[150/782] Loss: 0.4150 Acc:85.40%
Training: Epoch[015/300] Iteration[200/782] Loss: 0.4272 Acc:84.98%
Training: Epoch[015/300] Iteration[250/782] Loss: 0.4300 Acc:84.87%
Training: Epoch[015/300] Iteration[300/782] Loss: 0.4313 Acc:84.93%
Training: Epoch[015/300] Iteration[350/782] Loss: 0.4326 Acc:84.83%
Training: Epoch[015/300] Iteration[400/782] Loss: 0.4334 Acc:84.92%
Training: Epoch[015/300] Iteration[450/782] Loss: 0.4356 Acc:84.80%
Training: Epoch[015/300] Iteration[500/782] Loss: 0.4352 Acc:84.84%
Training: Epoch[015/300] Iteration[550/782] Loss: 0.4392 Acc:84.69%
Training: Epoch[015/300] Iteration[600/782] Loss: 0.4385 Acc:84.71%
Training: Epoch[015/300] Iteration[650/782] Loss: 0.4407 Acc:84.67%
Training: Epoch[015/300] Iteration[700/782] Loss: 0.4422 Acc:84.63%
Training: Epoch[015/300] Iteration[750/782] Loss: 0.4408 Acc:84.72%
Epoch[015/300] Train Acc: 84.67% Valid Acc:78.32% Train loss:0.4417 Valid loss:0.7255 LR:0.1
Training: Epoch[016/300] Iteration[050/782] Loss: 0.4325 Acc:85.22%
Training: Epoch[016/300] Iteration[100/782] Loss: 0.4199 Acc:85.69%
Training: Epoch[016/300] Iteration[150/782] Loss: 0.4246 Acc:85.20%
Training: Epoch[016/300] Iteration[200/782] Loss: 0.4316 Acc:84.85%
Training: Epoch[016/300] Iteration[250/782] Loss: 0.4320 Acc:84.84%
Training: Epoch[016/300] Iteration[300/782] Loss: 0.4389 Acc:84.73%
Training: Epoch[016/300] Iteration[350/782] Loss: 0.4373 Acc:84.72%
Training: Epoch[016/300] Iteration[400/782] Loss: 0.4408 Acc:84.63%
Training: Epoch[016/300] Iteration[450/782] Loss: 0.4402 Acc:84.64%
Training: Epoch[016/300] Iteration[500/782] Loss: 0.4414 Acc:84.61%
Training: Epoch[016/300] Iteration[550/782] Loss: 0.4423 Acc:84.64%
Training: Epoch[016/300] Iteration[600/782] Loss: 0.4407 Acc:84.72%
Training: Epoch[016/300] Iteration[650/782] Loss: 0.4390 Acc:84.81%
Training: Epoch[016/300] Iteration[700/782] Loss: 0.4402 Acc:84.77%
Training: Epoch[016/300] Iteration[750/782] Loss: 0.4400 Acc:84.80%
Epoch[016/300] Train Acc: 84.79% Valid Acc:78.15% Train loss:0.4403 Valid loss:0.6599 LR:0.1
Training: Epoch[017/300] Iteration[050/782] Loss: 0.3869 Acc:87.06%
Training: Epoch[017/300] Iteration[100/782] Loss: 0.4051 Acc:86.39%
Training: Epoch[017/300] Iteration[150/782] Loss: 0.4151 Acc:85.90%
Training: Epoch[017/300] Iteration[200/782] Loss: 0.4271 Acc:85.51%
Training: Epoch[017/300] Iteration[250/782] Loss: 0.4251 Acc:85.48%
Training: Epoch[017/300] Iteration[300/782] Loss: 0.4248 Acc:85.55%
Training: Epoch[017/300] Iteration[350/782] Loss: 0.4228 Acc:85.66%
Training: Epoch[017/300] Iteration[400/782] Loss: 0.4247 Acc:85.59%
Training: Epoch[017/300] Iteration[450/782] Loss: 0.4265 Acc:85.51%
Training: Epoch[017/300] Iteration[500/782] Loss: 0.4220 Acc:85.57%
Training: Epoch[017/300] Iteration[550/782] Loss: 0.4209 Acc:85.60%
Training: Epoch[017/300] Iteration[600/782] Loss: 0.4221 Acc:85.55%
Training: Epoch[017/300] Iteration[650/782] Loss: 0.4214 Acc:85.61%
Training: Epoch[017/300] Iteration[700/782] Loss: 0.4231 Acc:85.53%
Training: Epoch[017/300] Iteration[750/782] Loss: 0.4231 Acc:85.51%
Epoch[017/300] Train Acc: 85.54% Valid Acc:80.87% Train loss:0.4227 Valid loss:0.5836 LR:0.1
Training: Epoch[018/300] Iteration[050/782] Loss: 0.4441 Acc:85.41%
Training: Epoch[018/300] Iteration[100/782] Loss: 0.4203 Acc:85.69%
Training: Epoch[018/300] Iteration[150/782] Loss: 0.4229 Acc:85.57%
Training: Epoch[018/300] Iteration[200/782] Loss: 0.4177 Acc:85.75%
Training: Epoch[018/300] Iteration[250/782] Loss: 0.4186 Acc:85.66%
Training: Epoch[018/300] Iteration[300/782] Loss: 0.4167 Acc:85.78%
Training: Epoch[018/300] Iteration[350/782] Loss: 0.4151 Acc:85.88%
Training: Epoch[018/300] Iteration[400/782] Loss: 0.4174 Acc:85.78%
Training: Epoch[018/300] Iteration[450/782] Loss: 0.4187 Acc:85.64%
Training: Epoch[018/300] Iteration[500/782] Loss: 0.4191 Acc:85.60%
Training: Epoch[018/300] Iteration[550/782] Loss: 0.4191 Acc:85.66%
Training: Epoch[018/300] Iteration[600/782] Loss: 0.4201 Acc:85.61%
Training: Epoch[018/300] Iteration[650/782] Loss: 0.4199 Acc:85.61%
Training: Epoch[018/300] Iteration[700/782] Loss: 0.4178 Acc:85.62%
Training: Epoch[018/300] Iteration[750/782] Loss: 0.4188 Acc:85.58%
Epoch[018/300] Train Acc: 85.59% Valid Acc:78.40% Train loss:0.4191 Valid loss:0.6545 LR:0.1
Training: Epoch[019/300] Iteration[050/782] Loss: 0.4459 Acc:84.88%
Training: Epoch[019/300] Iteration[100/782] Loss: 0.4217 Acc:85.66%
Training: Epoch[019/300] Iteration[150/782] Loss: 0.4108 Acc:85.95%
Training: Epoch[019/300] Iteration[200/782] Loss: 0.4071 Acc:85.95%
Training: Epoch[019/300] Iteration[250/782] Loss: 0.4094 Acc:85.88%
Training: Epoch[019/300] Iteration[300/782] Loss: 0.4102 Acc:85.91%
Training: Epoch[019/300] Iteration[350/782] Loss: 0.4087 Acc:85.90%
Training: Epoch[019/300] Iteration[400/782] Loss: 0.4106 Acc:85.80%
Training: Epoch[019/300] Iteration[450/782] Loss: 0.4113 Acc:85.76%
Training: Epoch[019/300] Iteration[500/782] Loss: 0.4123 Acc:85.67%
Training: Epoch[019/300] Iteration[550/782] Loss: 0.4107 Acc:85.79%
Training: Epoch[019/300] Iteration[600/782] Loss: 0.4112 Acc:85.81%
Training: Epoch[019/300] Iteration[650/782] Loss: 0.4112 Acc:85.78%
Training: Epoch[019/300] Iteration[700/782] Loss: 0.4120 Acc:85.76%
Training: Epoch[019/300] Iteration[750/782] Loss: 0.4106 Acc:85.81%
Epoch[019/300] Train Acc: 85.82% Valid Acc:83.17% Train loss:0.4110 Valid loss:0.5135 LR:0.1
Training: Epoch[020/300] Iteration[050/782] Loss: 0.4122 Acc:85.69%
Training: Epoch[020/300] Iteration[100/782] Loss: 0.4041 Acc:86.11%
Training: Epoch[020/300] Iteration[150/782] Loss: 0.4021 Acc:86.11%
Training: Epoch[020/300] Iteration[200/782] Loss: 0.4041 Acc:86.13%
Training: Epoch[020/300] Iteration[250/782] Loss: 0.4056 Acc:86.03%
Training: Epoch[020/300] Iteration[300/782] Loss: 0.4071 Acc:85.90%
Training: Epoch[020/300] Iteration[350/782] Loss: 0.4054 Acc:86.02%
Training: Epoch[020/300] Iteration[400/782] Loss: 0.4072 Acc:85.90%
Training: Epoch[020/300] Iteration[450/782] Loss: 0.4081 Acc:85.87%
Training: Epoch[020/300] Iteration[500/782] Loss: 0.4075 Acc:85.93%
Training: Epoch[020/300] Iteration[550/782] Loss: 0.4071 Acc:85.94%
Training: Epoch[020/300] Iteration[600/782] Loss: 0.4093 Acc:85.87%
Training: Epoch[020/300] Iteration[650/782] Loss: 0.4074 Acc:85.95%
Training: Epoch[020/300] Iteration[700/782] Loss: 0.4077 Acc:85.94%
Training: Epoch[020/300] Iteration[750/782] Loss: 0.4107 Acc:85.85%
Epoch[020/300] Train Acc: 85.88% Valid Acc:81.95% Train loss:0.4096 Valid loss:0.5503 LR:0.1
Training: Epoch[021/300] Iteration[050/782] Loss: 0.3811 Acc:86.59%
Training: Epoch[021/300] Iteration[100/782] Loss: 0.3845 Acc:86.92%
Training: Epoch[021/300] Iteration[150/782] Loss: 0.3866 Acc:86.54%
Training: Epoch[021/300] Iteration[200/782] Loss: 0.3954 Acc:86.31%
Training: Epoch[021/300] Iteration[250/782] Loss: 0.3947 Acc:86.29%
Training: Epoch[021/300] Iteration[300/782] Loss: 0.3971 Acc:86.18%
Training: Epoch[021/300] Iteration[350/782] Loss: 0.3929 Acc:86.38%
Training: Epoch[021/300] Iteration[400/782] Loss: 0.3978 Acc:86.22%
Training: Epoch[021/300] Iteration[450/782] Loss: 0.4001 Acc:86.20%
Training: Epoch[021/300] Iteration[500/782] Loss: 0.3995 Acc:86.23%
Training: Epoch[021/300] Iteration[550/782] Loss: 0.3992 Acc:86.26%
Training: Epoch[021/300] Iteration[600/782] Loss: 0.4029 Acc:86.16%
Training: Epoch[021/300] Iteration[650/782] Loss: 0.4038 Acc:86.15%
Training: Epoch[021/300] Iteration[700/782] Loss: 0.4045 Acc:86.08%
Training: Epoch[021/300] Iteration[750/782] Loss: 0.4052 Acc:86.04%
Epoch[021/300] Train Acc: 86.01% Valid Acc:83.51% Train loss:0.4062 Valid loss:0.4973 LR:0.1
Training: Epoch[022/300] Iteration[050/782] Loss: 0.4098 Acc:86.19%
Training: Epoch[022/300] Iteration[100/782] Loss: 0.3897 Acc:86.86%
Training: Epoch[022/300] Iteration[150/782] Loss: 0.3819 Acc:87.05%
Training: Epoch[022/300] Iteration[200/782] Loss: 0.3815 Acc:86.83%
Training: Epoch[022/300] Iteration[250/782] Loss: 0.3808 Acc:86.83%
Training: Epoch[022/300] Iteration[300/782] Loss: 0.3834 Acc:86.92%
Training: Epoch[022/300] Iteration[350/782] Loss: 0.3862 Acc:86.88%
Training: Epoch[022/300] Iteration[400/782] Loss: 0.3848 Acc:86.85%
Training: Epoch[022/300] Iteration[450/782] Loss: 0.3864 Acc:86.75%
Training: Epoch[022/300] Iteration[500/782] Loss: 0.3908 Acc:86.62%
Training: Epoch[022/300] Iteration[550/782] Loss: 0.3953 Acc:86.43%
Training: Epoch[022/300] Iteration[600/782] Loss: 0.3971 Acc:86.41%
Training: Epoch[022/300] Iteration[650/782] Loss: 0.3978 Acc:86.34%
Training: Epoch[022/300] Iteration[700/782] Loss: 0.3973 Acc:86.35%
Training: Epoch[022/300] Iteration[750/782] Loss: 0.3967 Acc:86.35%
Epoch[022/300] Train Acc: 86.32% Valid Acc:84.47% Train loss:0.3966 Valid loss:0.4648 LR:0.1
Training: Epoch[023/300] Iteration[050/782] Loss: 0.3879 Acc:86.78%
Training: Epoch[023/300] Iteration[100/782] Loss: 0.3856 Acc:86.78%
Training: Epoch[023/300] Iteration[150/782] Loss: 0.3838 Acc:86.69%
Training: Epoch[023/300] Iteration[200/782] Loss: 0.3799 Acc:86.98%
Training: Epoch[023/300] Iteration[250/782] Loss: 0.3840 Acc:86.68%
Training: Epoch[023/300] Iteration[300/782] Loss: 0.3859 Acc:86.67%
Training: Epoch[023/300] Iteration[350/782] Loss: 0.3861 Acc:86.59%
Training: Epoch[023/300] Iteration[400/782] Loss: 0.3919 Acc:86.39%
Training: Epoch[023/300] Iteration[450/782] Loss: 0.3946 Acc:86.25%
Training: Epoch[023/300] Iteration[500/782] Loss: 0.3961 Acc:86.27%
Training: Epoch[023/300] Iteration[550/782] Loss: 0.3962 Acc:86.30%
Training: Epoch[023/300] Iteration[600/782] Loss: 0.3958 Acc:86.30%
Training: Epoch[023/300] Iteration[650/782] Loss: 0.3950 Acc:86.31%
Training: Epoch[023/300] Iteration[700/782] Loss: 0.3944 Acc:86.31%
Training: Epoch[023/300] Iteration[750/782] Loss: 0.3983 Acc:86.16%
Epoch[023/300] Train Acc: 86.17% Valid Acc:80.69% Train loss:0.3986 Valid loss:0.5979 LR:0.1
Training: Epoch[024/300] Iteration[050/782] Loss: 0.3679 Acc:87.16%
Training: Epoch[024/300] Iteration[100/782] Loss: 0.3719 Acc:87.14%
Training: Epoch[024/300] Iteration[150/782] Loss: 0.3801 Acc:86.95%
Training: Epoch[024/300] Iteration[200/782] Loss: 0.3856 Acc:86.70%
Training: Epoch[024/300] Iteration[250/782] Loss: 0.3844 Acc:86.69%
Training: Epoch[024/300] Iteration[300/782] Loss: 0.3802 Acc:86.89%
Training: Epoch[024/300] Iteration[350/782] Loss: 0.3823 Acc:86.82%
Training: Epoch[024/300] Iteration[400/782] Loss: 0.3884 Acc:86.64%
Training: Epoch[024/300] Iteration[450/782] Loss: 0.3869 Acc:86.67%
Training: Epoch[024/300] Iteration[500/782] Loss: 0.3873 Acc:86.70%
Training: Epoch[024/300] Iteration[550/782] Loss: 0.3840 Acc:86.80%
Training: Epoch[024/300] Iteration[600/782] Loss: 0.3834 Acc:86.83%
Training: Epoch[024/300] Iteration[650/782] Loss: 0.3832 Acc:86.88%
Training: Epoch[024/300] Iteration[700/782] Loss: 0.3842 Acc:86.84%
Training: Epoch[024/300] Iteration[750/782] Loss: 0.3867 Acc:86.76%
Epoch[024/300] Train Acc: 86.73% Valid Acc:83.39% Train loss:0.3878 Valid loss:0.4972 LR:0.1
Training: Epoch[025/300] Iteration[050/782] Loss: 0.3573 Acc:87.28%
Training: Epoch[025/300] Iteration[100/782] Loss: 0.3612 Acc:87.52%
Training: Epoch[025/300] Iteration[150/782] Loss: 0.3621 Acc:87.32%
Training: Epoch[025/300] Iteration[200/782] Loss: 0.3643 Acc:87.17%
Training: Epoch[025/300] Iteration[250/782] Loss: 0.3731 Acc:86.99%
Training: Epoch[025/300] Iteration[300/782] Loss: 0.3758 Acc:86.95%
Training: Epoch[025/300] Iteration[350/782] Loss: 0.3778 Acc:86.89%
Training: Epoch[025/300] Iteration[400/782] Loss: 0.3795 Acc:86.91%
Training: Epoch[025/300] Iteration[450/782] Loss: 0.3766 Acc:86.96%
Training: Epoch[025/300] Iteration[500/782] Loss: 0.3820 Acc:86.76%
Training: Epoch[025/300] Iteration[550/782] Loss: 0.3832 Acc:86.79%
Training: Epoch[025/300] Iteration[600/782] Loss: 0.3837 Acc:86.79%
Training: Epoch[025/300] Iteration[650/782] Loss: 0.3850 Acc:86.71%
Training: Epoch[025/300] Iteration[700/782] Loss: 0.3851 Acc:86.75%
Training: Epoch[025/300] Iteration[750/782] Loss: 0.3863 Acc:86.70%
Epoch[025/300] Train Acc: 86.73% Valid Acc:80.91% Train loss:0.3866 Valid loss:0.6007 LR:0.1
Training: Epoch[026/300] Iteration[050/782] Loss: 0.4211 Acc:85.03%
Training: Epoch[026/300] Iteration[100/782] Loss: 0.3952 Acc:86.23%
Training: Epoch[026/300] Iteration[150/782] Loss: 0.3921 Acc:86.28%
Training: Epoch[026/300] Iteration[200/782] Loss: 0.3924 Acc:86.52%
Training: Epoch[026/300] Iteration[250/782] Loss: 0.3919 Acc:86.61%
Training: Epoch[026/300] Iteration[300/782] Loss: 0.3885 Acc:86.73%
Training: Epoch[026/300] Iteration[350/782] Loss: 0.3825 Acc:86.88%
Training: Epoch[026/300] Iteration[400/782] Loss: 0.3843 Acc:86.79%
Training: Epoch[026/300] Iteration[450/782] Loss: 0.3831 Acc:86.83%
Training: Epoch[026/300] Iteration[500/782] Loss: 0.3848 Acc:86.73%
Training: Epoch[026/300] Iteration[550/782] Loss: 0.3821 Acc:86.80%
Training: Epoch[026/300] Iteration[600/782] Loss: 0.3832 Acc:86.70%
Training: Epoch[026/300] Iteration[650/782] Loss: 0.3845 Acc:86.60%
Training: Epoch[026/300] Iteration[700/782] Loss: 0.3841 Acc:86.64%
Training: Epoch[026/300] Iteration[750/782] Loss: 0.3853 Acc:86.63%
Epoch[026/300] Train Acc: 86.68% Valid Acc:81.55% Train loss:0.3849 Valid loss:0.5654 LR:0.1
Training: Epoch[027/300] Iteration[050/782] Loss: 0.3327 Acc:88.59%
Training: Epoch[027/300] Iteration[100/782] Loss: 0.3553 Acc:87.73%
Training: Epoch[027/300] Iteration[150/782] Loss: 0.3609 Acc:87.44%
Training: Epoch[027/300] Iteration[200/782] Loss: 0.3688 Acc:87.01%
Training: Epoch[027/300] Iteration[250/782] Loss: 0.3734 Acc:86.82%
Training: Epoch[027/300] Iteration[300/782] Loss: 0.3721 Acc:86.96%
Training: Epoch[027/300] Iteration[350/782] Loss: 0.3715 Acc:87.00%
Training: Epoch[027/300] Iteration[400/782] Loss: 0.3716 Acc:87.08%
Training: Epoch[027/300] Iteration[450/782] Loss: 0.3772 Acc:86.98%
Training: Epoch[027/300] Iteration[500/782] Loss: 0.3776 Acc:86.94%
Training: Epoch[027/300] Iteration[550/782] Loss: 0.3779 Acc:87.00%
Training: Epoch[027/300] Iteration[600/782] Loss: 0.3797 Acc:86.91%
Training: Epoch[027/300] Iteration[650/782] Loss: 0.3788 Acc:86.92%
Training: Epoch[027/300] Iteration[700/782] Loss: 0.3796 Acc:86.88%
Training: Epoch[027/300] Iteration[750/782] Loss: 0.3787 Acc:86.89%
Epoch[027/300] Train Acc: 86.86% Valid Acc:83.91% Train loss:0.3786 Valid loss:0.4833 LR:0.1
Training: Epoch[028/300] Iteration[050/782] Loss: 0.3817 Acc:87.00%
Training: Epoch[028/300] Iteration[100/782] Loss: 0.3856 Acc:86.80%
Training: Epoch[028/300] Iteration[150/782] Loss: 0.3780 Acc:87.05%
Training: Epoch[028/300] Iteration[200/782] Loss: 0.3714 Acc:87.20%
Training: Epoch[028/300] Iteration[250/782] Loss: 0.3736 Acc:87.17%
Training: Epoch[028/300] Iteration[300/782] Loss: 0.3745 Acc:87.15%
Training: Epoch[028/300] Iteration[350/782] Loss: 0.3739 Acc:87.17%
Training: Epoch[028/300] Iteration[400/782] Loss: 0.3740 Acc:87.13%
Training: Epoch[028/300] Iteration[450/782] Loss: 0.3726 Acc:87.09%
Training: Epoch[028/300] Iteration[500/782] Loss: 0.3717 Acc:87.16%
Training: Epoch[028/300] Iteration[550/782] Loss: 0.3704 Acc:87.23%
Training: Epoch[028/300] Iteration[600/782] Loss: 0.3732 Acc:87.13%
Training: Epoch[028/300] Iteration[650/782] Loss: 0.3751 Acc:87.11%
Training: Epoch[028/300] Iteration[700/782] Loss: 0.3727 Acc:87.15%
Training: Epoch[028/300] Iteration[750/782] Loss: 0.3732 Acc:87.12%
Epoch[028/300] Train Acc: 87.10% Valid Acc:80.78% Train loss:0.3734 Valid loss:0.6064 LR:0.1
Training: Epoch[029/300] Iteration[050/782] Loss: 0.3599 Acc:87.47%
Training: Epoch[029/300] Iteration[100/782] Loss: 0.3646 Acc:87.42%
Training: Epoch[029/300] Iteration[150/782] Loss: 0.3648 Acc:87.58%
Training: Epoch[029/300] Iteration[200/782] Loss: 0.3680 Acc:87.29%
Training: Epoch[029/300] Iteration[250/782] Loss: 0.3621 Acc:87.59%
Training: Epoch[029/300] Iteration[300/782] Loss: 0.3625 Acc:87.54%
Training: Epoch[029/300] Iteration[350/782] Loss: 0.3628 Acc:87.45%
Training: Epoch[029/300] Iteration[400/782] Loss: 0.3631 Acc:87.45%
Training: Epoch[029/300] Iteration[450/782] Loss: 0.3603 Acc:87.55%
Training: Epoch[029/300] Iteration[500/782] Loss: 0.3618 Acc:87.51%
Training: Epoch[029/300] Iteration[550/782] Loss: 0.3650 Acc:87.34%
Training: Epoch[029/300] Iteration[600/782] Loss: 0.3641 Acc:87.36%
Training: Epoch[029/300] Iteration[650/782] Loss: 0.3629 Acc:87.46%
Training: Epoch[029/300] Iteration[700/782] Loss: 0.3642 Acc:87.44%
Training: Epoch[029/300] Iteration[750/782] Loss: 0.3658 Acc:87.41%
Epoch[029/300] Train Acc: 87.36% Valid Acc:83.03% Train loss:0.3675 Valid loss:0.5194 LR:0.1
Training: Epoch[030/300] Iteration[050/782] Loss: 0.3694 Acc:86.66%
Training: Epoch[030/300] Iteration[100/782] Loss: 0.3615 Acc:87.39%
Training: Epoch[030/300] Iteration[150/782] Loss: 0.3648 Acc:87.52%
Training: Epoch[030/300] Iteration[200/782] Loss: 0.3601 Acc:87.71%
Training: Epoch[030/300] Iteration[250/782] Loss: 0.3671 Acc:87.48%
Training: Epoch[030/300] Iteration[300/782] Loss: 0.3617 Acc:87.66%
Training: Epoch[030/300] Iteration[350/782] Loss: 0.3585 Acc:87.75%
Training: Epoch[030/300] Iteration[400/782] Loss: 0.3597 Acc:87.72%
Training: Epoch[030/300] Iteration[450/782] Loss: 0.3658 Acc:87.51%
Training: Epoch[030/300] Iteration[500/782] Loss: 0.3658 Acc:87.42%
Training: Epoch[030/300] Iteration[550/782] Loss: 0.3669 Acc:87.33%
Training: Epoch[030/300] Iteration[600/782] Loss: 0.3667 Acc:87.36%
Training: Epoch[030/300] Iteration[650/782] Loss: 0.3672 Acc:87.32%
Training: Epoch[030/300] Iteration[700/782] Loss: 0.3671 Acc:87.34%
Training: Epoch[030/300] Iteration[750/782] Loss: 0.3671 Acc:87.34%
Epoch[030/300] Train Acc: 87.35% Valid Acc:83.43% Train loss:0.3673 Valid loss:0.5518 LR:0.1
Training: Epoch[031/300] Iteration[050/782] Loss: 0.3276 Acc:88.69%
Training: Epoch[031/300] Iteration[100/782] Loss: 0.3480 Acc:87.97%
Training: Epoch[031/300] Iteration[150/782] Loss: 0.3563 Acc:87.80%
Training: Epoch[031/300] Iteration[200/782] Loss: 0.3506 Acc:88.15%
Training: Epoch[031/300] Iteration[250/782] Loss: 0.3579 Acc:87.87%
Training: Epoch[031/300] Iteration[300/782] Loss: 0.3596 Acc:87.89%
Training: Epoch[031/300] Iteration[350/782] Loss: 0.3592 Acc:87.89%
Training: Epoch[031/300] Iteration[400/782] Loss: 0.3586 Acc:87.86%
Training: Epoch[031/300] Iteration[450/782] Loss: 0.3633 Acc:87.60%
Training: Epoch[031/300] Iteration[500/782] Loss: 0.3659 Acc:87.50%
Training: Epoch[031/300] Iteration[550/782] Loss: 0.3670 Acc:87.43%
Training: Epoch[031/300] Iteration[600/782] Loss: 0.3675 Acc:87.38%
Training: Epoch[031/300] Iteration[650/782] Loss: 0.3667 Acc:87.45%
Training: Epoch[031/300] Iteration[700/782] Loss: 0.3666 Acc:87.44%
Training: Epoch[031/300] Iteration[750/782] Loss: 0.3662 Acc:87.46%
Epoch[031/300] Train Acc: 87.49% Valid Acc:84.80% Train loss:0.3653 Valid loss:0.4488 LR:0.1
Training: Epoch[032/300] Iteration[050/782] Loss: 0.3395 Acc:88.47%
Training: Epoch[032/300] Iteration[100/782] Loss: 0.3399 Acc:88.62%
Training: Epoch[032/300] Iteration[150/782] Loss: 0.3474 Acc:88.20%
Training: Epoch[032/300] Iteration[200/782] Loss: 0.3512 Acc:88.07%
Training: Epoch[032/300] Iteration[250/782] Loss: 0.3521 Acc:87.96%
Training: Epoch[032/300] Iteration[300/782] Loss: 0.3555 Acc:87.78%
Training: Epoch[032/300] Iteration[350/782] Loss: 0.3560 Acc:87.78%
Training: Epoch[032/300] Iteration[400/782] Loss: 0.3564 Acc:87.79%
Training: Epoch[032/300] Iteration[450/782] Loss: 0.3581 Acc:87.73%
Training: Epoch[032/300] Iteration[500/782] Loss: 0.3594 Acc:87.68%
Training: Epoch[032/300] Iteration[550/782] Loss: 0.3611 Acc:87.61%
Training: Epoch[032/300] Iteration[600/782] Loss: 0.3596 Acc:87.61%
Training: Epoch[032/300] Iteration[650/782] Loss: 0.3605 Acc:87.61%
Training: Epoch[032/300] Iteration[700/782] Loss: 0.3629 Acc:87.56%
Training: Epoch[032/300] Iteration[750/782] Loss: 0.3629 Acc:87.53%
Epoch[032/300] Train Acc: 87.48% Valid Acc:84.25% Train loss:0.3639 Valid loss:0.4840 LR:0.1
Training: Epoch[033/300] Iteration[050/782] Loss: 0.3535 Acc:88.09%
Training: Epoch[033/300] Iteration[100/782] Loss: 0.3563 Acc:87.66%
Training: Epoch[033/300] Iteration[150/782] Loss: 0.3565 Acc:87.55%
Training: Epoch[033/300] Iteration[200/782] Loss: 0.3657 Acc:87.41%
Training: Epoch[033/300] Iteration[250/782] Loss: 0.3661 Acc:87.31%
Training: Epoch[033/300] Iteration[300/782] Loss: 0.3698 Acc:87.23%
Training: Epoch[033/300] Iteration[350/782] Loss: 0.3747 Acc:87.13%
Training: Epoch[033/300] Iteration[400/782] Loss: 0.3705 Acc:87.29%
Training: Epoch[033/300] Iteration[450/782] Loss: 0.3724 Acc:87.22%
Training: Epoch[033/300] Iteration[500/782] Loss: 0.3708 Acc:87.28%
Training: Epoch[033/300] Iteration[550/782] Loss: 0.3674 Acc:87.37%
Training: Epoch[033/300] Iteration[600/782] Loss: 0.3674 Acc:87.35%
Training: Epoch[033/300] Iteration[650/782] Loss: 0.3660 Acc:87.35%
Training: Epoch[033/300] Iteration[700/782] Loss: 0.3662 Acc:87.35%
Training: Epoch[033/300] Iteration[750/782] Loss: 0.3669 Acc:87.33%
Epoch[033/300] Train Acc: 87.31% Valid Acc:84.23% Train loss:0.3676 Valid loss:0.4874 LR:0.1
Training: Epoch[034/300] Iteration[050/782] Loss: 0.3459 Acc:88.69%
Training: Epoch[034/300] Iteration[100/782] Loss: 0.3409 Acc:88.53%
Training: Epoch[034/300] Iteration[150/782] Loss: 0.3460 Acc:88.31%
Training: Epoch[034/300] Iteration[200/782] Loss: 0.3462 Acc:88.26%
Training: Epoch[034/300] Iteration[250/782] Loss: 0.3535 Acc:87.96%
Training: Epoch[034/300] Iteration[300/782] Loss: 0.3519 Acc:87.95%
Training: Epoch[034/300] Iteration[350/782] Loss: 0.3517 Acc:88.00%
Training: Epoch[034/300] Iteration[400/782] Loss: 0.3519 Acc:87.98%
Training: Epoch[034/300] Iteration[450/782] Loss: 0.3535 Acc:87.95%
Training: Epoch[034/300] Iteration[500/782] Loss: 0.3550 Acc:87.82%
Training: Epoch[034/300] Iteration[550/782] Loss: 0.3562 Acc:87.78%
Training: Epoch[034/300] Iteration[600/782] Loss: 0.3587 Acc:87.67%
Training: Epoch[034/300] Iteration[650/782] Loss: 0.3597 Acc:87.61%
Training: Epoch[034/300] Iteration[700/782] Loss: 0.3587 Acc:87.63%
Training: Epoch[034/300] Iteration[750/782] Loss: 0.3574 Acc:87.65%
Epoch[034/300] Train Acc: 87.65% Valid Acc:81.38% Train loss:0.3590 Valid loss:0.5855 LR:0.1
Training: Epoch[035/300] Iteration[050/782] Loss: 0.3891 Acc:86.69%
Training: Epoch[035/300] Iteration[100/782] Loss: 0.3659 Acc:87.41%
Training: Epoch[035/300] Iteration[150/782] Loss: 0.3554 Acc:87.86%
Training: Epoch[035/300] Iteration[200/782] Loss: 0.3624 Acc:87.49%
Training: Epoch[035/300] Iteration[250/782] Loss: 0.3649 Acc:87.38%
Training: Epoch[035/300] Iteration[300/782] Loss: 0.3626 Acc:87.45%
Training: Epoch[035/300] Iteration[350/782] Loss: 0.3554 Acc:87.64%
Training: Epoch[035/300] Iteration[400/782] Loss: 0.3551 Acc:87.71%
Training: Epoch[035/300] Iteration[450/782] Loss: 0.3558 Acc:87.70%
Training: Epoch[035/300] Iteration[500/782] Loss: 0.3562 Acc:87.67%
Training: Epoch[035/300] Iteration[550/782] Loss: 0.3568 Acc:87.69%
Training: Epoch[035/300] Iteration[600/782] Loss: 0.3570 Acc:87.71%
Training: Epoch[035/300] Iteration[650/782] Loss: 0.3573 Acc:87.71%
Training: Epoch[035/300] Iteration[700/782] Loss: 0.3588 Acc:87.68%
Training: Epoch[035/300] Iteration[750/782] Loss: 0.3577 Acc:87.67%
Epoch[035/300] Train Acc: 87.64% Valid Acc:83.77% Train loss:0.3580 Valid loss:0.4900 LR:0.1
Training: Epoch[036/300] Iteration[050/782] Loss: 0.3085 Acc:89.25%
Training: Epoch[036/300] Iteration[100/782] Loss: 0.3346 Acc:88.45%
Training: Epoch[036/300] Iteration[150/782] Loss: 0.3422 Acc:88.16%
Training: Epoch[036/300] Iteration[200/782] Loss: 0.3389 Acc:88.37%
Training: Epoch[036/300] Iteration[250/782] Loss: 0.3390 Acc:88.33%
Training: Epoch[036/300] Iteration[300/782] Loss: 0.3432 Acc:88.16%
Training: Epoch[036/300] Iteration[350/782] Loss: 0.3471 Acc:88.03%
Training: Epoch[036/300] Iteration[400/782] Loss: 0.3470 Acc:88.07%
Training: Epoch[036/300] Iteration[450/782] Loss: 0.3495 Acc:87.96%
Training: Epoch[036/300] Iteration[500/782] Loss: 0.3488 Acc:88.00%
Training: Epoch[036/300] Iteration[550/782] Loss: 0.3498 Acc:87.93%
Training: Epoch[036/300] Iteration[600/782] Loss: 0.3501 Acc:87.94%
Training: Epoch[036/300] Iteration[650/782] Loss: 0.3512 Acc:87.90%
Training: Epoch[036/300] Iteration[700/782] Loss: 0.3529 Acc:87.82%
Training: Epoch[036/300] Iteration[750/782] Loss: 0.3551 Acc:87.76%
Epoch[036/300] Train Acc: 87.75% Valid Acc:85.40% Train loss:0.3555 Valid loss:0.4357 LR:0.1
Training: Epoch[037/300] Iteration[050/782] Loss: 0.3364 Acc:88.50%
Training: Epoch[037/300] Iteration[100/782] Loss: 0.3563 Acc:87.47%
Training: Epoch[037/300] Iteration[150/782] Loss: 0.3611 Acc:87.10%
Training: Epoch[037/300] Iteration[200/782] Loss: 0.3568 Acc:87.32%
Training: Epoch[037/300] Iteration[250/782] Loss: 0.3560 Acc:87.44%
Training: Epoch[037/300] Iteration[300/782] Loss: 0.3512 Acc:87.66%
Training: Epoch[037/300] Iteration[350/782] Loss: 0.3515 Acc:87.69%
Training: Epoch[037/300] Iteration[400/782] Loss: 0.3571 Acc:87.50%
Training: Epoch[037/300] Iteration[450/782] Loss: 0.3560 Acc:87.58%
Training: Epoch[037/300] Iteration[500/782] Loss: 0.3557 Acc:87.59%
Training: Epoch[037/300] Iteration[550/782] Loss: 0.3568 Acc:87.52%
Training: Epoch[037/300] Iteration[600/782] Loss: 0.3559 Acc:87.57%
Training: Epoch[037/300] Iteration[650/782] Loss: 0.3542 Acc:87.62%
Training: Epoch[037/300] Iteration[700/782] Loss: 0.3534 Acc:87.63%
Training: Epoch[037/300] Iteration[750/782] Loss: 0.3543 Acc:87.63%
Epoch[037/300] Train Acc: 87.60% Valid Acc:81.61% Train loss:0.3549 Valid loss:0.5639 LR:0.1
Training: Epoch[038/300] Iteration[050/782] Loss: 0.3572 Acc:87.47%
Training: Epoch[038/300] Iteration[100/782] Loss: 0.3513 Acc:87.91%
Training: Epoch[038/300] Iteration[150/782] Loss: 0.3478 Acc:87.95%
Training: Epoch[038/300] Iteration[200/782] Loss: 0.3446 Acc:88.04%
Training: Epoch[038/300] Iteration[250/782] Loss: 0.3423 Acc:88.14%
Training: Epoch[038/300] Iteration[300/782] Loss: 0.3424 Acc:88.10%
Training: Epoch[038/300] Iteration[350/782] Loss: 0.3461 Acc:87.99%
Training: Epoch[038/300] Iteration[400/782] Loss: 0.3471 Acc:87.98%
Training: Epoch[038/300] Iteration[450/782] Loss: 0.3479 Acc:87.90%
Training: Epoch[038/300] Iteration[500/782] Loss: 0.3496 Acc:87.85%
Training: Epoch[038/300] Iteration[550/782] Loss: 0.3503 Acc:87.86%
Training: Epoch[038/300] Iteration[600/782] Loss: 0.3491 Acc:87.90%
Training: Epoch[038/300] Iteration[650/782] Loss: 0.3491 Acc:87.84%
Training: Epoch[038/300] Iteration[700/782] Loss: 0.3485 Acc:87.88%
Training: Epoch[038/300] Iteration[750/782] Loss: 0.3479 Acc:87.90%
Epoch[038/300] Train Acc: 87.89% Valid Acc:84.16% Train loss:0.3475 Valid loss:0.4867 LR:0.1
Training: Epoch[039/300] Iteration[050/782] Loss: 0.3482 Acc:88.47%
Training: Epoch[039/300] Iteration[100/782] Loss: 0.3468 Acc:88.25%
Training: Epoch[039/300] Iteration[150/782] Loss: 0.3385 Acc:88.68%
Training: Epoch[039/300] Iteration[200/782] Loss: 0.3405 Acc:88.60%
Training: Epoch[039/300] Iteration[250/782] Loss: 0.3423 Acc:88.42%
Training: Epoch[039/300] Iteration[300/782] Loss: 0.3396 Acc:88.49%
Training: Epoch[039/300] Iteration[350/782] Loss: 0.3443 Acc:88.36%
Training: Epoch[039/300] Iteration[400/782] Loss: 0.3436 Acc:88.42%
Training: Epoch[039/300] Iteration[450/782] Loss: 0.3406 Acc:88.47%
Training: Epoch[039/300] Iteration[500/782] Loss: 0.3434 Acc:88.39%
Training: Epoch[039/300] Iteration[550/782] Loss: 0.3462 Acc:88.25%
Training: Epoch[039/300] Iteration[600/782] Loss: 0.3461 Acc:88.21%
Training: Epoch[039/300] Iteration[650/782] Loss: 0.3444 Acc:88.25%
Training: Epoch[039/300] Iteration[700/782] Loss: 0.3471 Acc:88.17%
Training: Epoch[039/300] Iteration[750/782] Loss: 0.3492 Acc:88.09%
Epoch[039/300] Train Acc: 88.06% Valid Acc:83.07% Train loss:0.3500 Valid loss:0.5028 LR:0.1
Training: Epoch[040/300] Iteration[050/782] Loss: 0.3428 Acc:88.75%
Training: Epoch[040/300] Iteration[100/782] Loss: 0.3362 Acc:88.88%
Training: Epoch[040/300] Iteration[150/782] Loss: 0.3367 Acc:88.72%
Training: Epoch[040/300] Iteration[200/782] Loss: 0.3357 Acc:88.56%
Training: Epoch[040/300] Iteration[250/782] Loss: 0.3398 Acc:88.38%
Training: Epoch[040/300] Iteration[300/782] Loss: 0.3383 Acc:88.45%
Training: Epoch[040/300] Iteration[350/782] Loss: 0.3372 Acc:88.43%
Training: Epoch[040/300] Iteration[400/782] Loss: 0.3437 Acc:88.31%
Training: Epoch[040/300] Iteration[450/782] Loss: 0.3447 Acc:88.23%
Training: Epoch[040/300] Iteration[500/782] Loss: 0.3466 Acc:88.09%
Training: Epoch[040/300] Iteration[550/782] Loss: 0.3458 Acc:88.09%
Training: Epoch[040/300] Iteration[600/782] Loss: 0.3463 Acc:88.01%
Training: Epoch[040/300] Iteration[650/782] Loss: 0.3473 Acc:88.00%
Training: Epoch[040/300] Iteration[700/782] Loss: 0.3490 Acc:87.96%
Training: Epoch[040/300] Iteration[750/782] Loss: 0.3483 Acc:87.99%
Epoch[040/300] Train Acc: 87.95% Valid Acc:85.44% Train loss:0.3485 Valid loss:0.4424 LR:0.1
Training: Epoch[041/300] Iteration[050/782] Loss: 0.3369 Acc:88.16%
Training: Epoch[041/300] Iteration[100/782] Loss: 0.3386 Acc:88.12%
Training: Epoch[041/300] Iteration[150/782] Loss: 0.3318 Acc:88.48%
Training: Epoch[041/300] Iteration[200/782] Loss: 0.3368 Acc:88.17%
Training: Epoch[041/300] Iteration[250/782] Loss: 0.3379 Acc:88.18%
Training: Epoch[041/300] Iteration[300/782] Loss: 0.3355 Acc:88.32%
Training: Epoch[041/300] Iteration[350/782] Loss: 0.3366 Acc:88.25%
Training: Epoch[041/300] Iteration[400/782] Loss: 0.3410 Acc:88.09%
Training: Epoch[041/300] Iteration[450/782] Loss: 0.3402 Acc:88.11%
Training: Epoch[041/300] Iteration[500/782] Loss: 0.3409 Acc:88.08%
Training: Epoch[041/300] Iteration[550/782] Loss: 0.3398 Acc:88.18%
Training: Epoch[041/300] Iteration[600/782] Loss: 0.3416 Acc:88.17%
Training: Epoch[041/300] Iteration[650/782] Loss: 0.3425 Acc:88.12%
Training: Epoch[041/300] Iteration[700/782] Loss: 0.3443 Acc:88.04%
Training: Epoch[041/300] Iteration[750/782] Loss: 0.3447 Acc:88.08%
Epoch[041/300] Train Acc: 88.08% Valid Acc:83.35% Train loss:0.3457 Valid loss:0.5132 LR:0.1
Training: Epoch[042/300] Iteration[050/782] Loss: 0.3561 Acc:87.47%
Training: Epoch[042/300] Iteration[100/782] Loss: 0.3378 Acc:88.23%
Training: Epoch[042/300] Iteration[150/782] Loss: 0.3419 Acc:88.31%
Training: Epoch[042/300] Iteration[200/782] Loss: 0.3381 Acc:88.37%
Training: Epoch[042/300] Iteration[250/782] Loss: 0.3348 Acc:88.38%
Training: Epoch[042/300] Iteration[300/782] Loss: 0.3369 Acc:88.41%
Training: Epoch[042/300] Iteration[350/782] Loss: 0.3389 Acc:88.38%
Training: Epoch[042/300] Iteration[400/782] Loss: 0.3410 Acc:88.30%
Training: Epoch[042/300] Iteration[450/782] Loss: 0.3415 Acc:88.21%
Training: Epoch[042/300] Iteration[500/782] Loss: 0.3440 Acc:88.17%
Training: Epoch[042/300] Iteration[550/782] Loss: 0.3463 Acc:88.09%
Training: Epoch[042/300] Iteration[600/782] Loss: 0.3434 Acc:88.20%
Training: Epoch[042/300] Iteration[650/782] Loss: 0.3441 Acc:88.15%
Training: Epoch[042/300] Iteration[700/782] Loss: 0.3453 Acc:88.09%
Training: Epoch[042/300] Iteration[750/782] Loss: 0.3445 Acc:88.11%
Epoch[042/300] Train Acc: 88.17% Valid Acc:84.28% Train loss:0.3435 Valid loss:0.4517 LR:0.1
Training: Epoch[043/300] Iteration[050/782] Loss: 0.3350 Acc:88.03%
Training: Epoch[043/300] Iteration[100/782] Loss: 0.3476 Acc:87.84%
Training: Epoch[043/300] Iteration[150/782] Loss: 0.3422 Acc:88.24%
Training: Epoch[043/300] Iteration[200/782] Loss: 0.3396 Acc:88.34%
Training: Epoch[043/300] Iteration[250/782] Loss: 0.3415 Acc:88.22%
Training: Epoch[043/300] Iteration[300/782] Loss: 0.3429 Acc:88.27%
Training: Epoch[043/300] Iteration[350/782] Loss: 0.3406 Acc:88.25%
Training: Epoch[043/300] Iteration[400/782] Loss: 0.3406 Acc:88.21%
Training: Epoch[043/300] Iteration[450/782] Loss: 0.3382 Acc:88.31%
Training: Epoch[043/300] Iteration[500/782] Loss: 0.3373 Acc:88.34%
Training: Epoch[043/300] Iteration[550/782] Loss: 0.3365 Acc:88.36%
Training: Epoch[043/300] Iteration[600/782] Loss: 0.3376 Acc:88.33%
Training: Epoch[043/300] Iteration[650/782] Loss: 0.3381 Acc:88.32%
Training: Epoch[043/300] Iteration[700/782] Loss: 0.3397 Acc:88.29%
Training: Epoch[043/300] Iteration[750/782] Loss: 0.3398 Acc:88.31%
Epoch[043/300] Train Acc: 88.30% Valid Acc:84.26% Train loss:0.3404 Valid loss:0.4912 LR:0.1
Training: Epoch[044/300] Iteration[050/782] Loss: 0.3277 Acc:88.75%
Training: Epoch[044/300] Iteration[100/782] Loss: 0.3219 Acc:88.94%
Training: Epoch[044/300] Iteration[150/782] Loss: 0.3248 Acc:88.61%
Training: Epoch[044/300] Iteration[200/782] Loss: 0.3388 Acc:88.04%
Training: Epoch[044/300] Iteration[250/782] Loss: 0.3407 Acc:88.17%
Training: Epoch[044/300] Iteration[300/782] Loss: 0.3409 Acc:88.17%
Training: Epoch[044/300] Iteration[350/782] Loss: 0.3386 Acc:88.27%
Training: Epoch[044/300] Iteration[400/782] Loss: 0.3384 Acc:88.29%
Training: Epoch[044/300] Iteration[450/782] Loss: 0.3376 Acc:88.28%
Training: Epoch[044/300] Iteration[500/782] Loss: 0.3370 Acc:88.33%
Training: Epoch[044/300] Iteration[550/782] Loss: 0.3389 Acc:88.24%
Training: Epoch[044/300] Iteration[600/782] Loss: 0.3388 Acc:88.29%
Training: Epoch[044/300] Iteration[650/782] Loss: 0.3398 Acc:88.26%
Training: Epoch[044/300] Iteration[700/782] Loss: 0.3418 Acc:88.19%
Training: Epoch[044/300] Iteration[750/782] Loss: 0.3412 Acc:88.24%
Epoch[044/300] Train Acc: 88.26% Valid Acc:83.63% Train loss:0.3410 Valid loss:0.5026 LR:0.1
Training: Epoch[045/300] Iteration[050/782] Loss: 0.3037 Acc:89.12%
Training: Epoch[045/300] Iteration[100/782] Loss: 0.3177 Acc:88.55%
Training: Epoch[045/300] Iteration[150/782] Loss: 0.3360 Acc:88.18%
Training: Epoch[045/300] Iteration[200/782] Loss: 0.3343 Acc:88.24%
Training: Epoch[045/300] Iteration[250/782] Loss: 0.3320 Acc:88.33%
Training: Epoch[045/300] Iteration[300/782] Loss: 0.3315 Acc:88.42%
Training: Epoch[045/300] Iteration[350/782] Loss: 0.3332 Acc:88.42%
Training: Epoch[045/300] Iteration[400/782] Loss: 0.3358 Acc:88.32%
Training: Epoch[045/300] Iteration[450/782] Loss: 0.3377 Acc:88.21%
Training: Epoch[045/300] Iteration[500/782] Loss: 0.3385 Acc:88.16%
Training: Epoch[045/300] Iteration[550/782] Loss: 0.3368 Acc:88.27%
Training: Epoch[045/300] Iteration[600/782] Loss: 0.3340 Acc:88.32%
Training: Epoch[045/300] Iteration[650/782] Loss: 0.3346 Acc:88.34%
Training: Epoch[045/300] Iteration[700/782] Loss: 0.3352 Acc:88.33%
Training: Epoch[045/300] Iteration[750/782] Loss: 0.3370 Acc:88.27%
Epoch[045/300] Train Acc: 88.26% Valid Acc:83.26% Train loss:0.3372 Valid loss:0.5249 LR:0.1
Training: Epoch[046/300] Iteration[050/782] Loss: 0.3283 Acc:88.84%
Training: Epoch[046/300] Iteration[100/782] Loss: 0.3373 Acc:88.58%
Training: Epoch[046/300] Iteration[150/782] Loss: 0.3318 Acc:88.41%
Training: Epoch[046/300] Iteration[200/782] Loss: 0.3342 Acc:88.25%
Training: Epoch[046/300] Iteration[250/782] Loss: 0.3373 Acc:88.19%
Training: Epoch[046/300] Iteration[300/782] Loss: 0.3376 Acc:88.20%
Training: Epoch[046/300] Iteration[350/782] Loss: 0.3369 Acc:88.11%
Training: Epoch[046/300] Iteration[400/782] Loss: 0.3353 Acc:88.21%
Training: Epoch[046/300] Iteration[450/782] Loss: 0.3345 Acc:88.25%
Training: Epoch[046/300] Iteration[500/782] Loss: 0.3358 Acc:88.22%
Training: Epoch[046/300] Iteration[550/782] Loss: 0.3336 Acc:88.34%
Training: Epoch[046/300] Iteration[600/782] Loss: 0.3344 Acc:88.33%
Training: Epoch[046/300] Iteration[650/782] Loss: 0.3345 Acc:88.31%
Training: Epoch[046/300] Iteration[700/782] Loss: 0.3351 Acc:88.30%
Training: Epoch[046/300] Iteration[750/782] Loss: 0.3349 Acc:88.34%
Epoch[046/300] Train Acc: 88.33% Valid Acc:80.64% Train loss:0.3349 Valid loss:0.6243 LR:0.1
Training: Epoch[047/300] Iteration[050/782] Loss: 0.3372 Acc:88.56%
Training: Epoch[047/300] Iteration[100/782] Loss: 0.3173 Acc:89.27%
Training: Epoch[047/300] Iteration[150/782] Loss: 0.3110 Acc:89.44%
Training: Epoch[047/300] Iteration[200/782] Loss: 0.3158 Acc:89.17%
Training: Epoch[047/300] Iteration[250/782] Loss: 0.3217 Acc:88.90%
Training: Epoch[047/300] Iteration[300/782] Loss: 0.3229 Acc:88.87%
Training: Epoch[047/300] Iteration[350/782] Loss: 0.3238 Acc:88.76%
Training: Epoch[047/300] Iteration[400/782] Loss: 0.3241 Acc:88.76%
Training: Epoch[047/300] Iteration[450/782] Loss: 0.3268 Acc:88.64%
Training: Epoch[047/300] Iteration[500/782] Loss: 0.3292 Acc:88.54%
Training: Epoch[047/300] Iteration[550/782] Loss: 0.3282 Acc:88.62%
Training: Epoch[047/300] Iteration[600/782] Loss: 0.3292 Acc:88.57%
Training: Epoch[047/300] Iteration[650/782] Loss: 0.3320 Acc:88.46%
Training: Epoch[047/300] Iteration[700/782] Loss: 0.3333 Acc:88.41%
Training: Epoch[047/300] Iteration[750/782] Loss: 0.3355 Acc:88.32%
Epoch[047/300] Train Acc: 88.28% Valid Acc:83.68% Train loss:0.3372 Valid loss:0.5182 LR:0.1
Training: Epoch[048/300] Iteration[050/782] Loss: 0.3450 Acc:88.38%
Training: Epoch[048/300] Iteration[100/782] Loss: 0.3205 Acc:89.31%
Training: Epoch[048/300] Iteration[150/782] Loss: 0.3212 Acc:89.27%
Training: Epoch[048/300] Iteration[200/782] Loss: 0.3234 Acc:88.98%
Training: Epoch[048/300] Iteration[250/782] Loss: 0.3213 Acc:88.94%
Training: Epoch[048/300] Iteration[300/782] Loss: 0.3256 Acc:88.78%
Training: Epoch[048/300] Iteration[350/782] Loss: 0.3248 Acc:88.84%
Training: Epoch[048/300] Iteration[400/782] Loss: 0.3259 Acc:88.89%
Training: Epoch[048/300] Iteration[450/782] Loss: 0.3287 Acc:88.71%
Training: Epoch[048/300] Iteration[500/782] Loss: 0.3282 Acc:88.72%
Training: Epoch[048/300] Iteration[550/782] Loss: 0.3268 Acc:88.71%
Training: Epoch[048/300] Iteration[600/782] Loss: 0.3297 Acc:88.59%
Training: Epoch[048/300] Iteration[650/782] Loss: 0.3313 Acc:88.54%
Training: Epoch[048/300] Iteration[700/782] Loss: 0.3314 Acc:88.53%
Training: Epoch[048/300] Iteration[750/782] Loss: 0.3336 Acc:88.44%
Epoch[048/300] Train Acc: 88.32% Valid Acc:82.17% Train loss:0.3362 Valid loss:0.5372 LR:0.1
Training: Epoch[049/300] Iteration[050/782] Loss: 0.3211 Acc:88.56%
Training: Epoch[049/300] Iteration[100/782] Loss: 0.3255 Acc:88.53%
Training: Epoch[049/300] Iteration[150/782] Loss: 0.3213 Acc:88.73%
Training: Epoch[049/300] Iteration[200/782] Loss: 0.3221 Acc:88.67%
Training: Epoch[049/300] Iteration[250/782] Loss: 0.3295 Acc:88.46%
Training: Epoch[049/300] Iteration[300/782] Loss: 0.3312 Acc:88.28%
Training: Epoch[049/300] Iteration[350/782] Loss: 0.3308 Acc:88.38%
Training: Epoch[049/300] Iteration[400/782] Loss: 0.3326 Acc:88.27%
Training: Epoch[049/300] Iteration[450/782] Loss: 0.3347 Acc:88.24%
Training: Epoch[049/300] Iteration[500/782] Loss: 0.3348 Acc:88.18%
Training: Epoch[049/300] Iteration[550/782] Loss: 0.3350 Acc:88.22%
Training: Epoch[049/300] Iteration[600/782] Loss: 0.3353 Acc:88.21%
Training: Epoch[049/300] Iteration[650/782] Loss: 0.3372 Acc:88.12%
Training: Epoch[049/300] Iteration[700/782] Loss: 0.3376 Acc:88.08%
Training: Epoch[049/300] Iteration[750/782] Loss: 0.3375 Acc:88.12%
Epoch[049/300] Train Acc: 88.12% Valid Acc:84.87% Train loss:0.3386 Valid loss:0.4600 LR:0.1
Training: Epoch[050/300] Iteration[050/782] Loss: 0.3523 Acc:87.66%
Training: Epoch[050/300] Iteration[100/782] Loss: 0.3323 Acc:88.31%
Training: Epoch[050/300] Iteration[150/782] Loss: 0.3360 Acc:88.19%
Training: Epoch[050/300] Iteration[200/782] Loss: 0.3370 Acc:88.14%
Training: Epoch[050/300] Iteration[250/782] Loss: 0.3343 Acc:88.18%
Training: Epoch[050/300] Iteration[300/782] Loss: 0.3315 Acc:88.36%
Training: Epoch[050/300] Iteration[350/782] Loss: 0.3356 Acc:88.30%
Training: Epoch[050/300] Iteration[400/782] Loss: 0.3371 Acc:88.28%
Training: Epoch[050/300] Iteration[450/782] Loss: 0.3359 Acc:88.33%
Training: Epoch[050/300] Iteration[500/782] Loss: 0.3345 Acc:88.36%
Training: Epoch[050/300] Iteration[550/782] Loss: 0.3365 Acc:88.34%
Training: Epoch[050/300] Iteration[600/782] Loss: 0.3346 Acc:88.36%
Training: Epoch[050/300] Iteration[650/782] Loss: 0.3360 Acc:88.35%
Training: Epoch[050/300] Iteration[700/782] Loss: 0.3380 Acc:88.28%
Training: Epoch[050/300] Iteration[750/782] Loss: 0.3367 Acc:88.32%
Epoch[050/300] Train Acc: 88.34% Valid Acc:86.36% Train loss:0.3358 Valid loss:0.4205 LR:0.1
Training: Epoch[051/300] Iteration[050/782] Loss: 0.3530 Acc:88.12%
Training: Epoch[051/300] Iteration[100/782] Loss: 0.3392 Acc:88.55%
Training: Epoch[051/300] Iteration[150/782] Loss: 0.3278 Acc:88.90%
Training: Epoch[051/300] Iteration[200/782] Loss: 0.3239 Acc:89.15%
Training: Epoch[051/300] Iteration[250/782] Loss: 0.3260 Acc:89.00%
Training: Epoch[051/300] Iteration[300/782] Loss: 0.3241 Acc:88.93%
Training: Epoch[051/300] Iteration[350/782] Loss: 0.3254 Acc:88.94%
Training: Epoch[051/300] Iteration[400/782] Loss: 0.3276 Acc:88.91%
Training: Epoch[051/300] Iteration[450/782] Loss: 0.3280 Acc:88.93%
Training: Epoch[051/300] Iteration[500/782] Loss: 0.3320 Acc:88.81%
Training: Epoch[051/300] Iteration[550/782] Loss: 0.3338 Acc:88.71%
Training: Epoch[051/300] Iteration[600/782] Loss: 0.3346 Acc:88.60%
Training: Epoch[051/300] Iteration[650/782] Loss: 0.3347 Acc:88.59%
Training: Epoch[051/300] Iteration[700/782] Loss: 0.3337 Acc:88.62%
Training: Epoch[051/300] Iteration[750/782] Loss: 0.3350 Acc:88.57%
Epoch[051/300] Train Acc: 88.58% Valid Acc:83.82% Train loss:0.3345 Valid loss:0.4926 LR:0.1
Training: Epoch[052/300] Iteration[050/782] Loss: 0.3246 Acc:88.91%
Training: Epoch[052/300] Iteration[100/782] Loss: 0.3207 Acc:88.92%
Training: Epoch[052/300] Iteration[150/782] Loss: 0.3200 Acc:88.90%
Training: Epoch[052/300] Iteration[200/782] Loss: 0.3246 Acc:88.60%
Training: Epoch[052/300] Iteration[250/782] Loss: 0.3285 Acc:88.46%
Training: Epoch[052/300] Iteration[300/782] Loss: 0.3273 Acc:88.48%
Training: Epoch[052/300] Iteration[350/782] Loss: 0.3309 Acc:88.39%
Training: Epoch[052/300] Iteration[400/782] Loss: 0.3328 Acc:88.27%
Training: Epoch[052/300] Iteration[450/782] Loss: 0.3342 Acc:88.31%
Training: Epoch[052/300] Iteration[500/782] Loss: 0.3325 Acc:88.39%
Training: Epoch[052/300] Iteration[550/782] Loss: 0.3329 Acc:88.38%
Training: Epoch[052/300] Iteration[600/782] Loss: 0.3333 Acc:88.36%
Training: Epoch[052/300] Iteration[650/782] Loss: 0.3345 Acc:88.34%
Training: Epoch[052/300] Iteration[700/782] Loss: 0.3338 Acc:88.40%
Training: Epoch[052/300] Iteration[750/782] Loss: 0.3355 Acc:88.37%
Epoch[052/300] Train Acc: 88.37% Valid Acc:84.83% Train loss:0.3353 Valid loss:0.4426 LR:0.1
Training: Epoch[053/300] Iteration[050/782] Loss: 0.3413 Acc:88.59%
Training: Epoch[053/300] Iteration[100/782] Loss: 0.3260 Acc:89.03%
Training: Epoch[053/300] Iteration[150/782] Loss: 0.3133 Acc:89.22%
Training: Epoch[053/300] Iteration[200/782] Loss: 0.3197 Acc:89.01%
Training: Epoch[053/300] Iteration[250/782] Loss: 0.3240 Acc:88.89%
Training: Epoch[053/300] Iteration[300/782] Loss: 0.3251 Acc:88.84%
Training: Epoch[053/300] Iteration[350/782] Loss: 0.3241 Acc:88.95%
Training: Epoch[053/300] Iteration[400/782] Loss: 0.3232 Acc:88.95%
Training: Epoch[053/300] Iteration[450/782] Loss: 0.3244 Acc:88.92%
Training: Epoch[053/300] Iteration[500/782] Loss: 0.3262 Acc:88.89%
Training: Epoch[053/300] Iteration[550/782] Loss: 0.3266 Acc:88.85%
Training: Epoch[053/300] Iteration[600/782] Loss: 0.3261 Acc:88.86%
Training: Epoch[053/300] Iteration[650/782] Loss: 0.3268 Acc:88.79%
Training: Epoch[053/300] Iteration[700/782] Loss: 0.3280 Acc:88.74%
Training: Epoch[053/300] Iteration[750/782] Loss: 0.3271 Acc:88.74%
Epoch[053/300] Train Acc: 88.75% Valid Acc:85.19% Train loss:0.3270 Valid loss:0.4451 LR:0.1
Training: Epoch[054/300] Iteration[050/782] Loss: 0.2993 Acc:89.75%
Training: Epoch[054/300] Iteration[100/782] Loss: 0.3142 Acc:88.84%
Training: Epoch[054/300] Iteration[150/782] Loss: 0.3146 Acc:88.78%
Training: Epoch[054/300] Iteration[200/782] Loss: 0.3149 Acc:88.93%
Training: Epoch[054/300] Iteration[250/782] Loss: 0.3207 Acc:88.70%
Training: Epoch[054/300] Iteration[300/782] Loss: 0.3207 Acc:88.72%
Training: Epoch[054/300] Iteration[350/782] Loss: 0.3216 Acc:88.74%
Training: Epoch[054/300] Iteration[400/782] Loss: 0.3256 Acc:88.67%
Training: Epoch[054/300] Iteration[450/782] Loss: 0.3249 Acc:88.75%
Training: Epoch[054/300] Iteration[500/782] Loss: 0.3263 Acc:88.67%
Training: Epoch[054/300] Iteration[550/782] Loss: 0.3284 Acc:88.56%
Training: Epoch[054/300] Iteration[600/782] Loss: 0.3276 Acc:88.59%
Training: Epoch[054/300] Iteration[650/782] Loss: 0.3290 Acc:88.56%
Training: Epoch[054/300] Iteration[700/782] Loss: 0.3293 Acc:88.51%
Training: Epoch[054/300] Iteration[750/782] Loss: 0.3295 Acc:88.54%
Epoch[054/300] Train Acc: 88.49% Valid Acc:85.87% Train loss:0.3316 Valid loss:0.4212 LR:0.1
Training: Epoch[055/300] Iteration[050/782] Loss: 0.3266 Acc:89.44%
Training: Epoch[055/300] Iteration[100/782] Loss: 0.3091 Acc:89.52%
Training: Epoch[055/300] Iteration[150/782] Loss: 0.3106 Acc:89.42%
Training: Epoch[055/300] Iteration[200/782] Loss: 0.3152 Acc:89.23%
Training: Epoch[055/300] Iteration[250/782] Loss: 0.3178 Acc:89.18%
Training: Epoch[055/300] Iteration[300/782] Loss: 0.3212 Acc:88.99%
Training: Epoch[055/300] Iteration[350/782] Loss: 0.3249 Acc:88.81%
Training: Epoch[055/300] Iteration[400/782] Loss: 0.3247 Acc:88.78%
Training: Epoch[055/300] Iteration[450/782] Loss: 0.3220 Acc:88.92%
Training: Epoch[055/300] Iteration[500/782] Loss: 0.3235 Acc:88.82%
Training: Epoch[055/300] Iteration[550/782] Loss: 0.3252 Acc:88.80%
Training: Epoch[055/300] Iteration[600/782] Loss: 0.3276 Acc:88.68%
Training: Epoch[055/300] Iteration[650/782] Loss: 0.3281 Acc:88.66%
Training: Epoch[055/300] Iteration[700/782] Loss: 0.3279 Acc:88.68%
Training: Epoch[055/300] Iteration[750/782] Loss: 0.3268 Acc:88.71%
Epoch[055/300] Train Acc: 88.70% Valid Acc:84.27% Train loss:0.3284 Valid loss:0.4948 LR:0.1
Training: Epoch[056/300] Iteration[050/782] Loss: 0.3618 Acc:87.06%
Training: Epoch[056/300] Iteration[100/782] Loss: 0.3218 Acc:88.80%
Training: Epoch[056/300] Iteration[150/782] Loss: 0.3193 Acc:88.84%
Training: Epoch[056/300] Iteration[200/782] Loss: 0.3233 Acc:88.67%
Training: Epoch[056/300] Iteration[250/782] Loss: 0.3210 Acc:88.68%
Training: Epoch[056/300] Iteration[300/782] Loss: 0.3196 Acc:88.76%
Training: Epoch[056/300] Iteration[350/782] Loss: 0.3180 Acc:88.87%
Training: Epoch[056/300] Iteration[400/782] Loss: 0.3170 Acc:88.93%
Training: Epoch[056/300] Iteration[450/782] Loss: 0.3213 Acc:88.83%
Training: Epoch[056/300] Iteration[500/782] Loss: 0.3232 Acc:88.79%
Training: Epoch[056/300] Iteration[550/782] Loss: 0.3234 Acc:88.85%
Training: Epoch[056/300] Iteration[600/782] Loss: 0.3232 Acc:88.83%
Training: Epoch[056/300] Iteration[650/782] Loss: 0.3235 Acc:88.81%
Training: Epoch[056/300] Iteration[700/782] Loss: 0.3269 Acc:88.73%
Training: Epoch[056/300] Iteration[750/782] Loss: 0.3264 Acc:88.75%
Epoch[056/300] Train Acc: 88.73% Valid Acc:83.48% Train loss:0.3270 Valid loss:0.5157 LR:0.1
Training: Epoch[057/300] Iteration[050/782] Loss: 0.3170 Acc:89.25%
Training: Epoch[057/300] Iteration[100/782] Loss: 0.3090 Acc:89.44%
Training: Epoch[057/300] Iteration[150/782] Loss: 0.3116 Acc:89.24%
Training: Epoch[057/300] Iteration[200/782] Loss: 0.3147 Acc:89.29%
Training: Epoch[057/300] Iteration[250/782] Loss: 0.3196 Acc:89.07%
Training: Epoch[057/300] Iteration[300/782] Loss: 0.3194 Acc:89.01%
Training: Epoch[057/300] Iteration[350/782] Loss: 0.3222 Acc:88.94%
Training: Epoch[057/300] Iteration[400/782] Loss: 0.3226 Acc:88.86%
Training: Epoch[057/300] Iteration[450/782] Loss: 0.3241 Acc:88.75%
Training: Epoch[057/300] Iteration[500/782] Loss: 0.3249 Acc:88.70%
Training: Epoch[057/300] Iteration[550/782] Loss: 0.3263 Acc:88.71%
Training: Epoch[057/300] Iteration[600/782] Loss: 0.3253 Acc:88.74%
Training: Epoch[057/300] Iteration[650/782] Loss: 0.3260 Acc:88.67%
Training: Epoch[057/300] Iteration[700/782] Loss: 0.3268 Acc:88.67%
Training: Epoch[057/300] Iteration[750/782] Loss: 0.3275 Acc:88.66%
Epoch[057/300] Train Acc: 88.71% Valid Acc:85.29% Train loss:0.3261 Valid loss:0.4745 LR:0.1
Training: Epoch[058/300] Iteration[050/782] Loss: 0.2959 Acc:89.53%
Training: Epoch[058/300] Iteration[100/782] Loss: 0.3000 Acc:89.30%
Training: Epoch[058/300] Iteration[150/782] Loss: 0.3009 Acc:89.60%
Training: Epoch[058/300] Iteration[200/782] Loss: 0.3009 Acc:89.55%
Training: Epoch[058/300] Iteration[250/782] Loss: 0.3046 Acc:89.45%
Training: Epoch[058/300] Iteration[300/782] Loss: 0.3115 Acc:89.31%
Training: Epoch[058/300] Iteration[350/782] Loss: 0.3134 Acc:89.23%
Training: Epoch[058/300] Iteration[400/782] Loss: 0.3141 Acc:89.21%
Training: Epoch[058/300] Iteration[450/782] Loss: 0.3158 Acc:89.16%
Training: Epoch[058/300] Iteration[500/782] Loss: 0.3157 Acc:89.14%
Training: Epoch[058/300] Iteration[550/782] Loss: 0.3188 Acc:89.09%
Training: Epoch[058/300] Iteration[600/782] Loss: 0.3185 Acc:89.10%
Training: Epoch[058/300] Iteration[650/782] Loss: 0.3208 Acc:88.99%
Training: Epoch[058/300] Iteration[700/782] Loss: 0.3217 Acc:88.96%
Training: Epoch[058/300] Iteration[750/782] Loss: 0.3220 Acc:88.95%
Epoch[058/300] Train Acc: 88.96% Valid Acc:82.97% Train loss:0.3231 Valid loss:0.5244 LR:0.1
Training: Epoch[059/300] Iteration[050/782] Loss: 0.3268 Acc:89.00%
Training: Epoch[059/300] Iteration[100/782] Loss: 0.3308 Acc:88.70%
Training: Epoch[059/300] Iteration[150/782] Loss: 0.3155 Acc:89.14%
Training: Epoch[059/300] Iteration[200/782] Loss: 0.3136 Acc:89.26%
Training: Epoch[059/300] Iteration[250/782] Loss: 0.3073 Acc:89.42%
Training: Epoch[059/300] Iteration[300/782] Loss: 0.3091 Acc:89.24%
Training: Epoch[059/300] Iteration[350/782] Loss: 0.3121 Acc:89.17%
Training: Epoch[059/300] Iteration[400/782] Loss: 0.3162 Acc:89.12%
Training: Epoch[059/300] Iteration[450/782] Loss: 0.3195 Acc:88.99%
Training: Epoch[059/300] Iteration[500/782] Loss: 0.3196 Acc:88.99%
Training: Epoch[059/300] Iteration[550/782] Loss: 0.3204 Acc:88.97%
Training: Epoch[059/300] Iteration[600/782] Loss: 0.3194 Acc:88.99%
Training: Epoch[059/300] Iteration[650/782] Loss: 0.3198 Acc:88.97%
Training: Epoch[059/300] Iteration[700/782] Loss: 0.3230 Acc:88.86%
Training: Epoch[059/300] Iteration[750/782] Loss: 0.3245 Acc:88.76%
Epoch[059/300] Train Acc: 88.75% Valid Acc:85.02% Train loss:0.3258 Valid loss:0.4469 LR:0.1
Training: Epoch[060/300] Iteration[050/782] Loss: 0.3406 Acc:88.72%
Training: Epoch[060/300] Iteration[100/782] Loss: 0.3218 Acc:89.02%
Training: Epoch[060/300] Iteration[150/782] Loss: 0.3289 Acc:88.57%
Training: Epoch[060/300] Iteration[200/782] Loss: 0.3310 Acc:88.39%
Training: Epoch[060/300] Iteration[250/782] Loss: 0.3302 Acc:88.48%
Training: Epoch[060/300] Iteration[300/782] Loss: 0.3295 Acc:88.43%
Training: Epoch[060/300] Iteration[350/782] Loss: 0.3294 Acc:88.50%
Training: Epoch[060/300] Iteration[400/782] Loss: 0.3284 Acc:88.49%
Training: Epoch[060/300] Iteration[450/782] Loss: 0.3264 Acc:88.56%
Training: Epoch[060/300] Iteration[500/782] Loss: 0.3234 Acc:88.62%
Training: Epoch[060/300] Iteration[550/782] Loss: 0.3256 Acc:88.60%
Training: Epoch[060/300] Iteration[600/782] Loss: 0.3264 Acc:88.58%
Training: Epoch[060/300] Iteration[650/782] Loss: 0.3241 Acc:88.71%
Training: Epoch[060/300] Iteration[700/782] Loss: 0.3244 Acc:88.70%
Training: Epoch[060/300] Iteration[750/782] Loss: 0.3230 Acc:88.73%
Epoch[060/300] Train Acc: 88.66% Valid Acc:84.67% Train loss:0.3254 Valid loss:0.4662 LR:0.1
Training: Epoch[061/300] Iteration[050/782] Loss: 0.3561 Acc:87.47%
Training: Epoch[061/300] Iteration[100/782] Loss: 0.3318 Acc:88.34%
Training: Epoch[061/300] Iteration[150/782] Loss: 0.3306 Acc:88.36%
Training: Epoch[061/300] Iteration[200/782] Loss: 0.3271 Acc:88.65%
Training: Epoch[061/300] Iteration[250/782] Loss: 0.3236 Acc:88.79%
Training: Epoch[061/300] Iteration[300/782] Loss: 0.3280 Acc:88.62%
Training: Epoch[061/300] Iteration[350/782] Loss: 0.3264 Acc:88.63%
Training: Epoch[061/300] Iteration[400/782] Loss: 0.3271 Acc:88.59%
Training: Epoch[061/300] Iteration[450/782] Loss: 0.3271 Acc:88.64%
Training: Epoch[061/300] Iteration[500/782] Loss: 0.3271 Acc:88.64%
Training: Epoch[061/300] Iteration[550/782] Loss: 0.3250 Acc:88.76%
Training: Epoch[061/300] Iteration[600/782] Loss: 0.3236 Acc:88.79%
Training: Epoch[061/300] Iteration[650/782] Loss: 0.3220 Acc:88.87%
Training: Epoch[061/300] Iteration[700/782] Loss: 0.3234 Acc:88.84%
Training: Epoch[061/300] Iteration[750/782] Loss: 0.3245 Acc:88.78%
Epoch[061/300] Train Acc: 88.76% Valid Acc:88.01% Train loss:0.3251 Valid loss:0.3600 LR:0.1
Training: Epoch[062/300] Iteration[050/782] Loss: 0.3170 Acc:89.03%
Training: Epoch[062/300] Iteration[100/782] Loss: 0.3161 Acc:88.95%
Training: Epoch[062/300] Iteration[150/782] Loss: 0.3121 Acc:89.04%
Training: Epoch[062/300] Iteration[200/782] Loss: 0.3148 Acc:88.97%
Training: Epoch[062/300] Iteration[250/782] Loss: 0.3126 Acc:89.08%
Training: Epoch[062/300] Iteration[300/782] Loss: 0.3143 Acc:89.12%
Training: Epoch[062/300] Iteration[350/782] Loss: 0.3131 Acc:89.14%
Training: Epoch[062/300] Iteration[400/782] Loss: 0.3154 Acc:89.13%
Training: Epoch[062/300] Iteration[450/782] Loss: 0.3165 Acc:89.07%
Training: Epoch[062/300] Iteration[500/782] Loss: 0.3185 Acc:89.03%
Training: Epoch[062/300] Iteration[550/782] Loss: 0.3202 Acc:89.00%
Training: Epoch[062/300] Iteration[600/782] Loss: 0.3219 Acc:88.90%
Training: Epoch[062/300] Iteration[650/782] Loss: 0.3224 Acc:88.88%
Training: Epoch[062/300] Iteration[700/782] Loss: 0.3233 Acc:88.83%
Training: Epoch[062/300] Iteration[750/782] Loss: 0.3247 Acc:88.78%
Epoch[062/300] Train Acc: 88.77% Valid Acc:85.33% Train loss:0.3251 Valid loss:0.4391 LR:0.1
Training: Epoch[063/300] Iteration[050/782] Loss: 0.3291 Acc:89.31%
Training: Epoch[063/300] Iteration[100/782] Loss: 0.3235 Acc:89.19%
Training: Epoch[063/300] Iteration[150/782] Loss: 0.3192 Acc:89.25%
Training: Epoch[063/300] Iteration[200/782] Loss: 0.3179 Acc:88.91%
Training: Epoch[063/300] Iteration[250/782] Loss: 0.3176 Acc:88.80%
Training: Epoch[063/300] Iteration[300/782] Loss: 0.3164 Acc:88.81%
Training: Epoch[063/300] Iteration[350/782] Loss: 0.3166 Acc:88.80%
Training: Epoch[063/300] Iteration[400/782] Loss: 0.3167 Acc:88.90%
Training: Epoch[063/300] Iteration[450/782] Loss: 0.3188 Acc:88.83%
Training: Epoch[063/300] Iteration[500/782] Loss: 0.3195 Acc:88.82%
Training: Epoch[063/300] Iteration[550/782] Loss: 0.3212 Acc:88.74%
Training: Epoch[063/300] Iteration[600/782] Loss: 0.3244 Acc:88.65%
Training: Epoch[063/300] Iteration[650/782] Loss: 0.3253 Acc:88.63%
Training: Epoch[063/300] Iteration[700/782] Loss: 0.3236 Acc:88.71%
Training: Epoch[063/300] Iteration[750/782] Loss: 0.3224 Acc:88.74%
Epoch[063/300] Train Acc: 88.75% Valid Acc:85.03% Train loss:0.3232 Valid loss:0.4468 LR:0.1
Training: Epoch[064/300] Iteration[050/782] Loss: 0.2897 Acc:89.84%
Training: Epoch[064/300] Iteration[100/782] Loss: 0.2907 Acc:89.80%
Training: Epoch[064/300] Iteration[150/782] Loss: 0.2928 Acc:89.78%
Training: Epoch[064/300] Iteration[200/782] Loss: 0.2909 Acc:89.81%
Training: Epoch[064/300] Iteration[250/782] Loss: 0.2912 Acc:89.79%
Training: Epoch[064/300] Iteration[300/782] Loss: 0.2951 Acc:89.74%
Training: Epoch[064/300] Iteration[350/782] Loss: 0.3001 Acc:89.53%
Training: Epoch[064/300] Iteration[400/782] Loss: 0.3043 Acc:89.42%
Training: Epoch[064/300] Iteration[450/782] Loss: 0.3035 Acc:89.42%
Training: Epoch[064/300] Iteration[500/782] Loss: 0.3079 Acc:89.28%
Training: Epoch[064/300] Iteration[550/782] Loss: 0.3107 Acc:89.15%
Training: Epoch[064/300] Iteration[600/782] Loss: 0.3156 Acc:88.97%
Training: Epoch[064/300] Iteration[650/782] Loss: 0.3149 Acc:88.96%
Training: Epoch[064/300] Iteration[700/782] Loss: 0.3151 Acc:88.97%
Training: Epoch[064/300] Iteration[750/782] Loss: 0.3161 Acc:88.93%
Epoch[064/300] Train Acc: 88.88% Valid Acc:85.16% Train loss:0.3168 Valid loss:0.4517 LR:0.1
Training: Epoch[065/300] Iteration[050/782] Loss: 0.3214 Acc:89.22%
Training: Epoch[065/300] Iteration[100/782] Loss: 0.3118 Acc:89.30%
Training: Epoch[065/300] Iteration[150/782] Loss: 0.3104 Acc:89.23%
Training: Epoch[065/300] Iteration[200/782] Loss: 0.3139 Acc:89.06%
Training: Epoch[065/300] Iteration[250/782] Loss: 0.3141 Acc:89.06%
Training: Epoch[065/300] Iteration[300/782] Loss: 0.3133 Acc:89.05%
Training: Epoch[065/300] Iteration[350/782] Loss: 0.3145 Acc:89.06%
Training: Epoch[065/300] Iteration[400/782] Loss: 0.3151 Acc:89.05%
Training: Epoch[065/300] Iteration[450/782] Loss: 0.3147 Acc:89.09%
Training: Epoch[065/300] Iteration[500/782] Loss: 0.3188 Acc:88.93%
Training: Epoch[065/300] Iteration[550/782] Loss: 0.3180 Acc:88.97%
Training: Epoch[065/300] Iteration[600/782] Loss: 0.3199 Acc:88.86%
Training: Epoch[065/300] Iteration[650/782] Loss: 0.3193 Acc:88.92%
Training: Epoch[065/300] Iteration[700/782] Loss: 0.3206 Acc:88.85%
Training: Epoch[065/300] Iteration[750/782] Loss: 0.3201 Acc:88.85%
Epoch[065/300] Train Acc: 88.84% Valid Acc:84.67% Train loss:0.3213 Valid loss:0.4794 LR:0.1
Training: Epoch[066/300] Iteration[050/782] Loss: 0.3236 Acc:88.25%
Training: Epoch[066/300] Iteration[100/782] Loss: 0.3143 Acc:88.73%
Training: Epoch[066/300] Iteration[150/782] Loss: 0.3097 Acc:88.94%
Training: Epoch[066/300] Iteration[200/782] Loss: 0.3098 Acc:89.10%
Training: Epoch[066/300] Iteration[250/782] Loss: 0.3114 Acc:89.08%
Training: Epoch[066/300] Iteration[300/782] Loss: 0.3114 Acc:89.11%
Training: Epoch[066/300] Iteration[350/782] Loss: 0.3111 Acc:89.17%
Training: Epoch[066/300] Iteration[400/782] Loss: 0.3102 Acc:89.20%
Training: Epoch[066/300] Iteration[450/782] Loss: 0.3116 Acc:89.22%
Training: Epoch[066/300] Iteration[500/782] Loss: 0.3154 Acc:89.10%
Training: Epoch[066/300] Iteration[550/782] Loss: 0.3186 Acc:88.95%
Training: Epoch[066/300] Iteration[600/782] Loss: 0.3174 Acc:88.98%
Training: Epoch[066/300] Iteration[650/782] Loss: 0.3185 Acc:88.98%
Training: Epoch[066/300] Iteration[700/782] Loss: 0.3192 Acc:88.96%
Training: Epoch[066/300] Iteration[750/782] Loss: 0.3189 Acc:89.00%
Epoch[066/300] Train Acc: 89.03% Valid Acc:87.24% Train loss:0.3173 Valid loss:0.3853 LR:0.1
Training: Epoch[067/300] Iteration[050/782] Loss: 0.3006 Acc:90.03%
Training: Epoch[067/300] Iteration[100/782] Loss: 0.3020 Acc:89.64%
Training: Epoch[067/300] Iteration[150/782] Loss: 0.3028 Acc:89.51%
Training: Epoch[067/300] Iteration[200/782] Loss: 0.3109 Acc:89.04%
Training: Epoch[067/300] Iteration[250/782] Loss: 0.3059 Acc:89.29%
Training: Epoch[067/300] Iteration[300/782] Loss: 0.3096 Acc:89.11%
Training: Epoch[067/300] Iteration[350/782] Loss: 0.3124 Acc:88.93%
Training: Epoch[067/300] Iteration[400/782] Loss: 0.3142 Acc:88.88%
Training: Epoch[067/300] Iteration[450/782] Loss: 0.3138 Acc:88.91%
Training: Epoch[067/300] Iteration[500/782] Loss: 0.3143 Acc:88.91%
Training: Epoch[067/300] Iteration[550/782] Loss: 0.3140 Acc:88.98%
Training: Epoch[067/300] Iteration[600/782] Loss: 0.3153 Acc:88.98%
Training: Epoch[067/300] Iteration[650/782] Loss: 0.3158 Acc:88.97%
Training: Epoch[067/300] Iteration[700/782] Loss: 0.3149 Acc:89.00%
Training: Epoch[067/300] Iteration[750/782] Loss: 0.3164 Acc:88.98%
Epoch[067/300] Train Acc: 88.95% Valid Acc:83.59% Train loss:0.3181 Valid loss:0.5007 LR:0.1
Training: Epoch[068/300] Iteration[050/782] Loss: 0.3289 Acc:88.75%
Training: Epoch[068/300] Iteration[100/782] Loss: 0.3106 Acc:89.33%
Training: Epoch[068/300] Iteration[150/782] Loss: 0.2974 Acc:89.57%
Training: Epoch[068/300] Iteration[200/782] Loss: 0.3021 Acc:89.36%
Training: Epoch[068/300] Iteration[250/782] Loss: 0.3018 Acc:89.39%
Training: Epoch[068/300] Iteration[300/782] Loss: 0.3053 Acc:89.32%
Training: Epoch[068/300] Iteration[350/782] Loss: 0.3063 Acc:89.23%
Training: Epoch[068/300] Iteration[400/782] Loss: 0.3095 Acc:89.26%
Training: Epoch[068/300] Iteration[450/782] Loss: 0.3135 Acc:89.18%
Training: Epoch[068/300] Iteration[500/782] Loss: 0.3123 Acc:89.19%
Training: Epoch[068/300] Iteration[550/782] Loss: 0.3122 Acc:89.20%
Training: Epoch[068/300] Iteration[600/782] Loss: 0.3129 Acc:89.15%
Training: Epoch[068/300] Iteration[650/782] Loss: 0.3140 Acc:89.19%
Training: Epoch[068/300] Iteration[700/782] Loss: 0.3145 Acc:89.18%
Training: Epoch[068/300] Iteration[750/782] Loss: 0.3162 Acc:89.11%
Epoch[068/300] Train Acc: 89.12% Valid Acc:85.23% Train loss:0.3154 Valid loss:0.4544 LR:0.1
Training: Epoch[069/300] Iteration[050/782] Loss: 0.2931 Acc:90.22%
Training: Epoch[069/300] Iteration[100/782] Loss: 0.3025 Acc:89.62%
Training: Epoch[069/300] Iteration[150/782] Loss: 0.3109 Acc:89.50%
Training: Epoch[069/300] Iteration[200/782] Loss: 0.3104 Acc:89.34%
Training: Epoch[069/300] Iteration[250/782] Loss: 0.3056 Acc:89.40%
Training: Epoch[069/300] Iteration[300/782] Loss: 0.3018 Acc:89.52%
Training: Epoch[069/300] Iteration[350/782] Loss: 0.3059 Acc:89.38%
Training: Epoch[069/300] Iteration[400/782] Loss: 0.3122 Acc:89.23%
Training: Epoch[069/300] Iteration[450/782] Loss: 0.3140 Acc:89.09%
Training: Epoch[069/300] Iteration[500/782] Loss: 0.3145 Acc:89.04%
Training: Epoch[069/300] Iteration[550/782] Loss: 0.3141 Acc:89.05%
Training: Epoch[069/300] Iteration[600/782] Loss: 0.3154 Acc:88.99%
Training: Epoch[069/300] Iteration[650/782] Loss: 0.3166 Acc:88.93%
Training: Epoch[069/300] Iteration[700/782] Loss: 0.3169 Acc:88.95%
Training: Epoch[069/300] Iteration[750/782] Loss: 0.3154 Acc:89.04%
Epoch[069/300] Train Acc: 88.99% Valid Acc:85.82% Train loss:0.3166 Valid loss:0.4388 LR:0.1
Training: Epoch[070/300] Iteration[050/782] Loss: 0.3020 Acc:89.66%
Training: Epoch[070/300] Iteration[100/782] Loss: 0.2936 Acc:89.98%
Training: Epoch[070/300] Iteration[150/782] Loss: 0.2994 Acc:89.59%
Training: Epoch[070/300] Iteration[200/782] Loss: 0.3065 Acc:89.44%
Training: Epoch[070/300] Iteration[250/782] Loss: 0.3036 Acc:89.55%
Training: Epoch[070/300] Iteration[300/782] Loss: 0.3054 Acc:89.39%
Training: Epoch[070/300] Iteration[350/782] Loss: 0.3077 Acc:89.34%
Training: Epoch[070/300] Iteration[400/782] Loss: 0.3083 Acc:89.32%
Training: Epoch[070/300] Iteration[450/782] Loss: 0.3093 Acc:89.28%
Training: Epoch[070/300] Iteration[500/782] Loss: 0.3098 Acc:89.22%
Training: Epoch[070/300] Iteration[550/782] Loss: 0.3088 Acc:89.28%
Training: Epoch[070/300] Iteration[600/782] Loss: 0.3101 Acc:89.22%
Training: Epoch[070/300] Iteration[650/782] Loss: 0.3110 Acc:89.15%
Training: Epoch[070/300] Iteration[700/782] Loss: 0.3124 Acc:89.13%
Training: Epoch[070/300] Iteration[750/782] Loss: 0.3113 Acc:89.18%
Epoch[070/300] Train Acc: 89.15% Valid Acc:86.95% Train loss:0.3134 Valid loss:0.3883 LR:0.1
Training: Epoch[071/300] Iteration[050/782] Loss: 0.3271 Acc:89.34%
Training: Epoch[071/300] Iteration[100/782] Loss: 0.3026 Acc:89.98%
Training: Epoch[071/300] Iteration[150/782] Loss: 0.3012 Acc:89.89%
Training: Epoch[071/300] Iteration[200/782] Loss: 0.3006 Acc:89.88%
Training: Epoch[071/300] Iteration[250/782] Loss: 0.3029 Acc:89.73%
Training: Epoch[071/300] Iteration[300/782] Loss: 0.3050 Acc:89.59%
Training: Epoch[071/300] Iteration[350/782] Loss: 0.3077 Acc:89.43%
Training: Epoch[071/300] Iteration[400/782] Loss: 0.3071 Acc:89.44%
Training: Epoch[071/300] Iteration[450/782] Loss: 0.3093 Acc:89.34%
Training: Epoch[071/300] Iteration[500/782] Loss: 0.3102 Acc:89.33%
Training: Epoch[071/300] Iteration[550/782] Loss: 0.3105 Acc:89.31%
Training: Epoch[071/300] Iteration[600/782] Loss: 0.3098 Acc:89.34%
Training: Epoch[071/300] Iteration[650/782] Loss: 0.3095 Acc:89.36%
Training: Epoch[071/300] Iteration[700/782] Loss: 0.3105 Acc:89.30%
Training: Epoch[071/300] Iteration[750/782] Loss: 0.3108 Acc:89.31%
Epoch[071/300] Train Acc: 89.29% Valid Acc:86.96% Train loss:0.3114 Valid loss:0.4198 LR:0.1
Training: Epoch[072/300] Iteration[050/782] Loss: 0.2976 Acc:89.53%
Training: Epoch[072/300] Iteration[100/782] Loss: 0.3005 Acc:89.25%
Training: Epoch[072/300] Iteration[150/782] Loss: 0.3051 Acc:89.14%
Training: Epoch[072/300] Iteration[200/782] Loss: 0.3087 Acc:89.10%
Training: Epoch[072/300] Iteration[250/782] Loss: 0.3075 Acc:89.20%
Training: Epoch[072/300] Iteration[300/782] Loss: 0.3083 Acc:89.18%
Training: Epoch[072/300] Iteration[350/782] Loss: 0.3102 Acc:89.16%
Training: Epoch[072/300] Iteration[400/782] Loss: 0.3095 Acc:89.21%
Training: Epoch[072/300] Iteration[450/782] Loss: 0.3119 Acc:89.13%
Training: Epoch[072/300] Iteration[500/782] Loss: 0.3110 Acc:89.13%
Training: Epoch[072/300] Iteration[550/782] Loss: 0.3114 Acc:89.13%
Training: Epoch[072/300] Iteration[600/782] Loss: 0.3128 Acc:89.07%
Training: Epoch[072/300] Iteration[650/782] Loss: 0.3140 Acc:89.05%
Training: Epoch[072/300] Iteration[700/782] Loss: 0.3150 Acc:89.01%
Training: Epoch[072/300] Iteration[750/782] Loss: 0.3155 Acc:88.99%
Epoch[072/300] Train Acc: 89.04% Valid Acc:87.23% Train loss:0.3143 Valid loss:0.3784 LR:0.1
Training: Epoch[073/300] Iteration[050/782] Loss: 0.2860 Acc:90.12%
Training: Epoch[073/300] Iteration[100/782] Loss: 0.2902 Acc:89.77%
Training: Epoch[073/300] Iteration[150/782] Loss: 0.3011 Acc:89.50%
Training: Epoch[073/300] Iteration[200/782] Loss: 0.3069 Acc:89.22%
Training: Epoch[073/300] Iteration[250/782] Loss: 0.3090 Acc:89.25%
Training: Epoch[073/300] Iteration[300/782] Loss: 0.3138 Acc:89.04%
Training: Epoch[073/300] Iteration[350/782] Loss: 0.3117 Acc:89.14%
Training: Epoch[073/300] Iteration[400/782] Loss: 0.3102 Acc:89.21%
Training: Epoch[073/300] Iteration[450/782] Loss: 0.3092 Acc:89.24%
Training: Epoch[073/300] Iteration[500/782] Loss: 0.3066 Acc:89.31%
Training: Epoch[073/300] Iteration[550/782] Loss: 0.3101 Acc:89.16%
Training: Epoch[073/300] Iteration[600/782] Loss: 0.3119 Acc:89.07%
Training: Epoch[073/300] Iteration[650/782] Loss: 0.3123 Acc:89.07%
Training: Epoch[073/300] Iteration[700/782] Loss: 0.3138 Acc:89.04%
Training: Epoch[073/300] Iteration[750/782] Loss: 0.3130 Acc:89.07%
Epoch[073/300] Train Acc: 89.08% Valid Acc:87.02% Train loss:0.3132 Valid loss:0.3843 LR:0.1
Training: Epoch[074/300] Iteration[050/782] Loss: 0.3029 Acc:89.84%
Training: Epoch[074/300] Iteration[100/782] Loss: 0.2998 Acc:89.69%
Training: Epoch[074/300] Iteration[150/782] Loss: 0.2908 Acc:89.84%
Training: Epoch[074/300] Iteration[200/782] Loss: 0.2944 Acc:89.73%
Training: Epoch[074/300] Iteration[250/782] Loss: 0.2930 Acc:89.83%
Training: Epoch[074/300] Iteration[300/782] Loss: 0.2937 Acc:89.86%
Training: Epoch[074/300] Iteration[350/782] Loss: 0.2913 Acc:89.91%
Training: Epoch[074/300] Iteration[400/782] Loss: 0.2994 Acc:89.61%
Training: Epoch[074/300] Iteration[450/782] Loss: 0.3018 Acc:89.51%
Training: Epoch[074/300] Iteration[500/782] Loss: 0.3040 Acc:89.46%
Training: Epoch[074/300] Iteration[550/782] Loss: 0.3064 Acc:89.38%
Training: Epoch[074/300] Iteration[600/782] Loss: 0.3060 Acc:89.40%
Training: Epoch[074/300] Iteration[650/782] Loss: 0.3081 Acc:89.33%
Training: Epoch[074/300] Iteration[700/782] Loss: 0.3089 Acc:89.29%
Training: Epoch[074/300] Iteration[750/782] Loss: 0.3092 Acc:89.29%
Epoch[074/300] Train Acc: 89.25% Valid Acc:85.61% Train loss:0.3093 Valid loss:0.4530 LR:0.1
Training: Epoch[075/300] Iteration[050/782] Loss: 0.2836 Acc:90.12%
Training: Epoch[075/300] Iteration[100/782] Loss: 0.2850 Acc:90.09%
Training: Epoch[075/300] Iteration[150/782] Loss: 0.2887 Acc:89.90%
Training: Epoch[075/300] Iteration[200/782] Loss: 0.2952 Acc:89.65%
Training: Epoch[075/300] Iteration[250/782] Loss: 0.2999 Acc:89.49%
Training: Epoch[075/300] Iteration[300/782] Loss: 0.2991 Acc:89.47%
Training: Epoch[075/300] Iteration[350/782] Loss: 0.3034 Acc:89.35%
Training: Epoch[075/300] Iteration[400/782] Loss: 0.3079 Acc:89.27%
Training: Epoch[075/300] Iteration[450/782] Loss: 0.3068 Acc:89.32%
Training: Epoch[075/300] Iteration[500/782] Loss: 0.3090 Acc:89.35%
Training: Epoch[075/300] Iteration[550/782] Loss: 0.3091 Acc:89.36%
Training: Epoch[075/300] Iteration[600/782] Loss: 0.3088 Acc:89.34%
Training: Epoch[075/300] Iteration[650/782] Loss: 0.3080 Acc:89.35%
Training: Epoch[075/300] Iteration[700/782] Loss: 0.3071 Acc:89.38%
Training: Epoch[075/300] Iteration[750/782] Loss: 0.3087 Acc:89.34%
Epoch[075/300] Train Acc: 89.29% Valid Acc:86.64% Train loss:0.3104 Valid loss:0.4092 LR:0.1
Training: Epoch[076/300] Iteration[050/782] Loss: 0.3450 Acc:88.59%
Training: Epoch[076/300] Iteration[100/782] Loss: 0.3269 Acc:88.81%
Training: Epoch[076/300] Iteration[150/782] Loss: 0.3311 Acc:88.77%
Training: Epoch[076/300] Iteration[200/782] Loss: 0.3244 Acc:89.10%
Training: Epoch[076/300] Iteration[250/782] Loss: 0.3179 Acc:89.29%
Training: Epoch[076/300] Iteration[300/782] Loss: 0.3159 Acc:89.21%
Training: Epoch[076/300] Iteration[350/782] Loss: 0.3149 Acc:89.19%
Training: Epoch[076/300] Iteration[400/782] Loss: 0.3172 Acc:89.14%
Training: Epoch[076/300] Iteration[450/782] Loss: 0.3174 Acc:89.05%
Training: Epoch[076/300] Iteration[500/782] Loss: 0.3155 Acc:89.10%
Training: Epoch[076/300] Iteration[550/782] Loss: 0.3159 Acc:89.04%
Training: Epoch[076/300] Iteration[600/782] Loss: 0.3158 Acc:88.98%
Training: Epoch[076/300] Iteration[650/782] Loss: 0.3165 Acc:88.97%
Training: Epoch[076/300] Iteration[700/782] Loss: 0.3165 Acc:88.96%
Training: Epoch[076/300] Iteration[750/782] Loss: 0.3142 Acc:89.07%
Epoch[076/300] Train Acc: 89.11% Valid Acc:85.72% Train loss:0.3141 Valid loss:0.4570 LR:0.1
Training: Epoch[077/300] Iteration[050/782] Loss: 0.3246 Acc:88.78%
Training: Epoch[077/300] Iteration[100/782] Loss: 0.3085 Acc:89.28%
Training: Epoch[077/300] Iteration[150/782] Loss: 0.3007 Acc:89.59%
Training: Epoch[077/300] Iteration[200/782] Loss: 0.3059 Acc:89.41%
Training: Epoch[077/300] Iteration[250/782] Loss: 0.3086 Acc:89.30%
Training: Epoch[077/300] Iteration[300/782] Loss: 0.3086 Acc:89.29%
Training: Epoch[077/300] Iteration[350/782] Loss: 0.3078 Acc:89.33%
Training: Epoch[077/300] Iteration[400/782] Loss: 0.3044 Acc:89.44%
Training: Epoch[077/300] Iteration[450/782] Loss: 0.3070 Acc:89.34%
Training: Epoch[077/300] Iteration[500/782] Loss: 0.3099 Acc:89.21%
Training: Epoch[077/300] Iteration[550/782] Loss: 0.3124 Acc:89.13%
Training: Epoch[077/300] Iteration[600/782] Loss: 0.3107 Acc:89.21%
Training: Epoch[077/300] Iteration[650/782] Loss: 0.3097 Acc:89.29%
Training: Epoch[077/300] Iteration[700/782] Loss: 0.3110 Acc:89.30%
Training: Epoch[077/300] Iteration[750/782] Loss: 0.3113 Acc:89.27%
Epoch[077/300] Train Acc: 89.31% Valid Acc:86.08% Train loss:0.3107 Valid loss:0.4448 LR:0.1
Training: Epoch[078/300] Iteration[050/782] Loss: 0.3415 Acc:88.72%
Training: Epoch[078/300] Iteration[100/782] Loss: 0.3286 Acc:88.83%
Training: Epoch[078/300] Iteration[150/782] Loss: 0.3243 Acc:89.06%
Training: Epoch[078/300] Iteration[200/782] Loss: 0.3194 Acc:89.26%
Training: Epoch[078/300] Iteration[250/782] Loss: 0.3130 Acc:89.42%
Training: Epoch[078/300] Iteration[300/782] Loss: 0.3043 Acc:89.64%
Training: Epoch[078/300] Iteration[350/782] Loss: 0.3039 Acc:89.62%
Training: Epoch[078/300] Iteration[400/782] Loss: 0.3029 Acc:89.61%
Training: Epoch[078/300] Iteration[450/782] Loss: 0.3050 Acc:89.60%
Training: Epoch[078/300] Iteration[500/782] Loss: 0.3054 Acc:89.59%
Training: Epoch[078/300] Iteration[550/782] Loss: 0.3072 Acc:89.57%
Training: Epoch[078/300] Iteration[600/782] Loss: 0.3077 Acc:89.54%
Training: Epoch[078/300] Iteration[650/782] Loss: 0.3086 Acc:89.52%
Training: Epoch[078/300] Iteration[700/782] Loss: 0.3092 Acc:89.51%
Training: Epoch[078/300] Iteration[750/782] Loss: 0.3100 Acc:89.50%
Epoch[078/300] Train Acc: 89.44% Valid Acc:85.56% Train loss:0.3113 Valid loss:0.4510 LR:0.1
Training: Epoch[079/300] Iteration[050/782] Loss: 0.2987 Acc:89.75%
Training: Epoch[079/300] Iteration[100/782] Loss: 0.3018 Acc:89.55%
Training: Epoch[079/300] Iteration[150/782] Loss: 0.2996 Acc:89.59%
Training: Epoch[079/300] Iteration[200/782] Loss: 0.2921 Acc:89.92%
Training: Epoch[079/300] Iteration[250/782] Loss: 0.2900 Acc:90.01%
Training: Epoch[079/300] Iteration[300/782] Loss: 0.2923 Acc:89.88%
Training: Epoch[079/300] Iteration[350/782] Loss: 0.2918 Acc:89.83%
Training: Epoch[079/300] Iteration[400/782] Loss: 0.2984 Acc:89.61%
Training: Epoch[079/300] Iteration[450/782] Loss: 0.3014 Acc:89.51%
Training: Epoch[079/300] Iteration[500/782] Loss: 0.3022 Acc:89.47%
Training: Epoch[079/300] Iteration[550/782] Loss: 0.3041 Acc:89.39%
Training: Epoch[079/300] Iteration[600/782] Loss: 0.3047 Acc:89.37%
Training: Epoch[079/300] Iteration[650/782] Loss: 0.3032 Acc:89.44%
Training: Epoch[079/300] Iteration[700/782] Loss: 0.3024 Acc:89.51%
Training: Epoch[079/300] Iteration[750/782] Loss: 0.3035 Acc:89.48%
Epoch[079/300] Train Acc: 89.46% Valid Acc:86.87% Train loss:0.3035 Valid loss:0.4110 LR:0.1
Training: Epoch[080/300] Iteration[050/782] Loss: 0.2848 Acc:89.75%
Training: Epoch[080/300] Iteration[100/782] Loss: 0.2930 Acc:89.64%
Training: Epoch[080/300] Iteration[150/782] Loss: 0.2930 Acc:89.72%
Training: Epoch[080/300] Iteration[200/782] Loss: 0.2895 Acc:89.94%
Training: Epoch[080/300] Iteration[250/782] Loss: 0.2928 Acc:89.86%
Training: Epoch[080/300] Iteration[300/782] Loss: 0.2932 Acc:89.79%
Training: Epoch[080/300] Iteration[350/782] Loss: 0.2975 Acc:89.66%
Training: Epoch[080/300] Iteration[400/782] Loss: 0.2990 Acc:89.54%
Training: Epoch[080/300] Iteration[450/782] Loss: 0.3025 Acc:89.41%
Training: Epoch[080/300] Iteration[500/782] Loss: 0.3023 Acc:89.44%
Training: Epoch[080/300] Iteration[550/782] Loss: 0.3010 Acc:89.47%
Training: Epoch[080/300] Iteration[600/782] Loss: 0.3022 Acc:89.43%
Training: Epoch[080/300] Iteration[650/782] Loss: 0.3055 Acc:89.31%
Training: Epoch[080/300] Iteration[700/782] Loss: 0.3075 Acc:89.24%
Training: Epoch[080/300] Iteration[750/782] Loss: 0.3064 Acc:89.30%
Epoch[080/300] Train Acc: 89.31% Valid Acc:85.35% Train loss:0.3075 Valid loss:0.4342 LR:0.1
Training: Epoch[081/300] Iteration[050/782] Loss: 0.3175 Acc:89.16%
Training: Epoch[081/300] Iteration[100/782] Loss: 0.3169 Acc:89.09%
Training: Epoch[081/300] Iteration[150/782] Loss: 0.3161 Acc:88.99%
Training: Epoch[081/300] Iteration[200/782] Loss: 0.3165 Acc:89.02%
Training: Epoch[081/300] Iteration[250/782] Loss: 0.3142 Acc:89.16%
Training: Epoch[081/300] Iteration[300/782] Loss: 0.3100 Acc:89.37%
Training: Epoch[081/300] Iteration[350/782] Loss: 0.3084 Acc:89.38%
Training: Epoch[081/300] Iteration[400/782] Loss: 0.3106 Acc:89.29%
Training: Epoch[081/300] Iteration[450/782] Loss: 0.3080 Acc:89.44%
Training: Epoch[081/300] Iteration[500/782] Loss: 0.3062 Acc:89.53%
Training: Epoch[081/300] Iteration[550/782] Loss: 0.3038 Acc:89.53%
Training: Epoch[081/300] Iteration[600/782] Loss: 0.3051 Acc:89.40%
Training: Epoch[081/300] Iteration[650/782] Loss: 0.3051 Acc:89.44%
Training: Epoch[081/300] Iteration[700/782] Loss: 0.3059 Acc:89.43%
Training: Epoch[081/300] Iteration[750/782] Loss: 0.3059 Acc:89.41%
Epoch[081/300] Train Acc: 89.44% Valid Acc:86.99% Train loss:0.3055 Valid loss:0.3867 LR:0.1
Training: Epoch[082/300] Iteration[050/782] Loss: 0.2636 Acc:90.84%
Training: Epoch[082/300] Iteration[100/782] Loss: 0.2785 Acc:90.33%
Training: Epoch[082/300] Iteration[150/782] Loss: 0.2874 Acc:89.88%
Training: Epoch[082/300] Iteration[200/782] Loss: 0.2882 Acc:89.91%
Training: Epoch[082/300] Iteration[250/782] Loss: 0.2916 Acc:89.92%
Training: Epoch[082/300] Iteration[300/782] Loss: 0.2954 Acc:89.77%
Training: Epoch[082/300] Iteration[350/782] Loss: 0.2974 Acc:89.73%
Training: Epoch[082/300] Iteration[400/782] Loss: 0.2975 Acc:89.74%
Training: Epoch[082/300] Iteration[450/782] Loss: 0.2975 Acc:89.73%
Training: Epoch[082/300] Iteration[500/782] Loss: 0.3008 Acc:89.62%
Training: Epoch[082/300] Iteration[550/782] Loss: 0.3024 Acc:89.59%
Training: Epoch[082/300] Iteration[600/782] Loss: 0.3061 Acc:89.47%
Training: Epoch[082/300] Iteration[650/782] Loss: 0.3063 Acc:89.47%
Training: Epoch[082/300] Iteration[700/782] Loss: 0.3077 Acc:89.43%
Training: Epoch[082/300] Iteration[750/782] Loss: 0.3081 Acc:89.39%
Epoch[082/300] Train Acc: 89.38% Valid Acc:85.87% Train loss:0.3094 Valid loss:0.4539 LR:0.1
Training: Epoch[083/300] Iteration[050/782] Loss: 0.3332 Acc:88.91%
Training: Epoch[083/300] Iteration[100/782] Loss: 0.3089 Acc:89.55%
Training: Epoch[083/300] Iteration[150/782] Loss: 0.3056 Acc:89.74%
Training: Epoch[083/300] Iteration[200/782] Loss: 0.3035 Acc:89.81%
Training: Epoch[083/300] Iteration[250/782] Loss: 0.3008 Acc:89.77%
Training: Epoch[083/300] Iteration[300/782] Loss: 0.3065 Acc:89.53%
Training: Epoch[083/300] Iteration[350/782] Loss: 0.3062 Acc:89.56%
Training: Epoch[083/300] Iteration[400/782] Loss: 0.3022 Acc:89.71%
Training: Epoch[083/300] Iteration[450/782] Loss: 0.3040 Acc:89.59%
Training: Epoch[083/300] Iteration[500/782] Loss: 0.3067 Acc:89.49%
Training: Epoch[083/300] Iteration[550/782] Loss: 0.3067 Acc:89.45%
Training: Epoch[083/300] Iteration[600/782] Loss: 0.3073 Acc:89.40%
Training: Epoch[083/300] Iteration[650/782] Loss: 0.3091 Acc:89.32%
Training: Epoch[083/300] Iteration[700/782] Loss: 0.3074 Acc:89.40%
Training: Epoch[083/300] Iteration[750/782] Loss: 0.3053 Acc:89.49%
Epoch[083/300] Train Acc: 89.51% Valid Acc:86.34% Train loss:0.3060 Valid loss:0.4213 LR:0.1
Training: Epoch[084/300] Iteration[050/782] Loss: 0.3558 Acc:88.00%
Training: Epoch[084/300] Iteration[100/782] Loss: 0.3158 Acc:89.36%
Training: Epoch[084/300] Iteration[150/782] Loss: 0.3222 Acc:89.27%
Training: Epoch[084/300] Iteration[200/782] Loss: 0.3178 Acc:89.34%
Training: Epoch[084/300] Iteration[250/782] Loss: 0.3133 Acc:89.34%
Training: Epoch[084/300] Iteration[300/782] Loss: 0.3142 Acc:89.31%
Training: Epoch[084/300] Iteration[350/782] Loss: 0.3118 Acc:89.33%
Training: Epoch[084/300] Iteration[400/782] Loss: 0.3108 Acc:89.30%
Training: Epoch[084/300] Iteration[450/782] Loss: 0.3099 Acc:89.27%
Training: Epoch[084/300] Iteration[500/782] Loss: 0.3098 Acc:89.28%
Training: Epoch[084/300] Iteration[550/782] Loss: 0.3096 Acc:89.25%
Training: Epoch[084/300] Iteration[600/782] Loss: 0.3130 Acc:89.18%
Training: Epoch[084/300] Iteration[650/782] Loss: 0.3123 Acc:89.18%
Training: Epoch[084/300] Iteration[700/782] Loss: 0.3120 Acc:89.22%
Training: Epoch[084/300] Iteration[750/782] Loss: 0.3118 Acc:89.24%
Epoch[084/300] Train Acc: 89.22% Valid Acc:86.76% Train loss:0.3120 Valid loss:0.4096 LR:0.1
Training: Epoch[085/300] Iteration[050/782] Loss: 0.2723 Acc:90.94%
Training: Epoch[085/300] Iteration[100/782] Loss: 0.2845 Acc:90.28%
Training: Epoch[085/300] Iteration[150/782] Loss: 0.2847 Acc:90.26%
Training: Epoch[085/300] Iteration[200/782] Loss: 0.2924 Acc:89.87%
Training: Epoch[085/300] Iteration[250/782] Loss: 0.3030 Acc:89.69%
Training: Epoch[085/300] Iteration[300/782] Loss: 0.3037 Acc:89.63%
Training: Epoch[085/300] Iteration[350/782] Loss: 0.3031 Acc:89.62%
Training: Epoch[085/300] Iteration[400/782] Loss: 0.3021 Acc:89.64%
Training: Epoch[085/300] Iteration[450/782] Loss: 0.3012 Acc:89.68%
Training: Epoch[085/300] Iteration[500/782] Loss: 0.2986 Acc:89.74%
Training: Epoch[085/300] Iteration[550/782] Loss: 0.3003 Acc:89.62%
Training: Epoch[085/300] Iteration[600/782] Loss: 0.3012 Acc:89.57%
Training: Epoch[085/300] Iteration[650/782] Loss: 0.3025 Acc:89.53%
Training: Epoch[085/300] Iteration[700/782] Loss: 0.3053 Acc:89.47%
Training: Epoch[085/300] Iteration[750/782] Loss: 0.3051 Acc:89.45%
Epoch[085/300] Train Acc: 89.47% Valid Acc:83.23% Train loss:0.3045 Valid loss:0.5336 LR:0.1
Training: Epoch[086/300] Iteration[050/782] Loss: 0.2914 Acc:90.06%
Training: Epoch[086/300] Iteration[100/782] Loss: 0.3036 Acc:89.36%
Training: Epoch[086/300] Iteration[150/782] Loss: 0.3058 Acc:89.18%
Training: Epoch[086/300] Iteration[200/782] Loss: 0.3008 Acc:89.52%
Training: Epoch[086/300] Iteration[250/782] Loss: 0.3004 Acc:89.48%
Training: Epoch[086/300] Iteration[300/782] Loss: 0.3033 Acc:89.30%
Training: Epoch[086/300] Iteration[350/782] Loss: 0.3032 Acc:89.32%
Training: Epoch[086/300] Iteration[400/782] Loss: 0.3017 Acc:89.39%
Training: Epoch[086/300] Iteration[450/782] Loss: 0.3004 Acc:89.44%
Training: Epoch[086/300] Iteration[500/782] Loss: 0.3015 Acc:89.41%
Training: Epoch[086/300] Iteration[550/782] Loss: 0.3029 Acc:89.38%
Training: Epoch[086/300] Iteration[600/782] Loss: 0.3035 Acc:89.32%
Training: Epoch[086/300] Iteration[650/782] Loss: 0.3046 Acc:89.33%
Training: Epoch[086/300] Iteration[700/782] Loss: 0.3061 Acc:89.29%
Training: Epoch[086/300] Iteration[750/782] Loss: 0.3061 Acc:89.26%
Epoch[086/300] Train Acc: 89.26% Valid Acc:85.82% Train loss:0.3076 Valid loss:0.4391 LR:0.1
Training: Epoch[087/300] Iteration[050/782] Loss: 0.2964 Acc:89.75%
Training: Epoch[087/300] Iteration[100/782] Loss: 0.2979 Acc:89.81%
Training: Epoch[087/300] Iteration[150/782] Loss: 0.2928 Acc:89.97%
Training: Epoch[087/300] Iteration[200/782] Loss: 0.2966 Acc:89.87%
Training: Epoch[087/300] Iteration[250/782] Loss: 0.3000 Acc:89.76%
Training: Epoch[087/300] Iteration[300/782] Loss: 0.2995 Acc:89.69%
Training: Epoch[087/300] Iteration[350/782] Loss: 0.2987 Acc:89.75%
Training: Epoch[087/300] Iteration[400/782] Loss: 0.2970 Acc:89.80%
Training: Epoch[087/300] Iteration[450/782] Loss: 0.2983 Acc:89.71%
Training: Epoch[087/300] Iteration[500/782] Loss: 0.2975 Acc:89.76%
Training: Epoch[087/300] Iteration[550/782] Loss: 0.3015 Acc:89.66%
Training: Epoch[087/300] Iteration[600/782] Loss: 0.3014 Acc:89.64%
Training: Epoch[087/300] Iteration[650/782] Loss: 0.3035 Acc:89.60%
Training: Epoch[087/300] Iteration[700/782] Loss: 0.3046 Acc:89.51%
Training: Epoch[087/300] Iteration[750/782] Loss: 0.3039 Acc:89.51%
Epoch[087/300] Train Acc: 89.49% Valid Acc:86.62% Train loss:0.3052 Valid loss:0.4161 LR:0.1
Training: Epoch[088/300] Iteration[050/782] Loss: 0.2856 Acc:89.78%
Training: Epoch[088/300] Iteration[100/782] Loss: 0.2936 Acc:89.55%
Training: Epoch[088/300] Iteration[150/782] Loss: 0.2993 Acc:89.57%
Training: Epoch[088/300] Iteration[200/782] Loss: 0.2959 Acc:89.79%
Training: Epoch[088/300] Iteration[250/782] Loss: 0.2946 Acc:89.84%
Training: Epoch[088/300] Iteration[300/782] Loss: 0.2929 Acc:89.83%
Training: Epoch[088/300] Iteration[350/782] Loss: 0.2967 Acc:89.72%
Training: Epoch[088/300] Iteration[400/782] Loss: 0.2963 Acc:89.78%
Training: Epoch[088/300] Iteration[450/782] Loss: 0.2964 Acc:89.73%
Training: Epoch[088/300] Iteration[500/782] Loss: 0.2990 Acc:89.66%
Training: Epoch[088/300] Iteration[550/782] Loss: 0.3017 Acc:89.56%
Training: Epoch[088/300] Iteration[600/782] Loss: 0.3021 Acc:89.54%
Training: Epoch[088/300] Iteration[650/782] Loss: 0.3043 Acc:89.46%
Training: Epoch[088/300] Iteration[700/782] Loss: 0.3032 Acc:89.53%
Training: Epoch[088/300] Iteration[750/782] Loss: 0.3032 Acc:89.54%
Epoch[088/300] Train Acc: 89.54% Valid Acc:87.28% Train loss:0.3038 Valid loss:0.3903 LR:0.1
Training: Epoch[089/300] Iteration[050/782] Loss: 0.3129 Acc:89.12%
Training: Epoch[089/300] Iteration[100/782] Loss: 0.3103 Acc:89.61%
Training: Epoch[089/300] Iteration[150/782] Loss: 0.3110 Acc:89.36%
Training: Epoch[089/300] Iteration[200/782] Loss: 0.3076 Acc:89.33%
Training: Epoch[089/300] Iteration[250/782] Loss: 0.3064 Acc:89.40%
Training: Epoch[089/300] Iteration[300/782] Loss: 0.3042 Acc:89.46%
Training: Epoch[089/300] Iteration[350/782] Loss: 0.3018 Acc:89.59%
Training: Epoch[089/300] Iteration[400/782] Loss: 0.3015 Acc:89.58%
Training: Epoch[089/300] Iteration[450/782] Loss: 0.3028 Acc:89.47%
Training: Epoch[089/300] Iteration[500/782] Loss: 0.3024 Acc:89.50%
Training: Epoch[089/300] Iteration[550/782] Loss: 0.3025 Acc:89.54%
Training: Epoch[089/300] Iteration[600/782] Loss: 0.3030 Acc:89.55%
Training: Epoch[089/300] Iteration[650/782] Loss: 0.3058 Acc:89.48%
Training: Epoch[089/300] Iteration[700/782] Loss: 0.3068 Acc:89.47%
Training: Epoch[089/300] Iteration[750/782] Loss: 0.3059 Acc:89.49%
Epoch[089/300] Train Acc: 89.50% Valid Acc:84.75% Train loss:0.3052 Valid loss:0.4684 LR:0.1
Training: Epoch[090/300] Iteration[050/782] Loss: 0.3008 Acc:89.19%
Training: Epoch[090/300] Iteration[100/782] Loss: 0.3117 Acc:89.31%
Training: Epoch[090/300] Iteration[150/782] Loss: 0.3178 Acc:89.12%
Training: Epoch[090/300] Iteration[200/782] Loss: 0.3147 Acc:89.35%
Training: Epoch[090/300] Iteration[250/782] Loss: 0.3081 Acc:89.40%
Training: Epoch[090/300] Iteration[300/782] Loss: 0.3024 Acc:89.66%
Training: Epoch[090/300] Iteration[350/782] Loss: 0.3031 Acc:89.58%
Training: Epoch[090/300] Iteration[400/782] Loss: 0.3031 Acc:89.52%
Training: Epoch[090/300] Iteration[450/782] Loss: 0.3043 Acc:89.47%
Training: Epoch[090/300] Iteration[500/782] Loss: 0.3025 Acc:89.54%
Training: Epoch[090/300] Iteration[550/782] Loss: 0.3030 Acc:89.51%
Training: Epoch[090/300] Iteration[600/782] Loss: 0.3027 Acc:89.54%
Training: Epoch[090/300] Iteration[650/782] Loss: 0.3032 Acc:89.49%
Training: Epoch[090/300] Iteration[700/782] Loss: 0.3044 Acc:89.45%
Training: Epoch[090/300] Iteration[750/782] Loss: 0.3044 Acc:89.46%
Epoch[090/300] Train Acc: 89.42% Valid Acc:85.88% Train loss:0.3064 Valid loss:0.4322 LR:0.1
Training: Epoch[091/300] Iteration[050/782] Loss: 0.3294 Acc:88.16%
Training: Epoch[091/300] Iteration[100/782] Loss: 0.3064 Acc:88.95%
Training: Epoch[091/300] Iteration[150/782] Loss: 0.2913 Acc:89.66%
Training: Epoch[091/300] Iteration[200/782] Loss: 0.2932 Acc:89.80%
Training: Epoch[091/300] Iteration[250/782] Loss: 0.2949 Acc:89.74%
Training: Epoch[091/300] Iteration[300/782] Loss: 0.2958 Acc:89.68%
Training: Epoch[091/300] Iteration[350/782] Loss: 0.2992 Acc:89.57%
Training: Epoch[091/300] Iteration[400/782] Loss: 0.2990 Acc:89.64%
Training: Epoch[091/300] Iteration[450/782] Loss: 0.3002 Acc:89.60%
Training: Epoch[091/300] Iteration[500/782] Loss: 0.2993 Acc:89.68%
Training: Epoch[091/300] Iteration[550/782] Loss: 0.3009 Acc:89.66%
Training: Epoch[091/300] Iteration[600/782] Loss: 0.3015 Acc:89.61%
Training: Epoch[091/300] Iteration[650/782] Loss: 0.3016 Acc:89.62%
Training: Epoch[091/300] Iteration[700/782] Loss: 0.3015 Acc:89.60%
Training: Epoch[091/300] Iteration[750/782] Loss: 0.3033 Acc:89.55%
Epoch[091/300] Train Acc: 89.53% Valid Acc:86.50% Train loss:0.3042 Valid loss:0.4190 LR:0.1
Training: Epoch[092/300] Iteration[050/782] Loss: 0.3145 Acc:89.38%
Training: Epoch[092/300] Iteration[100/782] Loss: 0.2985 Acc:90.08%
Training: Epoch[092/300] Iteration[150/782] Loss: 0.2916 Acc:90.17%
Training: Epoch[092/300] Iteration[200/782] Loss: 0.2992 Acc:89.85%
Training: Epoch[092/300] Iteration[250/782] Loss: 0.3040 Acc:89.64%
Training: Epoch[092/300] Iteration[300/782] Loss: 0.3045 Acc:89.60%
Training: Epoch[092/300] Iteration[350/782] Loss: 0.3045 Acc:89.58%
Training: Epoch[092/300] Iteration[400/782] Loss: 0.3037 Acc:89.53%
Training: Epoch[092/300] Iteration[450/782] Loss: 0.3027 Acc:89.59%
Training: Epoch[092/300] Iteration[500/782] Loss: 0.3013 Acc:89.68%
Training: Epoch[092/300] Iteration[550/782] Loss: 0.3001 Acc:89.73%
Training: Epoch[092/300] Iteration[600/782] Loss: 0.3027 Acc:89.64%
Training: Epoch[092/300] Iteration[650/782] Loss: 0.3032 Acc:89.57%
Training: Epoch[092/300] Iteration[700/782] Loss: 0.3009 Acc:89.65%
Training: Epoch[092/300] Iteration[750/782] Loss: 0.3008 Acc:89.62%
Epoch[092/300] Train Acc: 89.57% Valid Acc:86.14% Train loss:0.3027 Valid loss:0.4114 LR:0.1
Training: Epoch[093/300] Iteration[050/782] Loss: 0.2684 Acc:90.44%
Training: Epoch[093/300] Iteration[100/782] Loss: 0.2785 Acc:90.16%
Training: Epoch[093/300] Iteration[150/782] Loss: 0.2889 Acc:89.99%
Training: Epoch[093/300] Iteration[200/782] Loss: 0.2906 Acc:89.80%
Training: Epoch[093/300] Iteration[250/782] Loss: 0.2953 Acc:89.75%
Training: Epoch[093/300] Iteration[300/782] Loss: 0.2988 Acc:89.60%
Training: Epoch[093/300] Iteration[350/782] Loss: 0.3001 Acc:89.50%
Training: Epoch[093/300] Iteration[400/782] Loss: 0.3006 Acc:89.47%
Training: Epoch[093/300] Iteration[450/782] Loss: 0.3002 Acc:89.53%
Training: Epoch[093/300] Iteration[500/782] Loss: 0.2986 Acc:89.58%
Training: Epoch[093/300] Iteration[550/782] Loss: 0.2980 Acc:89.59%
Training: Epoch[093/300] Iteration[600/782] Loss: 0.2997 Acc:89.51%
Training: Epoch[093/300] Iteration[650/782] Loss: 0.3003 Acc:89.50%
Training: Epoch[093/300] Iteration[700/782] Loss: 0.3017 Acc:89.45%
Training: Epoch[093/300] Iteration[750/782] Loss: 0.3009 Acc:89.48%
Epoch[093/300] Train Acc: 89.42% Valid Acc:84.73% Train loss:0.3024 Valid loss:0.4883 LR:0.1
Training: Epoch[094/300] Iteration[050/782] Loss: 0.3174 Acc:88.91%
Training: Epoch[094/300] Iteration[100/782] Loss: 0.3069 Acc:89.28%
Training: Epoch[094/300] Iteration[150/782] Loss: 0.3032 Acc:89.39%
Training: Epoch[094/300] Iteration[200/782] Loss: 0.2988 Acc:89.73%
Training: Epoch[094/300] Iteration[250/782] Loss: 0.3035 Acc:89.59%
Training: Epoch[094/300] Iteration[300/782] Loss: 0.3025 Acc:89.54%
Training: Epoch[094/300] Iteration[350/782] Loss: 0.2993 Acc:89.62%
Training: Epoch[094/300] Iteration[400/782] Loss: 0.3000 Acc:89.61%
Training: Epoch[094/300] Iteration[450/782] Loss: 0.2992 Acc:89.65%
Training: Epoch[094/300] Iteration[500/782] Loss: 0.3016 Acc:89.53%
Training: Epoch[094/300] Iteration[550/782] Loss: 0.3022 Acc:89.51%
Training: Epoch[094/300] Iteration[600/782] Loss: 0.3034 Acc:89.46%
Training: Epoch[094/300] Iteration[650/782] Loss: 0.3038 Acc:89.46%
Training: Epoch[094/300] Iteration[700/782] Loss: 0.3052 Acc:89.43%
Training: Epoch[094/300] Iteration[750/782] Loss: 0.3041 Acc:89.52%
Epoch[094/300] Train Acc: 89.53% Valid Acc:86.96% Train loss:0.3037 Valid loss:0.4010 LR:0.1
Training: Epoch[095/300] Iteration[050/782] Loss: 0.3130 Acc:89.22%
Training: Epoch[095/300] Iteration[100/782] Loss: 0.3030 Acc:89.47%
Training: Epoch[095/300] Iteration[150/782] Loss: 0.2984 Acc:89.71%
Training: Epoch[095/300] Iteration[200/782] Loss: 0.2996 Acc:89.73%
Training: Epoch[095/300] Iteration[250/782] Loss: 0.3007 Acc:89.76%
Training: Epoch[095/300] Iteration[300/782] Loss: 0.3024 Acc:89.68%
Training: Epoch[095/300] Iteration[350/782] Loss: 0.3026 Acc:89.60%
Training: Epoch[095/300] Iteration[400/782] Loss: 0.3020 Acc:89.60%
Training: Epoch[095/300] Iteration[450/782] Loss: 0.3008 Acc:89.66%
Training: Epoch[095/300] Iteration[500/782] Loss: 0.3009 Acc:89.68%
Training: Epoch[095/300] Iteration[550/782] Loss: 0.3014 Acc:89.64%
Training: Epoch[095/300] Iteration[600/782] Loss: 0.3014 Acc:89.62%
Training: Epoch[095/300] Iteration[650/782] Loss: 0.3025 Acc:89.59%
Training: Epoch[095/300] Iteration[700/782] Loss: 0.3020 Acc:89.60%
Training: Epoch[095/300] Iteration[750/782] Loss: 0.3044 Acc:89.54%
Epoch[095/300] Train Acc: 89.52% Valid Acc:86.11% Train loss:0.3052 Valid loss:0.4338 LR:0.1
Training: Epoch[096/300] Iteration[050/782] Loss: 0.2714 Acc:90.53%
Training: Epoch[096/300] Iteration[100/782] Loss: 0.2766 Acc:90.25%
Training: Epoch[096/300] Iteration[150/782] Loss: 0.2842 Acc:89.83%
Training: Epoch[096/300] Iteration[200/782] Loss: 0.2910 Acc:89.88%
Training: Epoch[096/300] Iteration[250/782] Loss: 0.2914 Acc:89.81%
Training: Epoch[096/300] Iteration[300/782] Loss: 0.2936 Acc:89.75%
Training: Epoch[096/300] Iteration[350/782] Loss: 0.2941 Acc:89.77%
Training: Epoch[096/300] Iteration[400/782] Loss: 0.2959 Acc:89.66%
Training: Epoch[096/300] Iteration[450/782] Loss: 0.2968 Acc:89.62%
Training: Epoch[096/300] Iteration[500/782] Loss: 0.2972 Acc:89.60%
Training: Epoch[096/300] Iteration[550/782] Loss: 0.2988 Acc:89.56%
Training: Epoch[096/300] Iteration[600/782] Loss: 0.2984 Acc:89.60%
Training: Epoch[096/300] Iteration[650/782] Loss: 0.3012 Acc:89.49%
Training: Epoch[096/300] Iteration[700/782] Loss: 0.3009 Acc:89.46%
Training: Epoch[096/300] Iteration[750/782] Loss: 0.3013 Acc:89.48%
Epoch[096/300] Train Acc: 89.50% Valid Acc:86.36% Train loss:0.3008 Valid loss:0.4294 LR:0.1
Training: Epoch[097/300] Iteration[050/782] Loss: 0.3114 Acc:89.44%
Training: Epoch[097/300] Iteration[100/782] Loss: 0.2954 Acc:89.86%
Training: Epoch[097/300] Iteration[150/782] Loss: 0.3026 Acc:89.50%
Training: Epoch[097/300] Iteration[200/782] Loss: 0.3011 Acc:89.69%
Training: Epoch[097/300] Iteration[250/782] Loss: 0.3012 Acc:89.69%
Training: Epoch[097/300] Iteration[300/782] Loss: 0.2979 Acc:89.70%
Training: Epoch[097/300] Iteration[350/782] Loss: 0.3000 Acc:89.64%
Training: Epoch[097/300] Iteration[400/782] Loss: 0.3013 Acc:89.54%
Training: Epoch[097/300] Iteration[450/782] Loss: 0.3029 Acc:89.48%
Training: Epoch[097/300] Iteration[500/782] Loss: 0.3052 Acc:89.42%
Training: Epoch[097/300] Iteration[550/782] Loss: 0.3045 Acc:89.42%
Training: Epoch[097/300] Iteration[600/782] Loss: 0.3033 Acc:89.45%
Training: Epoch[097/300] Iteration[650/782] Loss: 0.3019 Acc:89.49%
Training: Epoch[097/300] Iteration[700/782] Loss: 0.3029 Acc:89.49%
Training: Epoch[097/300] Iteration[750/782] Loss: 0.3027 Acc:89.51%
Epoch[097/300] Train Acc: 89.52% Valid Acc:85.27% Train loss:0.3028 Valid loss:0.4609 LR:0.1
Training: Epoch[098/300] Iteration[050/782] Loss: 0.2857 Acc:89.72%
Training: Epoch[098/300] Iteration[100/782] Loss: 0.2755 Acc:90.50%
Training: Epoch[098/300] Iteration[150/782] Loss: 0.2774 Acc:90.34%
Training: Epoch[098/300] Iteration[200/782] Loss: 0.2862 Acc:90.04%
Training: Epoch[098/300] Iteration[250/782] Loss: 0.2888 Acc:89.92%
Training: Epoch[098/300] Iteration[300/782] Loss: 0.2921 Acc:89.80%
Training: Epoch[098/300] Iteration[350/782] Loss: 0.2921 Acc:89.86%
Training: Epoch[098/300] Iteration[400/782] Loss: 0.2950 Acc:89.78%
Training: Epoch[098/300] Iteration[450/782] Loss: 0.2958 Acc:89.78%
Training: Epoch[098/300] Iteration[500/782] Loss: 0.2990 Acc:89.69%
Training: Epoch[098/300] Iteration[550/782] Loss: 0.2992 Acc:89.70%
Training: Epoch[098/300] Iteration[600/782] Loss: 0.2979 Acc:89.72%
Training: Epoch[098/300] Iteration[650/782] Loss: 0.2981 Acc:89.72%
Training: Epoch[098/300] Iteration[700/782] Loss: 0.2981 Acc:89.73%
Training: Epoch[098/300] Iteration[750/782] Loss: 0.2986 Acc:89.69%
Epoch[098/300] Train Acc: 89.65% Valid Acc:85.20% Train loss:0.2992 Valid loss:0.4757 LR:0.1
Training: Epoch[099/300] Iteration[050/782] Loss: 0.2850 Acc:90.62%
Training: Epoch[099/300] Iteration[100/782] Loss: 0.2837 Acc:90.42%
Training: Epoch[099/300] Iteration[150/782] Loss: 0.2838 Acc:90.23%
Training: Epoch[099/300] Iteration[200/782] Loss: 0.2785 Acc:90.36%
Training: Epoch[099/300] Iteration[250/782] Loss: 0.2804 Acc:90.29%
Training: Epoch[099/300] Iteration[300/782] Loss: 0.2833 Acc:90.30%
Training: Epoch[099/300] Iteration[350/782] Loss: 0.2847 Acc:90.27%
Training: Epoch[099/300] Iteration[400/782] Loss: 0.2866 Acc:90.20%
Training: Epoch[099/300] Iteration[450/782] Loss: 0.2876 Acc:90.20%
Training: Epoch[099/300] Iteration[500/782] Loss: 0.2926 Acc:90.03%
Training: Epoch[099/300] Iteration[550/782] Loss: 0.2950 Acc:89.93%
Training: Epoch[099/300] Iteration[600/782] Loss: 0.2970 Acc:89.89%
Training: Epoch[099/300] Iteration[650/782] Loss: 0.2977 Acc:89.83%
Training: Epoch[099/300] Iteration[700/782] Loss: 0.2982 Acc:89.79%
Training: Epoch[099/300] Iteration[750/782] Loss: 0.3002 Acc:89.70%
Epoch[099/300] Train Acc: 89.67% Valid Acc:85.28% Train loss:0.3004 Valid loss:0.4776 LR:0.1
Training: Epoch[100/300] Iteration[050/782] Loss: 0.2758 Acc:90.50%
Training: Epoch[100/300] Iteration[100/782] Loss: 0.2935 Acc:89.81%
Training: Epoch[100/300] Iteration[150/782] Loss: 0.2932 Acc:89.80%
Training: Epoch[100/300] Iteration[200/782] Loss: 0.2934 Acc:89.85%
Training: Epoch[100/300] Iteration[250/782] Loss: 0.2959 Acc:89.88%
Training: Epoch[100/300] Iteration[300/782] Loss: 0.2979 Acc:89.83%
Training: Epoch[100/300] Iteration[350/782] Loss: 0.2990 Acc:89.75%
Training: Epoch[100/300] Iteration[400/782] Loss: 0.2985 Acc:89.80%
Training: Epoch[100/300] Iteration[450/782] Loss: 0.3000 Acc:89.74%
Training: Epoch[100/300] Iteration[500/782] Loss: 0.3024 Acc:89.60%
Training: Epoch[100/300] Iteration[550/782] Loss: 0.3016 Acc:89.67%
Training: Epoch[100/300] Iteration[600/782] Loss: 0.3038 Acc:89.57%
Training: Epoch[100/300] Iteration[650/782] Loss: 0.3059 Acc:89.49%
Training: Epoch[100/300] Iteration[700/782] Loss: 0.3062 Acc:89.50%
Training: Epoch[100/300] Iteration[750/782] Loss: 0.3068 Acc:89.44%
Epoch[100/300] Train Acc: 89.45% Valid Acc:86.83% Train loss:0.3068 Valid loss:0.3896 LR:0.1
Training: Epoch[101/300] Iteration[050/782] Loss: 0.2641 Acc:90.75%
Training: Epoch[101/300] Iteration[100/782] Loss: 0.2763 Acc:90.48%
Training: Epoch[101/300] Iteration[150/782] Loss: 0.2805 Acc:90.38%
Training: Epoch[101/300] Iteration[200/782] Loss: 0.2817 Acc:90.36%
Training: Epoch[101/300] Iteration[250/782] Loss: 0.2869 Acc:90.25%
Training: Epoch[101/300] Iteration[300/782] Loss: 0.2890 Acc:90.11%
Training: Epoch[101/300] Iteration[350/782] Loss: 0.2877 Acc:90.07%
Training: Epoch[101/300] Iteration[400/782] Loss: 0.2902 Acc:89.99%
Training: Epoch[101/300] Iteration[450/782] Loss: 0.2936 Acc:89.90%
Training: Epoch[101/300] Iteration[500/782] Loss: 0.2964 Acc:89.81%
Training: Epoch[101/300] Iteration[550/782] Loss: 0.2967 Acc:89.81%
Training: Epoch[101/300] Iteration[600/782] Loss: 0.2967 Acc:89.77%
Training: Epoch[101/300] Iteration[650/782] Loss: 0.2975 Acc:89.74%
Training: Epoch[101/300] Iteration[700/782] Loss: 0.2974 Acc:89.72%
Training: Epoch[101/300] Iteration[750/782] Loss: 0.2988 Acc:89.66%
Epoch[101/300] Train Acc: 89.66% Valid Acc:85.46% Train loss:0.2980 Valid loss:0.4519 LR:0.1
Training: Epoch[102/300] Iteration[050/782] Loss: 0.2957 Acc:89.84%
Training: Epoch[102/300] Iteration[100/782] Loss: 0.2996 Acc:89.55%
Training: Epoch[102/300] Iteration[150/782] Loss: 0.3024 Acc:89.40%
Training: Epoch[102/300] Iteration[200/782] Loss: 0.2985 Acc:89.59%
Training: Epoch[102/300] Iteration[250/782] Loss: 0.2969 Acc:89.62%
Training: Epoch[102/300] Iteration[300/782] Loss: 0.2947 Acc:89.74%
Training: Epoch[102/300] Iteration[350/782] Loss: 0.2956 Acc:89.66%
Training: Epoch[102/300] Iteration[400/782] Loss: 0.2947 Acc:89.64%
Training: Epoch[102/300] Iteration[450/782] Loss: 0.2947 Acc:89.65%
Training: Epoch[102/300] Iteration[500/782] Loss: 0.2936 Acc:89.65%
Training: Epoch[102/300] Iteration[550/782] Loss: 0.2952 Acc:89.62%
Training: Epoch[102/300] Iteration[600/782] Loss: 0.2937 Acc:89.66%
Training: Epoch[102/300] Iteration[650/782] Loss: 0.2954 Acc:89.58%
Training: Epoch[102/300] Iteration[700/782] Loss: 0.2963 Acc:89.59%
Training: Epoch[102/300] Iteration[750/782] Loss: 0.2973 Acc:89.59%
Epoch[102/300] Train Acc: 89.58% Valid Acc:86.66% Train loss:0.2978 Valid loss:0.4142 LR:0.1
Training: Epoch[103/300] Iteration[050/782] Loss: 0.2882 Acc:90.00%
Training: Epoch[103/300] Iteration[100/782] Loss: 0.2775 Acc:90.16%
Training: Epoch[103/300] Iteration[150/782] Loss: 0.2776 Acc:90.46%
Training: Epoch[103/300] Iteration[200/782] Loss: 0.2819 Acc:90.32%
Training: Epoch[103/300] Iteration[250/782] Loss: 0.2794 Acc:90.48%
Training: Epoch[103/300] Iteration[300/782] Loss: 0.2765 Acc:90.53%
Training: Epoch[103/300] Iteration[350/782] Loss: 0.2810 Acc:90.34%
Training: Epoch[103/300] Iteration[400/782] Loss: 0.2848 Acc:90.17%
Training: Epoch[103/300] Iteration[450/782] Loss: 0.2862 Acc:90.13%
Training: Epoch[103/300] Iteration[500/782] Loss: 0.2899 Acc:90.05%
Training: Epoch[103/300] Iteration[550/782] Loss: 0.2912 Acc:90.01%
Training: Epoch[103/300] Iteration[600/782] Loss: 0.2901 Acc:90.04%
Training: Epoch[103/300] Iteration[650/782] Loss: 0.2915 Acc:90.00%
Training: Epoch[103/300] Iteration[700/782] Loss: 0.2915 Acc:89.99%
Training: Epoch[103/300] Iteration[750/782] Loss: 0.2942 Acc:89.91%
Epoch[103/300] Train Acc: 89.90% Valid Acc:85.14% Train loss:0.2944 Valid loss:0.4621 LR:0.1
Training: Epoch[104/300] Iteration[050/782] Loss: 0.2517 Acc:91.62%
Training: Epoch[104/300] Iteration[100/782] Loss: 0.2582 Acc:91.11%
Training: Epoch[104/300] Iteration[150/782] Loss: 0.2739 Acc:90.50%
Training: Epoch[104/300] Iteration[200/782] Loss: 0.2812 Acc:90.20%
Training: Epoch[104/300] Iteration[250/782] Loss: 0.2816 Acc:90.36%
Training: Epoch[104/300] Iteration[300/782] Loss: 0.2873 Acc:90.09%
Training: Epoch[104/300] Iteration[350/782] Loss: 0.2881 Acc:89.94%
Training: Epoch[104/300] Iteration[400/782] Loss: 0.2902 Acc:89.86%
Training: Epoch[104/300] Iteration[450/782] Loss: 0.2918 Acc:89.81%
Training: Epoch[104/300] Iteration[500/782] Loss: 0.2929 Acc:89.78%
Training: Epoch[104/300] Iteration[550/782] Loss: 0.2910 Acc:89.87%
Training: Epoch[104/300] Iteration[600/782] Loss: 0.2916 Acc:89.84%
Training: Epoch[104/300] Iteration[650/782] Loss: 0.2920 Acc:89.83%
Training: Epoch[104/300] Iteration[700/782] Loss: 0.2933 Acc:89.81%
Training: Epoch[104/300] Iteration[750/782] Loss: 0.2951 Acc:89.75%
Epoch[104/300] Train Acc: 89.72% Valid Acc:85.58% Train loss:0.2958 Valid loss:0.4471 LR:0.1
Training: Epoch[105/300] Iteration[050/782] Loss: 0.3081 Acc:89.09%
Training: Epoch[105/300] Iteration[100/782] Loss: 0.2918 Acc:90.00%
Training: Epoch[105/300] Iteration[150/782] Loss: 0.2932 Acc:89.90%
Training: Epoch[105/300] Iteration[200/782] Loss: 0.2969 Acc:89.77%
Training: Epoch[105/300] Iteration[250/782] Loss: 0.2929 Acc:89.81%
Training: Epoch[105/300] Iteration[300/782] Loss: 0.2919 Acc:89.94%
Training: Epoch[105/300] Iteration[350/782] Loss: 0.2956 Acc:89.75%
Training: Epoch[105/300] Iteration[400/782] Loss: 0.2961 Acc:89.70%
Training: Epoch[105/300] Iteration[450/782] Loss: 0.2945 Acc:89.77%
Training: Epoch[105/300] Iteration[500/782] Loss: 0.2958 Acc:89.75%
Training: Epoch[105/300] Iteration[550/782] Loss: 0.2943 Acc:89.79%
Training: Epoch[105/300] Iteration[600/782] Loss: 0.2928 Acc:89.85%
Training: Epoch[105/300] Iteration[650/782] Loss: 0.2917 Acc:89.89%
Training: Epoch[105/300] Iteration[700/782] Loss: 0.2925 Acc:89.84%
Training: Epoch[105/300] Iteration[750/782] Loss: 0.2948 Acc:89.80%
Epoch[105/300] Train Acc: 89.79% Valid Acc:86.04% Train loss:0.2951 Valid loss:0.4472 LR:0.1
Training: Epoch[106/300] Iteration[050/782] Loss: 0.2726 Acc:90.34%
Training: Epoch[106/300] Iteration[100/782] Loss: 0.2707 Acc:90.41%
Training: Epoch[106/300] Iteration[150/782] Loss: 0.2761 Acc:90.34%
Training: Epoch[106/300] Iteration[200/782] Loss: 0.2769 Acc:90.21%
Training: Epoch[106/300] Iteration[250/782] Loss: 0.2841 Acc:89.94%
Training: Epoch[106/300] Iteration[300/782] Loss: 0.2860 Acc:89.94%
Training: Epoch[106/300] Iteration[350/782] Loss: 0.2879 Acc:89.94%
Training: Epoch[106/300] Iteration[400/782] Loss: 0.2920 Acc:89.86%
Training: Epoch[106/300] Iteration[450/782] Loss: 0.2948 Acc:89.79%
Training: Epoch[106/300] Iteration[500/782] Loss: 0.2933 Acc:89.84%
Training: Epoch[106/300] Iteration[550/782] Loss: 0.2940 Acc:89.77%
Training: Epoch[106/300] Iteration[600/782] Loss: 0.2922 Acc:89.82%
Training: Epoch[106/300] Iteration[650/782] Loss: 0.2931 Acc:89.81%
Training: Epoch[106/300] Iteration[700/782] Loss: 0.2949 Acc:89.79%
Training: Epoch[106/300] Iteration[750/782] Loss: 0.2974 Acc:89.71%
Epoch[106/300] Train Acc: 89.66% Valid Acc:86.44% Train loss:0.2992 Valid loss:0.4001 LR:0.1
Training: Epoch[107/300] Iteration[050/782] Loss: 0.2862 Acc:90.62%
Training: Epoch[107/300] Iteration[100/782] Loss: 0.2889 Acc:90.27%
Training: Epoch[107/300] Iteration[150/782] Loss: 0.2927 Acc:89.79%
Training: Epoch[107/300] Iteration[200/782] Loss: 0.2886 Acc:89.96%
Training: Epoch[107/300] Iteration[250/782] Loss: 0.2883 Acc:89.98%
Training: Epoch[107/300] Iteration[300/782] Loss: 0.2885 Acc:89.96%
Training: Epoch[107/300] Iteration[350/782] Loss: 0.2905 Acc:89.85%
Training: Epoch[107/300] Iteration[400/782] Loss: 0.2891 Acc:89.86%
Training: Epoch[107/300] Iteration[450/782] Loss: 0.2917 Acc:89.76%
Training: Epoch[107/300] Iteration[500/782] Loss: 0.2917 Acc:89.76%
Training: Epoch[107/300] Iteration[550/782] Loss: 0.2918 Acc:89.75%
Training: Epoch[107/300] Iteration[600/782] Loss: 0.2926 Acc:89.73%
Training: Epoch[107/300] Iteration[650/782] Loss: 0.2946 Acc:89.66%
Training: Epoch[107/300] Iteration[700/782] Loss: 0.2928 Acc:89.72%
Training: Epoch[107/300] Iteration[750/782] Loss: 0.2921 Acc:89.73%
Epoch[107/300] Train Acc: 89.72% Valid Acc:84.99% Train loss:0.2940 Valid loss:0.4622 LR:0.1
Training: Epoch[108/300] Iteration[050/782] Loss: 0.3145 Acc:88.28%
Training: Epoch[108/300] Iteration[100/782] Loss: 0.2970 Acc:89.39%
Training: Epoch[108/300] Iteration[150/782] Loss: 0.2983 Acc:89.30%
Training: Epoch[108/300] Iteration[200/782] Loss: 0.2959 Acc:89.46%
Training: Epoch[108/300] Iteration[250/782] Loss: 0.2932 Acc:89.55%
Training: Epoch[108/300] Iteration[300/782] Loss: 0.2911 Acc:89.71%
Training: Epoch[108/300] Iteration[350/782] Loss: 0.2931 Acc:89.68%
Training: Epoch[108/300] Iteration[400/782] Loss: 0.2929 Acc:89.76%
Training: Epoch[108/300] Iteration[450/782] Loss: 0.2925 Acc:89.82%
Training: Epoch[108/300] Iteration[500/782] Loss: 0.2948 Acc:89.75%
Training: Epoch[108/300] Iteration[550/782] Loss: 0.2969 Acc:89.72%
Training: Epoch[108/300] Iteration[600/782] Loss: 0.2967 Acc:89.70%
Training: Epoch[108/300] Iteration[650/782] Loss: 0.2967 Acc:89.73%
Training: Epoch[108/300] Iteration[700/782] Loss: 0.2993 Acc:89.66%
Training: Epoch[108/300] Iteration[750/782] Loss: 0.2999 Acc:89.67%
Epoch[108/300] Train Acc: 89.61% Valid Acc:84.97% Train loss:0.3013 Valid loss:0.4632 LR:0.1
Training: Epoch[109/300] Iteration[050/782] Loss: 0.2743 Acc:90.28%
Training: Epoch[109/300] Iteration[100/782] Loss: 0.2801 Acc:90.19%
Training: Epoch[109/300] Iteration[150/782] Loss: 0.2772 Acc:90.30%
Training: Epoch[109/300] Iteration[200/782] Loss: 0.2796 Acc:90.30%
Training: Epoch[109/300] Iteration[250/782] Loss: 0.2817 Acc:90.12%
Training: Epoch[109/300] Iteration[300/782] Loss: 0.2823 Acc:90.08%
Training: Epoch[109/300] Iteration[350/782] Loss: 0.2823 Acc:90.09%
Training: Epoch[109/300] Iteration[400/782] Loss: 0.2834 Acc:90.07%
Training: Epoch[109/300] Iteration[450/782] Loss: 0.2867 Acc:89.96%
Training: Epoch[109/300] Iteration[500/782] Loss: 0.2917 Acc:89.80%
Training: Epoch[109/300] Iteration[550/782] Loss: 0.2937 Acc:89.74%
Training: Epoch[109/300] Iteration[600/782] Loss: 0.2948 Acc:89.74%
Training: Epoch[109/300] Iteration[650/782] Loss: 0.2941 Acc:89.73%
Training: Epoch[109/300] Iteration[700/782] Loss: 0.2944 Acc:89.73%
Training: Epoch[109/300] Iteration[750/782] Loss: 0.2976 Acc:89.62%
Epoch[109/300] Train Acc: 89.63% Valid Acc:85.91% Train loss:0.2972 Valid loss:0.4399 LR:0.1
Training: Epoch[110/300] Iteration[050/782] Loss: 0.2826 Acc:90.19%
Training: Epoch[110/300] Iteration[100/782] Loss: 0.2819 Acc:90.42%
Training: Epoch[110/300] Iteration[150/782] Loss: 0.2824 Acc:90.40%
Training: Epoch[110/300] Iteration[200/782] Loss: 0.2864 Acc:90.17%
Training: Epoch[110/300] Iteration[250/782] Loss: 0.2901 Acc:90.08%
Training: Epoch[110/300] Iteration[300/782] Loss: 0.2892 Acc:90.05%
Training: Epoch[110/300] Iteration[350/782] Loss: 0.2899 Acc:89.99%
Training: Epoch[110/300] Iteration[400/782] Loss: 0.2908 Acc:90.00%
Training: Epoch[110/300] Iteration[450/782] Loss: 0.2918 Acc:89.94%
Training: Epoch[110/300] Iteration[500/782] Loss: 0.2943 Acc:89.81%
Training: Epoch[110/300] Iteration[550/782] Loss: 0.2949 Acc:89.75%
Training: Epoch[110/300] Iteration[600/782] Loss: 0.2937 Acc:89.80%
Training: Epoch[110/300] Iteration[650/782] Loss: 0.2940 Acc:89.81%
Training: Epoch[110/300] Iteration[700/782] Loss: 0.2963 Acc:89.72%
Training: Epoch[110/300] Iteration[750/782] Loss: 0.2968 Acc:89.68%
Epoch[110/300] Train Acc: 89.66% Valid Acc:87.42% Train loss:0.2984 Valid loss:0.3882 LR:0.1
Training: Epoch[111/300] Iteration[050/782] Loss: 0.2960 Acc:90.00%
Training: Epoch[111/300] Iteration[100/782] Loss: 0.2916 Acc:89.84%
Training: Epoch[111/300] Iteration[150/782] Loss: 0.2862 Acc:89.95%
Training: Epoch[111/300] Iteration[200/782] Loss: 0.2858 Acc:90.04%
Training: Epoch[111/300] Iteration[250/782] Loss: 0.2847 Acc:90.08%
Training: Epoch[111/300] Iteration[300/782] Loss: 0.2874 Acc:89.95%
Training: Epoch[111/300] Iteration[350/782] Loss: 0.2901 Acc:89.83%
Training: Epoch[111/300] Iteration[400/782] Loss: 0.2929 Acc:89.72%
Training: Epoch[111/300] Iteration[450/782] Loss: 0.2931 Acc:89.74%
Training: Epoch[111/300] Iteration[500/782] Loss: 0.2941 Acc:89.74%
Training: Epoch[111/300] Iteration[550/782] Loss: 0.2961 Acc:89.70%
Training: Epoch[111/300] Iteration[600/782] Loss: 0.2971 Acc:89.68%
Training: Epoch[111/300] Iteration[650/782] Loss: 0.2964 Acc:89.68%
Training: Epoch[111/300] Iteration[700/782] Loss: 0.2961 Acc:89.69%
Training: Epoch[111/300] Iteration[750/782] Loss: 0.2963 Acc:89.67%
Epoch[111/300] Train Acc: 89.69% Valid Acc:86.13% Train loss:0.2961 Valid loss:0.4320 LR:0.1
Training: Epoch[112/300] Iteration[050/782] Loss: 0.2781 Acc:90.66%
Training: Epoch[112/300] Iteration[100/782] Loss: 0.2675 Acc:91.00%
Training: Epoch[112/300] Iteration[150/782] Loss: 0.2643 Acc:91.08%
Training: Epoch[112/300] Iteration[200/782] Loss: 0.2704 Acc:90.67%
Training: Epoch[112/300] Iteration[250/782] Loss: 0.2761 Acc:90.39%
Training: Epoch[112/300] Iteration[300/782] Loss: 0.2782 Acc:90.32%
Training: Epoch[112/300] Iteration[350/782] Loss: 0.2777 Acc:90.29%
Training: Epoch[112/300] Iteration[400/782] Loss: 0.2815 Acc:90.13%
Training: Epoch[112/300] Iteration[450/782] Loss: 0.2874 Acc:89.99%
Training: Epoch[112/300] Iteration[500/782] Loss: 0.2880 Acc:89.97%
Training: Epoch[112/300] Iteration[550/782] Loss: 0.2907 Acc:89.88%
Training: Epoch[112/300] Iteration[600/782] Loss: 0.2891 Acc:89.98%
Training: Epoch[112/300] Iteration[650/782] Loss: 0.2910 Acc:89.91%
Training: Epoch[112/300] Iteration[700/782] Loss: 0.2916 Acc:89.92%
Training: Epoch[112/300] Iteration[750/782] Loss: 0.2925 Acc:89.90%
Epoch[112/300] Train Acc: 89.92% Valid Acc:86.54% Train loss:0.2928 Valid loss:0.4268 LR:0.1
Training: Epoch[113/300] Iteration[050/782] Loss: 0.2972 Acc:90.34%
Training: Epoch[113/300] Iteration[100/782] Loss: 0.2927 Acc:90.09%
Training: Epoch[113/300] Iteration[150/782] Loss: 0.2979 Acc:89.93%
Training: Epoch[113/300] Iteration[200/782] Loss: 0.2931 Acc:89.96%
Training: Epoch[113/300] Iteration[250/782] Loss: 0.2903 Acc:89.91%
Training: Epoch[113/300] Iteration[300/782] Loss: 0.2876 Acc:90.08%
Training: Epoch[113/300] Iteration[350/782] Loss: 0.2896 Acc:89.94%
Training: Epoch[113/300] Iteration[400/782] Loss: 0.2886 Acc:89.98%
Training: Epoch[113/300] Iteration[450/782] Loss: 0.2869 Acc:90.09%
Training: Epoch[113/300] Iteration[500/782] Loss: 0.2903 Acc:89.95%
Training: Epoch[113/300] Iteration[550/782] Loss: 0.2902 Acc:89.90%
Training: Epoch[113/300] Iteration[600/782] Loss: 0.2895 Acc:89.92%
Training: Epoch[113/300] Iteration[650/782] Loss: 0.2902 Acc:89.88%
Training: Epoch[113/300] Iteration[700/782] Loss: 0.2933 Acc:89.81%
Training: Epoch[113/300] Iteration[750/782] Loss: 0.2941 Acc:89.78%
Epoch[113/300] Train Acc: 89.71% Valid Acc:84.17% Train loss:0.2957 Valid loss:0.4635 LR:0.1
Training: Epoch[114/300] Iteration[050/782] Loss: 0.3039 Acc:89.50%
Training: Epoch[114/300] Iteration[100/782] Loss: 0.2848 Acc:90.06%
Training: Epoch[114/300] Iteration[150/782] Loss: 0.2841 Acc:90.16%
Training: Epoch[114/300] Iteration[200/782] Loss: 0.2855 Acc:89.98%
Training: Epoch[114/300] Iteration[250/782] Loss: 0.2841 Acc:90.05%
Training: Epoch[114/300] Iteration[300/782] Loss: 0.2869 Acc:89.98%
Training: Epoch[114/300] Iteration[350/782] Loss: 0.2898 Acc:89.93%
Training: Epoch[114/300] Iteration[400/782] Loss: 0.2908 Acc:89.86%
Training: Epoch[114/300] Iteration[450/782] Loss: 0.2925 Acc:89.75%
Training: Epoch[114/300] Iteration[500/782] Loss: 0.2920 Acc:89.78%
Training: Epoch[114/300] Iteration[550/782] Loss: 0.2923 Acc:89.79%
Training: Epoch[114/300] Iteration[600/782] Loss: 0.2913 Acc:89.84%
Training: Epoch[114/300] Iteration[650/782] Loss: 0.2940 Acc:89.77%
Training: Epoch[114/300] Iteration[700/782] Loss: 0.2919 Acc:89.81%
Training: Epoch[114/300] Iteration[750/782] Loss: 0.2924 Acc:89.81%
Epoch[114/300] Train Acc: 89.84% Valid Acc:87.94% Train loss:0.2918 Valid loss:0.3592 LR:0.1
Training: Epoch[115/300] Iteration[050/782] Loss: 0.2988 Acc:89.47%
Training: Epoch[115/300] Iteration[100/782] Loss: 0.2985 Acc:89.58%
Training: Epoch[115/300] Iteration[150/782] Loss: 0.2847 Acc:90.29%
Training: Epoch[115/300] Iteration[200/782] Loss: 0.2908 Acc:89.88%
Training: Epoch[115/300] Iteration[250/782] Loss: 0.2936 Acc:89.78%
Training: Epoch[115/300] Iteration[300/782] Loss: 0.2945 Acc:89.65%
Training: Epoch[115/300] Iteration[350/782] Loss: 0.2929 Acc:89.65%
Training: Epoch[115/300] Iteration[400/782] Loss: 0.2924 Acc:89.65%
Training: Epoch[115/300] Iteration[450/782] Loss: 0.2926 Acc:89.74%
Training: Epoch[115/300] Iteration[500/782] Loss: 0.2926 Acc:89.74%
Training: Epoch[115/300] Iteration[550/782] Loss: 0.2910 Acc:89.75%
Training: Epoch[115/300] Iteration[600/782] Loss: 0.2932 Acc:89.69%
Training: Epoch[115/300] Iteration[650/782] Loss: 0.2966 Acc:89.57%
Training: Epoch[115/300] Iteration[700/782] Loss: 0.2979 Acc:89.55%
Training: Epoch[115/300] Iteration[750/782] Loss: 0.2986 Acc:89.52%
Epoch[115/300] Train Acc: 89.55% Valid Acc:87.84% Train loss:0.2979 Valid loss:0.3513 LR:0.1
Training: Epoch[116/300] Iteration[050/782] Loss: 0.2786 Acc:90.09%
Training: Epoch[116/300] Iteration[100/782] Loss: 0.2622 Acc:91.11%
Training: Epoch[116/300] Iteration[150/782] Loss: 0.2768 Acc:90.56%
Training: Epoch[116/300] Iteration[200/782] Loss: 0.2780 Acc:90.43%
Training: Epoch[116/300] Iteration[250/782] Loss: 0.2794 Acc:90.38%
Training: Epoch[116/300] Iteration[300/782] Loss: 0.2809 Acc:90.31%
Training: Epoch[116/300] Iteration[350/782] Loss: 0.2822 Acc:90.18%
Training: Epoch[116/300] Iteration[400/782] Loss: 0.2801 Acc:90.29%
Training: Epoch[116/300] Iteration[450/782] Loss: 0.2832 Acc:90.14%
Training: Epoch[116/300] Iteration[500/782] Loss: 0.2828 Acc:90.15%
Training: Epoch[116/300] Iteration[550/782] Loss: 0.2832 Acc:90.16%
Training: Epoch[116/300] Iteration[600/782] Loss: 0.2878 Acc:90.05%
Training: Epoch[116/300] Iteration[650/782] Loss: 0.2883 Acc:90.03%
Training: Epoch[116/300] Iteration[700/782] Loss: 0.2918 Acc:89.92%
Training: Epoch[116/300] Iteration[750/782] Loss: 0.2914 Acc:89.95%
Epoch[116/300] Train Acc: 89.95% Valid Acc:87.85% Train loss:0.2906 Valid loss:0.3713 LR:0.1
Training: Epoch[117/300] Iteration[050/782] Loss: 0.2579 Acc:91.03%
Training: Epoch[117/300] Iteration[100/782] Loss: 0.2725 Acc:90.38%
Training: Epoch[117/300] Iteration[150/782] Loss: 0.2733 Acc:90.33%
Training: Epoch[117/300] Iteration[200/782] Loss: 0.2781 Acc:90.30%
Training: Epoch[117/300] Iteration[250/782] Loss: 0.2790 Acc:90.21%
Training: Epoch[117/300] Iteration[300/782] Loss: 0.2811 Acc:90.16%
Training: Epoch[117/300] Iteration[350/782] Loss: 0.2854 Acc:90.00%
Training: Epoch[117/300] Iteration[400/782] Loss: 0.2858 Acc:90.05%
Training: Epoch[117/300] Iteration[450/782] Loss: 0.2883 Acc:89.97%
Training: Epoch[117/300] Iteration[500/782] Loss: 0.2872 Acc:90.05%
Training: Epoch[117/300] Iteration[550/782] Loss: 0.2899 Acc:90.00%
Training: Epoch[117/300] Iteration[600/782] Loss: 0.2910 Acc:89.97%
Training: Epoch[117/300] Iteration[650/782] Loss: 0.2931 Acc:89.93%
Training: Epoch[117/300] Iteration[700/782] Loss: 0.2921 Acc:89.94%
Training: Epoch[117/300] Iteration[750/782] Loss: 0.2910 Acc:89.99%
Epoch[117/300] Train Acc: 90.00% Valid Acc:85.75% Train loss:0.2913 Valid loss:0.4328 LR:0.1
Training: Epoch[118/300] Iteration[050/782] Loss: 0.2986 Acc:89.72%
Training: Epoch[118/300] Iteration[100/782] Loss: 0.2908 Acc:89.91%
Training: Epoch[118/300] Iteration[150/782] Loss: 0.2858 Acc:90.10%
Training: Epoch[118/300] Iteration[200/782] Loss: 0.2941 Acc:89.83%
Training: Epoch[118/300] Iteration[250/782] Loss: 0.2936 Acc:89.85%
Training: Epoch[118/300] Iteration[300/782] Loss: 0.2931 Acc:89.79%
Training: Epoch[118/300] Iteration[350/782] Loss: 0.2954 Acc:89.79%
Training: Epoch[118/300] Iteration[400/782] Loss: 0.2930 Acc:89.89%
Training: Epoch[118/300] Iteration[450/782] Loss: 0.2932 Acc:89.85%
Training: Epoch[118/300] Iteration[500/782] Loss: 0.2925 Acc:89.85%
Training: Epoch[118/300] Iteration[550/782] Loss: 0.2910 Acc:89.90%
Training: Epoch[118/300] Iteration[600/782] Loss: 0.2944 Acc:89.75%
Training: Epoch[118/300] Iteration[650/782] Loss: 0.2939 Acc:89.78%
Training: Epoch[118/300] Iteration[700/782] Loss: 0.2931 Acc:89.81%
Training: Epoch[118/300] Iteration[750/782] Loss: 0.2938 Acc:89.77%
Epoch[118/300] Train Acc: 89.72% Valid Acc:88.26% Train loss:0.2956 Valid loss:0.3417 LR:0.1
Training: Epoch[119/300] Iteration[050/782] Loss: 0.3090 Acc:89.09%
Training: Epoch[119/300] Iteration[100/782] Loss: 0.3017 Acc:89.48%
Training: Epoch[119/300] Iteration[150/782] Loss: 0.2953 Acc:89.65%
Training: Epoch[119/300] Iteration[200/782] Loss: 0.2889 Acc:89.82%
Training: Epoch[119/300] Iteration[250/782] Loss: 0.2888 Acc:89.88%
Training: Epoch[119/300] Iteration[300/782] Loss: 0.2869 Acc:89.96%
Training: Epoch[119/300] Iteration[350/782] Loss: 0.2885 Acc:89.89%
Training: Epoch[119/300] Iteration[400/782] Loss: 0.2914 Acc:89.78%
Training: Epoch[119/300] Iteration[450/782] Loss: 0.2934 Acc:89.66%
Training: Epoch[119/300] Iteration[500/782] Loss: 0.2924 Acc:89.65%
Training: Epoch[119/300] Iteration[550/782] Loss: 0.2924 Acc:89.65%
Training: Epoch[119/300] Iteration[600/782] Loss: 0.2915 Acc:89.72%
Training: Epoch[119/300] Iteration[650/782] Loss: 0.2907 Acc:89.72%
Training: Epoch[119/300] Iteration[700/782] Loss: 0.2911 Acc:89.73%
Training: Epoch[119/300] Iteration[750/782] Loss: 0.2918 Acc:89.73%
Epoch[119/300] Train Acc: 89.72% Valid Acc:86.33% Train loss:0.2923 Valid loss:0.4197 LR:0.1
Training: Epoch[120/300] Iteration[050/782] Loss: 0.3239 Acc:88.28%
Training: Epoch[120/300] Iteration[100/782] Loss: 0.2934 Acc:89.62%
Training: Epoch[120/300] Iteration[150/782] Loss: 0.2862 Acc:90.05%
Training: Epoch[120/300] Iteration[200/782] Loss: 0.2821 Acc:90.20%
Training: Epoch[120/300] Iteration[250/782] Loss: 0.2829 Acc:90.09%
Training: Epoch[120/300] Iteration[300/782] Loss: 0.2841 Acc:90.16%
Training: Epoch[120/300] Iteration[350/782] Loss: 0.2860 Acc:90.03%
Training: Epoch[120/300] Iteration[400/782] Loss: 0.2868 Acc:89.95%
Training: Epoch[120/300] Iteration[450/782] Loss: 0.2916 Acc:89.79%
Training: Epoch[120/300] Iteration[500/782] Loss: 0.2936 Acc:89.73%
Training: Epoch[120/300] Iteration[550/782] Loss: 0.2937 Acc:89.72%
Training: Epoch[120/300] Iteration[600/782] Loss: 0.2914 Acc:89.81%
Training: Epoch[120/300] Iteration[650/782] Loss: 0.2901 Acc:89.85%
Training: Epoch[120/300] Iteration[700/782] Loss: 0.2899 Acc:89.83%
Training: Epoch[120/300] Iteration[750/782] Loss: 0.2902 Acc:89.83%
Epoch[120/300] Train Acc: 89.82% Valid Acc:87.07% Train loss:0.2908 Valid loss:0.3905 LR:0.1
Training: Epoch[121/300] Iteration[050/782] Loss: 0.2878 Acc:90.06%
Training: Epoch[121/300] Iteration[100/782] Loss: 0.2802 Acc:90.22%
Training: Epoch[121/300] Iteration[150/782] Loss: 0.2824 Acc:90.22%
Training: Epoch[121/300] Iteration[200/782] Loss: 0.2866 Acc:90.10%
Training: Epoch[121/300] Iteration[250/782] Loss: 0.2907 Acc:89.95%
Training: Epoch[121/300] Iteration[300/782] Loss: 0.2904 Acc:89.93%
Training: Epoch[121/300] Iteration[350/782] Loss: 0.2868 Acc:90.09%
Training: Epoch[121/300] Iteration[400/782] Loss: 0.2854 Acc:90.13%
Training: Epoch[121/300] Iteration[450/782] Loss: 0.2849 Acc:90.12%
Training: Epoch[121/300] Iteration[500/782] Loss: 0.2856 Acc:90.09%
Training: Epoch[121/300] Iteration[550/782] Loss: 0.2866 Acc:90.02%
Training: Epoch[121/300] Iteration[600/782] Loss: 0.2897 Acc:89.93%
Training: Epoch[121/300] Iteration[650/782] Loss: 0.2900 Acc:89.90%
Training: Epoch[121/300] Iteration[700/782] Loss: 0.2904 Acc:89.87%
Training: Epoch[121/300] Iteration[750/782] Loss: 0.2902 Acc:89.91%
Epoch[121/300] Train Acc: 89.88% Valid Acc:86.76% Train loss:0.2911 Valid loss:0.4282 LR:0.1
Training: Epoch[122/300] Iteration[050/782] Loss: 0.2925 Acc:89.78%
Training: Epoch[122/300] Iteration[100/782] Loss: 0.2931 Acc:89.66%
Training: Epoch[122/300] Iteration[150/782] Loss: 0.2867 Acc:89.77%
Training: Epoch[122/300] Iteration[200/782] Loss: 0.2805 Acc:90.16%
Training: Epoch[122/300] Iteration[250/782] Loss: 0.2871 Acc:89.96%
Training: Epoch[122/300] Iteration[300/782] Loss: 0.2841 Acc:90.18%
Training: Epoch[122/300] Iteration[350/782] Loss: 0.2791 Acc:90.25%
Training: Epoch[122/300] Iteration[400/782] Loss: 0.2778 Acc:90.31%
Training: Epoch[122/300] Iteration[450/782] Loss: 0.2815 Acc:90.20%
Training: Epoch[122/300] Iteration[500/782] Loss: 0.2811 Acc:90.22%
Training: Epoch[122/300] Iteration[550/782] Loss: 0.2814 Acc:90.24%
Training: Epoch[122/300] Iteration[600/782] Loss: 0.2815 Acc:90.22%
Training: Epoch[122/300] Iteration[650/782] Loss: 0.2835 Acc:90.17%
Training: Epoch[122/300] Iteration[700/782] Loss: 0.2842 Acc:90.18%
Training: Epoch[122/300] Iteration[750/782] Loss: 0.2860 Acc:90.10%
Epoch[122/300] Train Acc: 90.03% Valid Acc:87.16% Train loss:0.2873 Valid loss:0.3678 LR:0.1
Training: Epoch[123/300] Iteration[050/782] Loss: 0.2867 Acc:89.88%
Training: Epoch[123/300] Iteration[100/782] Loss: 0.2866 Acc:89.95%
Training: Epoch[123/300] Iteration[150/782] Loss: 0.2825 Acc:90.17%
Training: Epoch[123/300] Iteration[200/782] Loss: 0.2786 Acc:90.34%
Training: Epoch[123/300] Iteration[250/782] Loss: 0.2843 Acc:90.07%
Training: Epoch[123/300] Iteration[300/782] Loss: 0.2874 Acc:90.02%
Training: Epoch[123/300] Iteration[350/782] Loss: 0.2852 Acc:90.18%
Training: Epoch[123/300] Iteration[400/782] Loss: 0.2874 Acc:90.07%
Training: Epoch[123/300] Iteration[450/782] Loss: 0.2864 Acc:90.09%
Training: Epoch[123/300] Iteration[500/782] Loss: 0.2872 Acc:90.04%
Training: Epoch[123/300] Iteration[550/782] Loss: 0.2890 Acc:89.98%
Training: Epoch[123/300] Iteration[600/782] Loss: 0.2898 Acc:89.96%
Training: Epoch[123/300] Iteration[650/782] Loss: 0.2905 Acc:89.94%
Training: Epoch[123/300] Iteration[700/782] Loss: 0.2881 Acc:89.96%
Training: Epoch[123/300] Iteration[750/782] Loss: 0.2881 Acc:89.98%
Epoch[123/300] Train Acc: 89.92% Valid Acc:85.83% Train loss:0.2898 Valid loss:0.4237 LR:0.1
Training: Epoch[124/300] Iteration[050/782] Loss: 0.2912 Acc:89.62%
Training: Epoch[124/300] Iteration[100/782] Loss: 0.2844 Acc:90.08%
Training: Epoch[124/300] Iteration[150/782] Loss: 0.2819 Acc:90.27%
Training: Epoch[124/300] Iteration[200/782] Loss: 0.2840 Acc:90.22%
Training: Epoch[124/300] Iteration[250/782] Loss: 0.2839 Acc:90.18%
Training: Epoch[124/300] Iteration[300/782] Loss: 0.2886 Acc:89.96%
Training: Epoch[124/300] Iteration[350/782] Loss: 0.2875 Acc:90.04%
Training: Epoch[124/300] Iteration[400/782] Loss: 0.2898 Acc:89.99%
Training: Epoch[124/300] Iteration[450/782] Loss: 0.2897 Acc:89.98%
Training: Epoch[124/300] Iteration[500/782] Loss: 0.2915 Acc:89.93%
Training: Epoch[124/300] Iteration[550/782] Loss: 0.2945 Acc:89.76%
Training: Epoch[124/300] Iteration[600/782] Loss: 0.2962 Acc:89.72%
Training: Epoch[124/300] Iteration[650/782] Loss: 0.2990 Acc:89.62%
Training: Epoch[124/300] Iteration[700/782] Loss: 0.2996 Acc:89.64%
Training: Epoch[124/300] Iteration[750/782] Loss: 0.2992 Acc:89.65%
Epoch[124/300] Train Acc: 89.65% Valid Acc:84.13% Train loss:0.2995 Valid loss:0.5035 LR:0.1
Training: Epoch[125/300] Iteration[050/782] Loss: 0.2525 Acc:91.34%
Training: Epoch[125/300] Iteration[100/782] Loss: 0.2753 Acc:90.58%
Training: Epoch[125/300] Iteration[150/782] Loss: 0.2687 Acc:90.80%
Training: Epoch[125/300] Iteration[200/782] Loss: 0.2776 Acc:90.55%
Training: Epoch[125/300] Iteration[250/782] Loss: 0.2796 Acc:90.44%
Training: Epoch[125/300] Iteration[300/782] Loss: 0.2859 Acc:90.22%
Training: Epoch[125/300] Iteration[350/782] Loss: 0.2815 Acc:90.41%
Training: Epoch[125/300] Iteration[400/782] Loss: 0.2852 Acc:90.26%
Training: Epoch[125/300] Iteration[450/782] Loss: 0.2859 Acc:90.23%
Training: Epoch[125/300] Iteration[500/782] Loss: 0.2898 Acc:90.14%
Training: Epoch[125/300] Iteration[550/782] Loss: 0.2880 Acc:90.23%
Training: Epoch[125/300] Iteration[600/782] Loss: 0.2894 Acc:90.15%
Training: Epoch[125/300] Iteration[650/782] Loss: 0.2900 Acc:90.09%
Training: Epoch[125/300] Iteration[700/782] Loss: 0.2895 Acc:90.06%
Training: Epoch[125/300] Iteration[750/782] Loss: 0.2918 Acc:90.02%
Epoch[125/300] Train Acc: 89.97% Valid Acc:87.25% Train loss:0.2932 Valid loss:0.3844 LR:0.1
Training: Epoch[126/300] Iteration[050/782] Loss: 0.2989 Acc:89.69%
Training: Epoch[126/300] Iteration[100/782] Loss: 0.2909 Acc:89.94%
Training: Epoch[126/300] Iteration[150/782] Loss: 0.2781 Acc:90.38%
Training: Epoch[126/300] Iteration[200/782] Loss: 0.2780 Acc:90.38%
Training: Epoch[126/300] Iteration[250/782] Loss: 0.2839 Acc:90.34%
Training: Epoch[126/300] Iteration[300/782] Loss: 0.2863 Acc:90.21%
Training: Epoch[126/300] Iteration[350/782] Loss: 0.2913 Acc:90.01%
Training: Epoch[126/300] Iteration[400/782] Loss: 0.2884 Acc:90.04%
Training: Epoch[126/300] Iteration[450/782] Loss: 0.2856 Acc:90.08%
Training: Epoch[126/300] Iteration[500/782] Loss: 0.2836 Acc:90.18%
Training: Epoch[126/300] Iteration[550/782] Loss: 0.2851 Acc:90.11%
Training: Epoch[126/300] Iteration[600/782] Loss: 0.2877 Acc:89.99%
Training: Epoch[126/300] Iteration[650/782] Loss: 0.2888 Acc:89.98%
Training: Epoch[126/300] Iteration[700/782] Loss: 0.2883 Acc:89.98%
Training: Epoch[126/300] Iteration[750/782] Loss: 0.2905 Acc:89.92%
Epoch[126/300] Train Acc: 89.88% Valid Acc:86.21% Train loss:0.2923 Valid loss:0.4252 LR:0.1
Training: Epoch[127/300] Iteration[050/782] Loss: 0.2646 Acc:91.06%
Training: Epoch[127/300] Iteration[100/782] Loss: 0.2705 Acc:90.73%
Training: Epoch[127/300] Iteration[150/782] Loss: 0.2812 Acc:90.26%
Training: Epoch[127/300] Iteration[200/782] Loss: 0.2888 Acc:90.01%
Training: Epoch[127/300] Iteration[250/782] Loss: 0.2960 Acc:89.71%
Training: Epoch[127/300] Iteration[300/782] Loss: 0.2944 Acc:89.81%
Training: Epoch[127/300] Iteration[350/782] Loss: 0.2900 Acc:89.92%
Training: Epoch[127/300] Iteration[400/782] Loss: 0.2932 Acc:89.78%
Training: Epoch[127/300] Iteration[450/782] Loss: 0.2933 Acc:89.77%
Training: Epoch[127/300] Iteration[500/782] Loss: 0.2927 Acc:89.83%
Training: Epoch[127/300] Iteration[550/782] Loss: 0.2929 Acc:89.79%
Training: Epoch[127/300] Iteration[600/782] Loss: 0.2929 Acc:89.83%
Training: Epoch[127/300] Iteration[650/782] Loss: 0.2938 Acc:89.81%
Training: Epoch[127/300] Iteration[700/782] Loss: 0.2928 Acc:89.87%
Training: Epoch[127/300] Iteration[750/782] Loss: 0.2932 Acc:89.88%
Epoch[127/300] Train Acc: 89.83% Valid Acc:86.96% Train loss:0.2947 Valid loss:0.3787 LR:0.1
Training: Epoch[128/300] Iteration[050/782] Loss: 0.3029 Acc:89.88%
Training: Epoch[128/300] Iteration[100/782] Loss: 0.2872 Acc:90.45%
Training: Epoch[128/300] Iteration[150/782] Loss: 0.2927 Acc:89.98%
Training: Epoch[128/300] Iteration[200/782] Loss: 0.2871 Acc:90.09%
Training: Epoch[128/300] Iteration[250/782] Loss: 0.2851 Acc:90.12%
Training: Epoch[128/300] Iteration[300/782] Loss: 0.2870 Acc:90.10%
Training: Epoch[128/300] Iteration[350/782] Loss: 0.2873 Acc:90.10%
Training: Epoch[128/300] Iteration[400/782] Loss: 0.2853 Acc:90.11%
Training: Epoch[128/300] Iteration[450/782] Loss: 0.2857 Acc:90.14%
Training: Epoch[128/300] Iteration[500/782] Loss: 0.2870 Acc:90.05%
Training: Epoch[128/300] Iteration[550/782] Loss: 0.2868 Acc:90.09%
Training: Epoch[128/300] Iteration[600/782] Loss: 0.2868 Acc:90.08%
Training: Epoch[128/300] Iteration[650/782] Loss: 0.2887 Acc:90.03%
Training: Epoch[128/300] Iteration[700/782] Loss: 0.2870 Acc:90.10%
Training: Epoch[128/300] Iteration[750/782] Loss: 0.2884 Acc:90.03%
Epoch[128/300] Train Acc: 90.05% Valid Acc:85.27% Train loss:0.2884 Valid loss:0.4603 LR:0.1
Training: Epoch[129/300] Iteration[050/782] Loss: 0.3050 Acc:89.16%
Training: Epoch[129/300] Iteration[100/782] Loss: 0.2946 Acc:89.36%
Training: Epoch[129/300] Iteration[150/782] Loss: 0.2894 Acc:89.67%
Training: Epoch[129/300] Iteration[200/782] Loss: 0.2893 Acc:89.81%
Training: Epoch[129/300] Iteration[250/782] Loss: 0.2891 Acc:89.79%
Training: Epoch[129/300] Iteration[300/782] Loss: 0.2869 Acc:89.88%
Training: Epoch[129/300] Iteration[350/782] Loss: 0.2897 Acc:89.74%
Training: Epoch[129/300] Iteration[400/782] Loss: 0.2899 Acc:89.76%
Training: Epoch[129/300] Iteration[450/782] Loss: 0.2914 Acc:89.72%
Training: Epoch[129/300] Iteration[500/782] Loss: 0.2898 Acc:89.75%
Training: Epoch[129/300] Iteration[550/782] Loss: 0.2914 Acc:89.71%
Training: Epoch[129/300] Iteration[600/782] Loss: 0.2897 Acc:89.78%
Training: Epoch[129/300] Iteration[650/782] Loss: 0.2908 Acc:89.74%
Training: Epoch[129/300] Iteration[700/782] Loss: 0.2906 Acc:89.80%
Training: Epoch[129/300] Iteration[750/782] Loss: 0.2912 Acc:89.81%
Epoch[129/300] Train Acc: 89.79% Valid Acc:87.79% Train loss:0.2921 Valid loss:0.3610 LR:0.1
Training: Epoch[130/300] Iteration[050/782] Loss: 0.3061 Acc:89.34%
Training: Epoch[130/300] Iteration[100/782] Loss: 0.2794 Acc:90.27%
Training: Epoch[130/300] Iteration[150/782] Loss: 0.2824 Acc:90.16%
Training: Epoch[130/300] Iteration[200/782] Loss: 0.2842 Acc:90.20%
Training: Epoch[130/300] Iteration[250/782] Loss: 0.2840 Acc:90.06%
Training: Epoch[130/300] Iteration[300/782] Loss: 0.2832 Acc:90.12%
Training: Epoch[130/300] Iteration[350/782] Loss: 0.2855 Acc:90.01%
Training: Epoch[130/300] Iteration[400/782] Loss: 0.2861 Acc:89.97%
Training: Epoch[130/300] Iteration[450/782] Loss: 0.2879 Acc:89.89%
Training: Epoch[130/300] Iteration[500/782] Loss: 0.2893 Acc:89.84%
Training: Epoch[130/300] Iteration[550/782] Loss: 0.2908 Acc:89.81%
Training: Epoch[130/300] Iteration[600/782] Loss: 0.2930 Acc:89.75%
Training: Epoch[130/300] Iteration[650/782] Loss: 0.2950 Acc:89.71%
Training: Epoch[130/300] Iteration[700/782] Loss: 0.2955 Acc:89.69%
Training: Epoch[130/300] Iteration[750/782] Loss: 0.2950 Acc:89.72%
Epoch[130/300] Train Acc: 89.72% Valid Acc:87.58% Train loss:0.2950 Valid loss:0.3794 LR:0.1
Training: Epoch[131/300] Iteration[050/782] Loss: 0.2904 Acc:89.75%
Training: Epoch[131/300] Iteration[100/782] Loss: 0.2866 Acc:89.62%
Training: Epoch[131/300] Iteration[150/782] Loss: 0.2832 Acc:89.88%
Training: Epoch[131/300] Iteration[200/782] Loss: 0.2814 Acc:89.92%
Training: Epoch[131/300] Iteration[250/782] Loss: 0.2797 Acc:89.96%
Training: Epoch[131/300] Iteration[300/782] Loss: 0.2811 Acc:90.03%
Training: Epoch[131/300] Iteration[350/782] Loss: 0.2826 Acc:90.14%
Training: Epoch[131/300] Iteration[400/782] Loss: 0.2849 Acc:90.02%
Training: Epoch[131/300] Iteration[450/782] Loss: 0.2798 Acc:90.22%
Training: Epoch[131/300] Iteration[500/782] Loss: 0.2806 Acc:90.22%
Training: Epoch[131/300] Iteration[550/782] Loss: 0.2828 Acc:90.17%
Training: Epoch[131/300] Iteration[600/782] Loss: 0.2824 Acc:90.22%
Training: Epoch[131/300] Iteration[650/782] Loss: 0.2851 Acc:90.14%
Training: Epoch[131/300] Iteration[700/782] Loss: 0.2864 Acc:90.07%
Training: Epoch[131/300] Iteration[750/782] Loss: 0.2861 Acc:90.08%
Epoch[131/300] Train Acc: 90.10% Valid Acc:85.44% Train loss:0.2856 Valid loss:0.4459 LR:0.1
Training: Epoch[132/300] Iteration[050/782] Loss: 0.2847 Acc:90.25%
Training: Epoch[132/300] Iteration[100/782] Loss: 0.2674 Acc:90.73%
Training: Epoch[132/300] Iteration[150/782] Loss: 0.2579 Acc:91.12%
Training: Epoch[132/300] Iteration[200/782] Loss: 0.2684 Acc:90.82%
Training: Epoch[132/300] Iteration[250/782] Loss: 0.2770 Acc:90.45%
Training: Epoch[132/300] Iteration[300/782] Loss: 0.2827 Acc:90.30%
Training: Epoch[132/300] Iteration[350/782] Loss: 0.2838 Acc:90.25%
Training: Epoch[132/300] Iteration[400/782] Loss: 0.2832 Acc:90.26%
Training: Epoch[132/300] Iteration[450/782] Loss: 0.2834 Acc:90.23%
Training: Epoch[132/300] Iteration[500/782] Loss: 0.2888 Acc:90.03%
Training: Epoch[132/300] Iteration[550/782] Loss: 0.2896 Acc:90.01%
Training: Epoch[132/300] Iteration[600/782] Loss: 0.2898 Acc:90.01%
Training: Epoch[132/300] Iteration[650/782] Loss: 0.2899 Acc:89.99%
Training: Epoch[132/300] Iteration[700/782] Loss: 0.2912 Acc:89.96%
Training: Epoch[132/300] Iteration[750/782] Loss: 0.2912 Acc:89.97%
Epoch[132/300] Train Acc: 89.98% Valid Acc:88.35% Train loss:0.2909 Valid loss:0.3589 LR:0.1
Training: Epoch[133/300] Iteration[050/782] Loss: 0.2745 Acc:89.91%
Training: Epoch[133/300] Iteration[100/782] Loss: 0.2853 Acc:89.88%
Training: Epoch[133/300] Iteration[150/782] Loss: 0.2803 Acc:90.14%
Training: Epoch[133/300] Iteration[200/782] Loss: 0.2774 Acc:90.34%
Training: Epoch[133/300] Iteration[250/782] Loss: 0.2807 Acc:90.20%
Training: Epoch[133/300] Iteration[300/782] Loss: 0.2835 Acc:90.06%
Training: Epoch[133/300] Iteration[350/782] Loss: 0.2799 Acc:90.15%
Training: Epoch[133/300] Iteration[400/782] Loss: 0.2808 Acc:90.12%
Training: Epoch[133/300] Iteration[450/782] Loss: 0.2799 Acc:90.14%
Training: Epoch[133/300] Iteration[500/782] Loss: 0.2823 Acc:90.11%
Training: Epoch[133/300] Iteration[550/782] Loss: 0.2832 Acc:90.08%
Training: Epoch[133/300] Iteration[600/782] Loss: 0.2847 Acc:89.99%
Training: Epoch[133/300] Iteration[650/782] Loss: 0.2854 Acc:89.98%
Training: Epoch[133/300] Iteration[700/782] Loss: 0.2848 Acc:90.03%
Training: Epoch[133/300] Iteration[750/782] Loss: 0.2852 Acc:90.01%
Epoch[133/300] Train Acc: 89.98% Valid Acc:86.22% Train loss:0.2862 Valid loss:0.3941 LR:0.1
Training: Epoch[134/300] Iteration[050/782] Loss: 0.2779 Acc:89.91%
Training: Epoch[134/300] Iteration[100/782] Loss: 0.2915 Acc:89.88%
Training: Epoch[134/300] Iteration[150/782] Loss: 0.2853 Acc:90.04%
Training: Epoch[134/300] Iteration[200/782] Loss: 0.2822 Acc:90.20%
Training: Epoch[134/300] Iteration[250/782] Loss: 0.2876 Acc:90.08%
Training: Epoch[134/300] Iteration[300/782] Loss: 0.2897 Acc:90.04%
Training: Epoch[134/300] Iteration[350/782] Loss: 0.2880 Acc:90.05%
Training: Epoch[134/300] Iteration[400/782] Loss: 0.2878 Acc:90.05%
Training: Epoch[134/300] Iteration[450/782] Loss: 0.2865 Acc:90.14%
Training: Epoch[134/300] Iteration[500/782] Loss: 0.2861 Acc:90.13%
Training: Epoch[134/300] Iteration[550/782] Loss: 0.2851 Acc:90.18%
Training: Epoch[134/300] Iteration[600/782] Loss: 0.2860 Acc:90.12%
Training: Epoch[134/300] Iteration[650/782] Loss: 0.2887 Acc:90.03%
Training: Epoch[134/300] Iteration[700/782] Loss: 0.2890 Acc:90.04%
Training: Epoch[134/300] Iteration[750/782] Loss: 0.2883 Acc:90.08%
Epoch[134/300] Train Acc: 90.11% Valid Acc:87.96% Train loss:0.2883 Valid loss:0.3747 LR:0.1
Training: Epoch[135/300] Iteration[050/782] Loss: 0.2508 Acc:91.09%
Training: Epoch[135/300] Iteration[100/782] Loss: 0.2740 Acc:90.25%
Training: Epoch[135/300] Iteration[150/782] Loss: 0.2736 Acc:90.49%
Training: Epoch[135/300] Iteration[200/782] Loss: 0.2752 Acc:90.48%
Training: Epoch[135/300] Iteration[250/782] Loss: 0.2807 Acc:90.24%
Training: Epoch[135/300] Iteration[300/782] Loss: 0.2849 Acc:90.07%
Training: Epoch[135/300] Iteration[350/782] Loss: 0.2843 Acc:90.08%
Training: Epoch[135/300] Iteration[400/782] Loss: 0.2825 Acc:90.18%
Training: Epoch[135/300] Iteration[450/782] Loss: 0.2850 Acc:90.09%
Training: Epoch[135/300] Iteration[500/782] Loss: 0.2875 Acc:89.98%
Training: Epoch[135/300] Iteration[550/782] Loss: 0.2911 Acc:89.84%
Training: Epoch[135/300] Iteration[600/782] Loss: 0.2920 Acc:89.81%
Training: Epoch[135/300] Iteration[650/782] Loss: 0.2912 Acc:89.86%
Training: Epoch[135/300] Iteration[700/782] Loss: 0.2901 Acc:89.89%
Training: Epoch[135/300] Iteration[750/782] Loss: 0.2902 Acc:89.87%
Epoch[135/300] Train Acc: 89.90% Valid Acc:84.89% Train loss:0.2901 Valid loss:0.4793 LR:0.1
Training: Epoch[136/300] Iteration[050/782] Loss: 0.2903 Acc:90.03%
Training: Epoch[136/300] Iteration[100/782] Loss: 0.2871 Acc:90.22%
Training: Epoch[136/300] Iteration[150/782] Loss: 0.2891 Acc:90.04%
Training: Epoch[136/300] Iteration[200/782] Loss: 0.2889 Acc:89.98%
Training: Epoch[136/300] Iteration[250/782] Loss: 0.2881 Acc:90.03%
Training: Epoch[136/300] Iteration[300/782] Loss: 0.2877 Acc:90.09%
Training: Epoch[136/300] Iteration[350/782] Loss: 0.2889 Acc:90.02%
Training: Epoch[136/300] Iteration[400/782] Loss: 0.2895 Acc:89.96%
Training: Epoch[136/300] Iteration[450/782] Loss: 0.2888 Acc:89.96%
Training: Epoch[136/300] Iteration[500/782] Loss: 0.2893 Acc:89.98%
Training: Epoch[136/300] Iteration[550/782] Loss: 0.2870 Acc:90.09%
Training: Epoch[136/300] Iteration[600/782] Loss: 0.2853 Acc:90.20%
Training: Epoch[136/300] Iteration[650/782] Loss: 0.2859 Acc:90.21%
Training: Epoch[136/300] Iteration[700/782] Loss: 0.2856 Acc:90.20%
Training: Epoch[136/300] Iteration[750/782] Loss: 0.2855 Acc:90.20%
Epoch[136/300] Train Acc: 90.16% Valid Acc:85.38% Train loss:0.2862 Valid loss:0.4548 LR:0.1
Training: Epoch[137/300] Iteration[050/782] Loss: 0.2954 Acc:89.78%
Training: Epoch[137/300] Iteration[100/782] Loss: 0.2961 Acc:89.66%
Training: Epoch[137/300] Iteration[150/782] Loss: 0.2987 Acc:89.65%
Training: Epoch[137/300] Iteration[200/782] Loss: 0.3008 Acc:89.53%
Training: Epoch[137/300] Iteration[250/782] Loss: 0.2948 Acc:89.76%
Training: Epoch[137/300] Iteration[300/782] Loss: 0.2903 Acc:90.01%
Training: Epoch[137/300] Iteration[350/782] Loss: 0.2916 Acc:89.93%
Training: Epoch[137/300] Iteration[400/782] Loss: 0.2914 Acc:90.00%
Training: Epoch[137/300] Iteration[450/782] Loss: 0.2918 Acc:90.02%
Training: Epoch[137/300] Iteration[500/782] Loss: 0.2932 Acc:89.97%
Training: Epoch[137/300] Iteration[550/782] Loss: 0.2912 Acc:90.01%
Training: Epoch[137/300] Iteration[600/782] Loss: 0.2921 Acc:89.98%
Training: Epoch[137/300] Iteration[650/782] Loss: 0.2901 Acc:90.06%
Training: Epoch[137/300] Iteration[700/782] Loss: 0.2912 Acc:90.03%
Training: Epoch[137/300] Iteration[750/782] Loss: 0.2902 Acc:90.05%
Epoch[137/300] Train Acc: 90.04% Valid Acc:87.20% Train loss:0.2902 Valid loss:0.3852 LR:0.1
Training: Epoch[138/300] Iteration[050/782] Loss: 0.2874 Acc:89.88%
Training: Epoch[138/300] Iteration[100/782] Loss: 0.2801 Acc:90.19%
Training: Epoch[138/300] Iteration[150/782] Loss: 0.2818 Acc:90.05%
Training: Epoch[138/300] Iteration[200/782] Loss: 0.2804 Acc:90.02%
Training: Epoch[138/300] Iteration[250/782] Loss: 0.2801 Acc:90.01%
Training: Epoch[138/300] Iteration[300/782] Loss: 0.2799 Acc:90.10%
Training: Epoch[138/300] Iteration[350/782] Loss: 0.2836 Acc:90.03%
Training: Epoch[138/300] Iteration[400/782] Loss: 0.2842 Acc:89.98%
Training: Epoch[138/300] Iteration[450/782] Loss: 0.2823 Acc:90.05%
Training: Epoch[138/300] Iteration[500/782] Loss: 0.2851 Acc:89.98%
Training: Epoch[138/300] Iteration[550/782] Loss: 0.2848 Acc:90.00%
Training: Epoch[138/300] Iteration[600/782] Loss: 0.2869 Acc:89.96%
Training: Epoch[138/300] Iteration[650/782] Loss: 0.2880 Acc:89.90%
Training: Epoch[138/300] Iteration[700/782] Loss: 0.2895 Acc:89.86%
Training: Epoch[138/300] Iteration[750/782] Loss: 0.2889 Acc:89.86%
Epoch[138/300] Train Acc: 89.88% Valid Acc:87.23% Train loss:0.2886 Valid loss:0.3955 LR:0.1
Training: Epoch[139/300] Iteration[050/782] Loss: 0.2898 Acc:89.94%
Training: Epoch[139/300] Iteration[100/782] Loss: 0.2796 Acc:90.23%
Training: Epoch[139/300] Iteration[150/782] Loss: 0.2709 Acc:90.69%
Training: Epoch[139/300] Iteration[200/782] Loss: 0.2734 Acc:90.69%
Training: Epoch[139/300] Iteration[250/782] Loss: 0.2748 Acc:90.45%
Training: Epoch[139/300] Iteration[300/782] Loss: 0.2787 Acc:90.34%
Training: Epoch[139/300] Iteration[350/782] Loss: 0.2794 Acc:90.30%
Training: Epoch[139/300] Iteration[400/782] Loss: 0.2838 Acc:90.15%
Training: Epoch[139/300] Iteration[450/782] Loss: 0.2856 Acc:90.11%
Training: Epoch[139/300] Iteration[500/782] Loss: 0.2852 Acc:90.11%
Training: Epoch[139/300] Iteration[550/782] Loss: 0.2859 Acc:90.07%
Training: Epoch[139/300] Iteration[600/782] Loss: 0.2843 Acc:90.11%
Training: Epoch[139/300] Iteration[650/782] Loss: 0.2835 Acc:90.13%
Training: Epoch[139/300] Iteration[700/782] Loss: 0.2832 Acc:90.16%
Training: Epoch[139/300] Iteration[750/782] Loss: 0.2850 Acc:90.11%
Epoch[139/300] Train Acc: 90.03% Valid Acc:83.76% Train loss:0.2873 Valid loss:0.5126 LR:0.1
Training: Epoch[140/300] Iteration[050/782] Loss: 0.2883 Acc:89.84%
Training: Epoch[140/300] Iteration[100/782] Loss: 0.2876 Acc:89.95%
Training: Epoch[140/300] Iteration[150/782] Loss: 0.2880 Acc:89.81%
Training: Epoch[140/300] Iteration[200/782] Loss: 0.2798 Acc:90.12%
Training: Epoch[140/300] Iteration[250/782] Loss: 0.2807 Acc:90.16%
Training: Epoch[140/300] Iteration[300/782] Loss: 0.2807 Acc:90.23%
Training: Epoch[140/300] Iteration[350/782] Loss: 0.2851 Acc:90.07%
Training: Epoch[140/300] Iteration[400/782] Loss: 0.2866 Acc:90.05%
Training: Epoch[140/300] Iteration[450/782] Loss: 0.2861 Acc:90.06%
Training: Epoch[140/300] Iteration[500/782] Loss: 0.2874 Acc:90.05%
Training: Epoch[140/300] Iteration[550/782] Loss: 0.2872 Acc:90.10%
Training: Epoch[140/300] Iteration[600/782] Loss: 0.2876 Acc:90.05%
Training: Epoch[140/300] Iteration[650/782] Loss: 0.2901 Acc:89.98%
Training: Epoch[140/300] Iteration[700/782] Loss: 0.2903 Acc:89.96%
Training: Epoch[140/300] Iteration[750/782] Loss: 0.2908 Acc:89.91%
Epoch[140/300] Train Acc: 89.95% Valid Acc:86.46% Train loss:0.2907 Valid loss:0.4248 LR:0.1
Training: Epoch[141/300] Iteration[050/782] Loss: 0.2866 Acc:90.06%
Training: Epoch[141/300] Iteration[100/782] Loss: 0.2842 Acc:90.44%
Training: Epoch[141/300] Iteration[150/782] Loss: 0.2782 Acc:90.71%
Training: Epoch[141/300] Iteration[200/782] Loss: 0.2796 Acc:90.62%
Training: Epoch[141/300] Iteration[250/782] Loss: 0.2761 Acc:90.74%
Training: Epoch[141/300] Iteration[300/782] Loss: 0.2794 Acc:90.55%
Training: Epoch[141/300] Iteration[350/782] Loss: 0.2825 Acc:90.38%
Training: Epoch[141/300] Iteration[400/782] Loss: 0.2819 Acc:90.35%
Training: Epoch[141/300] Iteration[450/782] Loss: 0.2823 Acc:90.30%
Training: Epoch[141/300] Iteration[500/782] Loss: 0.2836 Acc:90.27%
Training: Epoch[141/300] Iteration[550/782] Loss: 0.2837 Acc:90.31%
Training: Epoch[141/300] Iteration[600/782] Loss: 0.2849 Acc:90.30%
Training: Epoch[141/300] Iteration[650/782] Loss: 0.2878 Acc:90.20%
Training: Epoch[141/300] Iteration[700/782] Loss: 0.2880 Acc:90.17%
Training: Epoch[141/300] Iteration[750/782] Loss: 0.2875 Acc:90.18%
Epoch[141/300] Train Acc: 90.17% Valid Acc:84.75% Train loss:0.2875 Valid loss:0.4933 LR:0.1
Training: Epoch[142/300] Iteration[050/782] Loss: 0.2717 Acc:90.47%
Training: Epoch[142/300] Iteration[100/782] Loss: 0.2810 Acc:90.08%
Training: Epoch[142/300] Iteration[150/782] Loss: 0.2807 Acc:90.06%
Training: Epoch[142/300] Iteration[200/782] Loss: 0.2789 Acc:90.23%
Training: Epoch[142/300] Iteration[250/782] Loss: 0.2765 Acc:90.31%
Training: Epoch[142/300] Iteration[300/782] Loss: 0.2745 Acc:90.40%
Training: Epoch[142/300] Iteration[350/782] Loss: 0.2755 Acc:90.40%
Training: Epoch[142/300] Iteration[400/782] Loss: 0.2743 Acc:90.38%
Training: Epoch[142/300] Iteration[450/782] Loss: 0.2755 Acc:90.33%
Training: Epoch[142/300] Iteration[500/782] Loss: 0.2801 Acc:90.12%
Training: Epoch[142/300] Iteration[550/782] Loss: 0.2816 Acc:90.07%
Training: Epoch[142/300] Iteration[600/782] Loss: 0.2831 Acc:90.02%
Training: Epoch[142/300] Iteration[650/782] Loss: 0.2846 Acc:90.00%
Training: Epoch[142/300] Iteration[700/782] Loss: 0.2850 Acc:89.94%
Training: Epoch[142/300] Iteration[750/782] Loss: 0.2859 Acc:89.92%
Epoch[142/300] Train Acc: 89.90% Valid Acc:85.98% Train loss:0.2863 Valid loss:0.4216 LR:0.1
Training: Epoch[143/300] Iteration[050/782] Loss: 0.2994 Acc:89.53%
Training: Epoch[143/300] Iteration[100/782] Loss: 0.2958 Acc:89.78%
Training: Epoch[143/300] Iteration[150/782] Loss: 0.2914 Acc:89.75%
Training: Epoch[143/300] Iteration[200/782] Loss: 0.2831 Acc:90.01%
Training: Epoch[143/300] Iteration[250/782] Loss: 0.2793 Acc:90.18%
Training: Epoch[143/300] Iteration[300/782] Loss: 0.2854 Acc:89.92%
Training: Epoch[143/300] Iteration[350/782] Loss: 0.2852 Acc:89.90%
Training: Epoch[143/300] Iteration[400/782] Loss: 0.2890 Acc:89.73%
Training: Epoch[143/300] Iteration[450/782] Loss: 0.2897 Acc:89.77%
Training: Epoch[143/300] Iteration[500/782] Loss: 0.2891 Acc:89.78%
Training: Epoch[143/300] Iteration[550/782] Loss: 0.2897 Acc:89.76%
Training: Epoch[143/300] Iteration[600/782] Loss: 0.2904 Acc:89.75%
Training: Epoch[143/300] Iteration[650/782] Loss: 0.2901 Acc:89.74%
Training: Epoch[143/300] Iteration[700/782] Loss: 0.2901 Acc:89.71%
Training: Epoch[143/300] Iteration[750/782] Loss: 0.2890 Acc:89.75%
Epoch[143/300] Train Acc: 89.74% Valid Acc:86.09% Train loss:0.2889 Valid loss:0.4241 LR:0.1
Training: Epoch[144/300] Iteration[050/782] Loss: 0.2801 Acc:90.44%
Training: Epoch[144/300] Iteration[100/782] Loss: 0.2785 Acc:90.27%
Training: Epoch[144/300] Iteration[150/782] Loss: 0.2781 Acc:90.36%
Training: Epoch[144/300] Iteration[200/782] Loss: 0.2789 Acc:90.28%
Training: Epoch[144/300] Iteration[250/782] Loss: 0.2824 Acc:90.12%
Training: Epoch[144/300] Iteration[300/782] Loss: 0.2814 Acc:90.23%
Training: Epoch[144/300] Iteration[350/782] Loss: 0.2787 Acc:90.30%
Training: Epoch[144/300] Iteration[400/782] Loss: 0.2796 Acc:90.28%
Training: Epoch[144/300] Iteration[450/782] Loss: 0.2803 Acc:90.24%
Training: Epoch[144/300] Iteration[500/782] Loss: 0.2873 Acc:89.98%
Training: Epoch[144/300] Iteration[550/782] Loss: 0.2872 Acc:90.01%
Training: Epoch[144/300] Iteration[600/782] Loss: 0.2881 Acc:89.97%
Training: Epoch[144/300] Iteration[650/782] Loss: 0.2898 Acc:89.88%
Training: Epoch[144/300] Iteration[700/782] Loss: 0.2886 Acc:89.90%
Training: Epoch[144/300] Iteration[750/782] Loss: 0.2894 Acc:89.90%
Epoch[144/300] Train Acc: 89.89% Valid Acc:87.46% Train loss:0.2902 Valid loss:0.3673 LR:0.1
Training: Epoch[145/300] Iteration[050/782] Loss: 0.2737 Acc:90.03%
Training: Epoch[145/300] Iteration[100/782] Loss: 0.2654 Acc:90.91%
Training: Epoch[145/300] Iteration[150/782] Loss: 0.2742 Acc:90.54%
Training: Epoch[145/300] Iteration[200/782] Loss: 0.2711 Acc:90.64%
Training: Epoch[145/300] Iteration[250/782] Loss: 0.2697 Acc:90.75%
Training: Epoch[145/300] Iteration[300/782] Loss: 0.2731 Acc:90.51%
Training: Epoch[145/300] Iteration[350/782] Loss: 0.2765 Acc:90.33%
Training: Epoch[145/300] Iteration[400/782] Loss: 0.2756 Acc:90.33%
Training: Epoch[145/300] Iteration[450/782] Loss: 0.2804 Acc:90.19%
Training: Epoch[145/300] Iteration[500/782] Loss: 0.2859 Acc:90.03%
Training: Epoch[145/300] Iteration[550/782] Loss: 0.2875 Acc:90.00%
Training: Epoch[145/300] Iteration[600/782] Loss: 0.2879 Acc:90.00%
Training: Epoch[145/300] Iteration[650/782] Loss: 0.2869 Acc:90.03%
Training: Epoch[145/300] Iteration[700/782] Loss: 0.2863 Acc:90.02%
Training: Epoch[145/300] Iteration[750/782] Loss: 0.2883 Acc:89.98%
Epoch[145/300] Train Acc: 89.98% Valid Acc:87.69% Train loss:0.2883 Valid loss:0.3817 LR:0.1
Training: Epoch[146/300] Iteration[050/782] Loss: 0.2536 Acc:91.09%
Training: Epoch[146/300] Iteration[100/782] Loss: 0.2565 Acc:90.86%
Training: Epoch[146/300] Iteration[150/782] Loss: 0.2641 Acc:90.57%
Training: Epoch[146/300] Iteration[200/782] Loss: 0.2655 Acc:90.56%
Training: Epoch[146/300] Iteration[250/782] Loss: 0.2665 Acc:90.66%
Training: Epoch[146/300] Iteration[300/782] Loss: 0.2698 Acc:90.52%
Training: Epoch[146/300] Iteration[350/782] Loss: 0.2704 Acc:90.52%
Training: Epoch[146/300] Iteration[400/782] Loss: 0.2734 Acc:90.43%
Training: Epoch[146/300] Iteration[450/782] Loss: 0.2724 Acc:90.51%
Training: Epoch[146/300] Iteration[500/782] Loss: 0.2743 Acc:90.42%
Training: Epoch[146/300] Iteration[550/782] Loss: 0.2753 Acc:90.39%
Training: Epoch[146/300] Iteration[600/782] Loss: 0.2744 Acc:90.40%
Training: Epoch[146/300] Iteration[650/782] Loss: 0.2785 Acc:90.24%
Training: Epoch[146/300] Iteration[700/782] Loss: 0.2792 Acc:90.19%
Training: Epoch[146/300] Iteration[750/782] Loss: 0.2813 Acc:90.10%
Epoch[146/300] Train Acc: 90.08% Valid Acc:85.27% Train loss:0.2822 Valid loss:0.4856 LR:0.1
Training: Epoch[147/300] Iteration[050/782] Loss: 0.2939 Acc:89.19%
Training: Epoch[147/300] Iteration[100/782] Loss: 0.2798 Acc:89.95%
Training: Epoch[147/300] Iteration[150/782] Loss: 0.2851 Acc:89.78%
Training: Epoch[147/300] Iteration[200/782] Loss: 0.2836 Acc:89.92%
Training: Epoch[147/300] Iteration[250/782] Loss: 0.2809 Acc:90.05%
Training: Epoch[147/300] Iteration[300/782] Loss: 0.2826 Acc:90.06%
Training: Epoch[147/300] Iteration[350/782] Loss: 0.2822 Acc:90.05%
Training: Epoch[147/300] Iteration[400/782] Loss: 0.2848 Acc:90.03%
Training: Epoch[147/300] Iteration[450/782] Loss: 0.2831 Acc:90.10%
Training: Epoch[147/300] Iteration[500/782] Loss: 0.2850 Acc:90.07%
Training: Epoch[147/300] Iteration[550/782] Loss: 0.2851 Acc:90.06%
Training: Epoch[147/300] Iteration[600/782] Loss: 0.2857 Acc:90.02%
Training: Epoch[147/300] Iteration[650/782] Loss: 0.2876 Acc:89.96%
Training: Epoch[147/300] Iteration[700/782] Loss: 0.2886 Acc:89.94%
Training: Epoch[147/300] Iteration[750/782] Loss: 0.2876 Acc:89.98%
Epoch[147/300] Train Acc: 89.98% Valid Acc:86.71% Train loss:0.2876 Valid loss:0.4195 LR:0.1
Training: Epoch[148/300] Iteration[050/782] Loss: 0.2542 Acc:91.00%
Training: Epoch[148/300] Iteration[100/782] Loss: 0.2628 Acc:90.94%
Training: Epoch[148/300] Iteration[150/782] Loss: 0.2729 Acc:90.54%
Training: Epoch[148/300] Iteration[200/782] Loss: 0.2805 Acc:90.23%
Training: Epoch[148/300] Iteration[250/782] Loss: 0.2777 Acc:90.30%
Training: Epoch[148/300] Iteration[300/782] Loss: 0.2780 Acc:90.36%
Training: Epoch[148/300] Iteration[350/782] Loss: 0.2762 Acc:90.42%
Training: Epoch[148/300] Iteration[400/782] Loss: 0.2792 Acc:90.31%
Training: Epoch[148/300] Iteration[450/782] Loss: 0.2777 Acc:90.34%
Training: Epoch[148/300] Iteration[500/782] Loss: 0.2795 Acc:90.29%
Training: Epoch[148/300] Iteration[550/782] Loss: 0.2801 Acc:90.24%
Training: Epoch[148/300] Iteration[600/782] Loss: 0.2812 Acc:90.22%
Training: Epoch[148/300] Iteration[650/782] Loss: 0.2813 Acc:90.27%
Training: Epoch[148/300] Iteration[700/782] Loss: 0.2812 Acc:90.27%
Training: Epoch[148/300] Iteration[750/782] Loss: 0.2824 Acc:90.20%
Epoch[148/300] Train Acc: 90.16% Valid Acc:88.01% Train loss:0.2835 Valid loss:0.3694 LR:0.1
Training: Epoch[149/300] Iteration[050/782] Loss: 0.2806 Acc:90.12%
Training: Epoch[149/300] Iteration[100/782] Loss: 0.2664 Acc:90.67%
Training: Epoch[149/300] Iteration[150/782] Loss: 0.2762 Acc:90.43%
Training: Epoch[149/300] Iteration[200/782] Loss: 0.2767 Acc:90.38%
Training: Epoch[149/300] Iteration[250/782] Loss: 0.2761 Acc:90.34%
Training: Epoch[149/300] Iteration[300/782] Loss: 0.2746 Acc:90.38%
Training: Epoch[149/300] Iteration[350/782] Loss: 0.2777 Acc:90.26%
Training: Epoch[149/300] Iteration[400/782] Loss: 0.2806 Acc:90.16%
Training: Epoch[149/300] Iteration[450/782] Loss: 0.2833 Acc:90.05%
Training: Epoch[149/300] Iteration[500/782] Loss: 0.2843 Acc:90.03%
Training: Epoch[149/300] Iteration[550/782] Loss: 0.2828 Acc:90.10%
Training: Epoch[149/300] Iteration[600/782] Loss: 0.2847 Acc:90.06%
Training: Epoch[149/300] Iteration[650/782] Loss: 0.2861 Acc:90.05%
Training: Epoch[149/300] Iteration[700/782] Loss: 0.2857 Acc:90.07%
Training: Epoch[149/300] Iteration[750/782] Loss: 0.2861 Acc:90.07%
Epoch[149/300] Train Acc: 90.10% Valid Acc:85.11% Train loss:0.2848 Valid loss:0.4904 LR:0.1
Training: Epoch[150/300] Iteration[050/782] Loss: 0.2636 Acc:91.03%
Training: Epoch[150/300] Iteration[100/782] Loss: 0.2604 Acc:91.02%
Training: Epoch[150/300] Iteration[150/782] Loss: 0.2713 Acc:90.67%
Training: Epoch[150/300] Iteration[200/782] Loss: 0.2769 Acc:90.42%
Training: Epoch[150/300] Iteration[250/782] Loss: 0.2881 Acc:90.07%
Training: Epoch[150/300] Iteration[300/782] Loss: 0.2874 Acc:90.05%
Training: Epoch[150/300] Iteration[350/782] Loss: 0.2877 Acc:90.02%
Training: Epoch[150/300] Iteration[400/782] Loss: 0.2844 Acc:90.11%
Training: Epoch[150/300] Iteration[450/782] Loss: 0.2816 Acc:90.19%
Training: Epoch[150/300] Iteration[500/782] Loss: 0.2797 Acc:90.28%
Training: Epoch[150/300] Iteration[550/782] Loss: 0.2787 Acc:90.31%
Training: Epoch[150/300] Iteration[600/782] Loss: 0.2798 Acc:90.30%
Training: Epoch[150/300] Iteration[650/782] Loss: 0.2823 Acc:90.21%
Training: Epoch[150/300] Iteration[700/782] Loss: 0.2839 Acc:90.15%
Training: Epoch[150/300] Iteration[750/782] Loss: 0.2848 Acc:90.09%
Epoch[150/300] Train Acc: 90.04% Valid Acc:84.46% Train loss:0.2871 Valid loss:0.4547 LR:0.1
Training: Epoch[151/300] Iteration[050/782] Loss: 0.2447 Acc:92.06%
Training: Epoch[151/300] Iteration[100/782] Loss: 0.2304 Acc:92.42%
Training: Epoch[151/300] Iteration[150/782] Loss: 0.2162 Acc:92.90%
Training: Epoch[151/300] Iteration[200/782] Loss: 0.2070 Acc:93.10%
Training: Epoch[151/300] Iteration[250/782] Loss: 0.2045 Acc:93.11%
Training: Epoch[151/300] Iteration[300/782] Loss: 0.1989 Acc:93.29%
Training: Epoch[151/300] Iteration[350/782] Loss: 0.1956 Acc:93.36%
Training: Epoch[151/300] Iteration[400/782] Loss: 0.1922 Acc:93.51%
Training: Epoch[151/300] Iteration[450/782] Loss: 0.1905 Acc:93.52%
Training: Epoch[151/300] Iteration[500/782] Loss: 0.1890 Acc:93.57%
Training: Epoch[151/300] Iteration[550/782] Loss: 0.1877 Acc:93.62%
Training: Epoch[151/300] Iteration[600/782] Loss: 0.1857 Acc:93.68%
Training: Epoch[151/300] Iteration[650/782] Loss: 0.1838 Acc:93.74%
Training: Epoch[151/300] Iteration[700/782] Loss: 0.1817 Acc:93.82%
Training: Epoch[151/300] Iteration[750/782] Loss: 0.1800 Acc:93.89%
Epoch[151/300] Train Acc: 93.95% Valid Acc:91.89% Train loss:0.1784 Valid loss:0.2342 LR:0.010000000000000002
Training: Epoch[152/300] Iteration[050/782] Loss: 0.1502 Acc:94.97%
Training: Epoch[152/300] Iteration[100/782] Loss: 0.1433 Acc:95.48%
Training: Epoch[152/300] Iteration[150/782] Loss: 0.1454 Acc:95.34%
Training: Epoch[152/300] Iteration[200/782] Loss: 0.1453 Acc:95.25%
Training: Epoch[152/300] Iteration[250/782] Loss: 0.1427 Acc:95.29%
Training: Epoch[152/300] Iteration[300/782] Loss: 0.1437 Acc:95.26%
Training: Epoch[152/300] Iteration[350/782] Loss: 0.1424 Acc:95.34%
Training: Epoch[152/300] Iteration[400/782] Loss: 0.1440 Acc:95.30%
Training: Epoch[152/300] Iteration[450/782] Loss: 0.1436 Acc:95.32%
Training: Epoch[152/300] Iteration[500/782] Loss: 0.1442 Acc:95.25%
Training: Epoch[152/300] Iteration[550/782] Loss: 0.1435 Acc:95.28%
Training: Epoch[152/300] Iteration[600/782] Loss: 0.1435 Acc:95.26%
Training: Epoch[152/300] Iteration[650/782] Loss: 0.1430 Acc:95.25%
Training: Epoch[152/300] Iteration[700/782] Loss: 0.1439 Acc:95.22%
Training: Epoch[152/300] Iteration[750/782] Loss: 0.1435 Acc:95.23%
Epoch[152/300] Train Acc: 95.27% Valid Acc:92.20% Train loss:0.1432 Valid loss:0.2294 LR:0.010000000000000002
Training: Epoch[153/300] Iteration[050/782] Loss: 0.1291 Acc:95.56%
Training: Epoch[153/300] Iteration[100/782] Loss: 0.1269 Acc:95.73%
Training: Epoch[153/300] Iteration[150/782] Loss: 0.1263 Acc:95.70%
Training: Epoch[153/300] Iteration[200/782] Loss: 0.1234 Acc:95.84%
Training: Epoch[153/300] Iteration[250/782] Loss: 0.1245 Acc:95.77%
Training: Epoch[153/300] Iteration[300/782] Loss: 0.1259 Acc:95.70%
Training: Epoch[153/300] Iteration[350/782] Loss: 0.1262 Acc:95.72%
Training: Epoch[153/300] Iteration[400/782] Loss: 0.1264 Acc:95.78%
Training: Epoch[153/300] Iteration[450/782] Loss: 0.1274 Acc:95.72%
Training: Epoch[153/300] Iteration[500/782] Loss: 0.1275 Acc:95.69%
Training: Epoch[153/300] Iteration[550/782] Loss: 0.1274 Acc:95.71%
Training: Epoch[153/300] Iteration[600/782] Loss: 0.1268 Acc:95.75%
Training: Epoch[153/300] Iteration[650/782] Loss: 0.1273 Acc:95.74%
Training: Epoch[153/300] Iteration[700/782] Loss: 0.1264 Acc:95.77%
Training: Epoch[153/300] Iteration[750/782] Loss: 0.1259 Acc:95.77%
Epoch[153/300] Train Acc: 95.77% Valid Acc:92.61% Train loss:0.1258 Valid loss:0.2254 LR:0.010000000000000002
Training: Epoch[154/300] Iteration[050/782] Loss: 0.1146 Acc:96.06%
Training: Epoch[154/300] Iteration[100/782] Loss: 0.1220 Acc:95.84%
Training: Epoch[154/300] Iteration[150/782] Loss: 0.1180 Acc:96.06%
Training: Epoch[154/300] Iteration[200/782] Loss: 0.1164 Acc:96.10%
Training: Epoch[154/300] Iteration[250/782] Loss: 0.1179 Acc:96.03%
Training: Epoch[154/300] Iteration[300/782] Loss: 0.1174 Acc:96.03%
Training: Epoch[154/300] Iteration[350/782] Loss: 0.1190 Acc:95.96%
Training: Epoch[154/300] Iteration[400/782] Loss: 0.1164 Acc:96.00%
Training: Epoch[154/300] Iteration[450/782] Loss: 0.1161 Acc:96.01%
Training: Epoch[154/300] Iteration[500/782] Loss: 0.1175 Acc:95.99%
Training: Epoch[154/300] Iteration[550/782] Loss: 0.1176 Acc:95.97%
Training: Epoch[154/300] Iteration[600/782] Loss: 0.1176 Acc:96.00%
Training: Epoch[154/300] Iteration[650/782] Loss: 0.1177 Acc:96.03%
Training: Epoch[154/300] Iteration[700/782] Loss: 0.1177 Acc:96.00%
Training: Epoch[154/300] Iteration[750/782] Loss: 0.1183 Acc:95.98%
Epoch[154/300] Train Acc: 95.98% Valid Acc:92.44% Train loss:0.1185 Valid loss:0.2286 LR:0.010000000000000002
Training: Epoch[155/300] Iteration[050/782] Loss: 0.1096 Acc:96.50%
Training: Epoch[155/300] Iteration[100/782] Loss: 0.1055 Acc:96.58%
Training: Epoch[155/300] Iteration[150/782] Loss: 0.1084 Acc:96.32%
Training: Epoch[155/300] Iteration[200/782] Loss: 0.1074 Acc:96.34%
Training: Epoch[155/300] Iteration[250/782] Loss: 0.1095 Acc:96.29%
Training: Epoch[155/300] Iteration[300/782] Loss: 0.1105 Acc:96.27%
Training: Epoch[155/300] Iteration[350/782] Loss: 0.1111 Acc:96.19%
Training: Epoch[155/300] Iteration[400/782] Loss: 0.1115 Acc:96.17%
Training: Epoch[155/300] Iteration[450/782] Loss: 0.1103 Acc:96.24%
Training: Epoch[155/300] Iteration[500/782] Loss: 0.1106 Acc:96.23%
Training: Epoch[155/300] Iteration[550/782] Loss: 0.1114 Acc:96.17%
Training: Epoch[155/300] Iteration[600/782] Loss: 0.1122 Acc:96.12%
Training: Epoch[155/300] Iteration[650/782] Loss: 0.1121 Acc:96.13%
Training: Epoch[155/300] Iteration[700/782] Loss: 0.1123 Acc:96.10%
Training: Epoch[155/300] Iteration[750/782] Loss: 0.1124 Acc:96.08%
Epoch[155/300] Train Acc: 96.08% Valid Acc:92.69% Train loss:0.1125 Valid loss:0.2340 LR:0.010000000000000002
Training: Epoch[156/300] Iteration[050/782] Loss: 0.1058 Acc:96.47%
Training: Epoch[156/300] Iteration[100/782] Loss: 0.1027 Acc:96.34%
Training: Epoch[156/300] Iteration[150/782] Loss: 0.1042 Acc:96.18%
Training: Epoch[156/300] Iteration[200/782] Loss: 0.1020 Acc:96.33%
Training: Epoch[156/300] Iteration[250/782] Loss: 0.1021 Acc:96.33%
Training: Epoch[156/300] Iteration[300/782] Loss: 0.1022 Acc:96.38%
Training: Epoch[156/300] Iteration[350/782] Loss: 0.1035 Acc:96.32%
Training: Epoch[156/300] Iteration[400/782] Loss: 0.1026 Acc:96.36%
Training: Epoch[156/300] Iteration[450/782] Loss: 0.1041 Acc:96.32%
Training: Epoch[156/300] Iteration[500/782] Loss: 0.1048 Acc:96.32%
Training: Epoch[156/300] Iteration[550/782] Loss: 0.1057 Acc:96.33%
Training: Epoch[156/300] Iteration[600/782] Loss: 0.1056 Acc:96.36%
Training: Epoch[156/300] Iteration[650/782] Loss: 0.1059 Acc:96.32%
Training: Epoch[156/300] Iteration[700/782] Loss: 0.1061 Acc:96.32%
Training: Epoch[156/300] Iteration[750/782] Loss: 0.1057 Acc:96.33%
Epoch[156/300] Train Acc: 96.30% Valid Acc:92.44% Train loss:0.1063 Valid loss:0.2297 LR:0.010000000000000002
Training: Epoch[157/300] Iteration[050/782] Loss: 0.1095 Acc:96.31%
Training: Epoch[157/300] Iteration[100/782] Loss: 0.0994 Acc:96.62%
Training: Epoch[157/300] Iteration[150/782] Loss: 0.1037 Acc:96.58%
Training: Epoch[157/300] Iteration[200/782] Loss: 0.1019 Acc:96.68%
Training: Epoch[157/300] Iteration[250/782] Loss: 0.1002 Acc:96.71%
Training: Epoch[157/300] Iteration[300/782] Loss: 0.1000 Acc:96.66%
Training: Epoch[157/300] Iteration[350/782] Loss: 0.0993 Acc:96.71%
Training: Epoch[157/300] Iteration[400/782] Loss: 0.0998 Acc:96.62%
Training: Epoch[157/300] Iteration[450/782] Loss: 0.1000 Acc:96.63%
Training: Epoch[157/300] Iteration[500/782] Loss: 0.0997 Acc:96.63%
Training: Epoch[157/300] Iteration[550/782] Loss: 0.0993 Acc:96.62%
Training: Epoch[157/300] Iteration[600/782] Loss: 0.0996 Acc:96.58%
Training: Epoch[157/300] Iteration[650/782] Loss: 0.0997 Acc:96.58%
Training: Epoch[157/300] Iteration[700/782] Loss: 0.0998 Acc:96.56%
Training: Epoch[157/300] Iteration[750/782] Loss: 0.0997 Acc:96.56%
Epoch[157/300] Train Acc: 96.55% Valid Acc:92.29% Train loss:0.0999 Valid loss:0.2406 LR:0.010000000000000002
Training: Epoch[158/300] Iteration[050/782] Loss: 0.0973 Acc:96.88%
Training: Epoch[158/300] Iteration[100/782] Loss: 0.0949 Acc:96.98%
Training: Epoch[158/300] Iteration[150/782] Loss: 0.0943 Acc:96.89%
Training: Epoch[158/300] Iteration[200/782] Loss: 0.0972 Acc:96.70%
Training: Epoch[158/300] Iteration[250/782] Loss: 0.0951 Acc:96.77%
Training: Epoch[158/300] Iteration[300/782] Loss: 0.0950 Acc:96.79%
Training: Epoch[158/300] Iteration[350/782] Loss: 0.0952 Acc:96.81%
Training: Epoch[158/300] Iteration[400/782] Loss: 0.0941 Acc:96.81%
Training: Epoch[158/300] Iteration[450/782] Loss: 0.0938 Acc:96.82%
Training: Epoch[158/300] Iteration[500/782] Loss: 0.0940 Acc:96.81%
Training: Epoch[158/300] Iteration[550/782] Loss: 0.0942 Acc:96.77%
Training: Epoch[158/300] Iteration[600/782] Loss: 0.0944 Acc:96.78%
Training: Epoch[158/300] Iteration[650/782] Loss: 0.0947 Acc:96.77%
Training: Epoch[158/300] Iteration[700/782] Loss: 0.0946 Acc:96.78%
Training: Epoch[158/300] Iteration[750/782] Loss: 0.0946 Acc:96.76%
Epoch[158/300] Train Acc: 96.76% Valid Acc:92.60% Train loss:0.0945 Valid loss:0.2342 LR:0.010000000000000002
Training: Epoch[159/300] Iteration[050/782] Loss: 0.0942 Acc:96.66%
Training: Epoch[159/300] Iteration[100/782] Loss: 0.0958 Acc:96.72%
Training: Epoch[159/300] Iteration[150/782] Loss: 0.0912 Acc:96.90%
Training: Epoch[159/300] Iteration[200/782] Loss: 0.0911 Acc:96.80%
Training: Epoch[159/300] Iteration[250/782] Loss: 0.0905 Acc:96.85%
Training: Epoch[159/300] Iteration[300/782] Loss: 0.0909 Acc:96.90%
Training: Epoch[159/300] Iteration[350/782] Loss: 0.0906 Acc:96.89%
Training: Epoch[159/300] Iteration[400/782] Loss: 0.0904 Acc:96.90%
Training: Epoch[159/300] Iteration[450/782] Loss: 0.0902 Acc:96.92%
Training: Epoch[159/300] Iteration[500/782] Loss: 0.0917 Acc:96.84%
Training: Epoch[159/300] Iteration[550/782] Loss: 0.0922 Acc:96.83%
Training: Epoch[159/300] Iteration[600/782] Loss: 0.0921 Acc:96.82%
Training: Epoch[159/300] Iteration[650/782] Loss: 0.0919 Acc:96.85%
Training: Epoch[159/300] Iteration[700/782] Loss: 0.0921 Acc:96.84%
Training: Epoch[159/300] Iteration[750/782] Loss: 0.0929 Acc:96.81%
Epoch[159/300] Train Acc: 96.80% Valid Acc:92.74% Train loss:0.0929 Valid loss:0.2337 LR:0.010000000000000002
Training: Epoch[160/300] Iteration[050/782] Loss: 0.0907 Acc:96.69%
Training: Epoch[160/300] Iteration[100/782] Loss: 0.0902 Acc:96.78%
Training: Epoch[160/300] Iteration[150/782] Loss: 0.0869 Acc:96.96%
Training: Epoch[160/300] Iteration[200/782] Loss: 0.0874 Acc:96.97%
Training: Epoch[160/300] Iteration[250/782] Loss: 0.0884 Acc:96.91%
Training: Epoch[160/300] Iteration[300/782] Loss: 0.0869 Acc:97.03%
Training: Epoch[160/300] Iteration[350/782] Loss: 0.0883 Acc:97.00%
Training: Epoch[160/300] Iteration[400/782] Loss: 0.0880 Acc:97.00%
Training: Epoch[160/300] Iteration[450/782] Loss: 0.0886 Acc:96.97%
Training: Epoch[160/300] Iteration[500/782] Loss: 0.0890 Acc:96.96%
Training: Epoch[160/300] Iteration[550/782] Loss: 0.0893 Acc:96.95%
Training: Epoch[160/300] Iteration[600/782] Loss: 0.0886 Acc:96.98%
Training: Epoch[160/300] Iteration[650/782] Loss: 0.0893 Acc:96.96%
Training: Epoch[160/300] Iteration[700/782] Loss: 0.0897 Acc:96.96%
Training: Epoch[160/300] Iteration[750/782] Loss: 0.0902 Acc:96.95%
Epoch[160/300] Train Acc: 96.93% Valid Acc:92.83% Train loss:0.0910 Valid loss:0.2301 LR:0.010000000000000002
Training: Epoch[161/300] Iteration[050/782] Loss: 0.0794 Acc:97.34%
Training: Epoch[161/300] Iteration[100/782] Loss: 0.0812 Acc:97.27%
Training: Epoch[161/300] Iteration[150/782] Loss: 0.0813 Acc:97.22%
Training: Epoch[161/300] Iteration[200/782] Loss: 0.0820 Acc:97.23%
Training: Epoch[161/300] Iteration[250/782] Loss: 0.0854 Acc:97.09%
Training: Epoch[161/300] Iteration[300/782] Loss: 0.0871 Acc:97.01%
Training: Epoch[161/300] Iteration[350/782] Loss: 0.0869 Acc:97.04%
Training: Epoch[161/300] Iteration[400/782] Loss: 0.0858 Acc:97.10%
Training: Epoch[161/300] Iteration[450/782] Loss: 0.0857 Acc:97.11%
Training: Epoch[161/300] Iteration[500/782] Loss: 0.0858 Acc:97.08%
Training: Epoch[161/300] Iteration[550/782] Loss: 0.0865 Acc:97.02%
Training: Epoch[161/300] Iteration[600/782] Loss: 0.0863 Acc:97.02%
Training: Epoch[161/300] Iteration[650/782] Loss: 0.0871 Acc:96.97%
Training: Epoch[161/300] Iteration[700/782] Loss: 0.0872 Acc:96.97%
Training: Epoch[161/300] Iteration[750/782] Loss: 0.0870 Acc:96.97%
Epoch[161/300] Train Acc: 96.98% Valid Acc:92.92% Train loss:0.0866 Valid loss:0.2317 LR:0.010000000000000002
Training: Epoch[162/300] Iteration[050/782] Loss: 0.0874 Acc:97.31%
Training: Epoch[162/300] Iteration[100/782] Loss: 0.0883 Acc:97.03%
Training: Epoch[162/300] Iteration[150/782] Loss: 0.0864 Acc:97.07%
Training: Epoch[162/300] Iteration[200/782] Loss: 0.0857 Acc:97.00%
Training: Epoch[162/300] Iteration[250/782] Loss: 0.0880 Acc:96.92%
Training: Epoch[162/300] Iteration[300/782] Loss: 0.0880 Acc:96.99%
Training: Epoch[162/300] Iteration[350/782] Loss: 0.0881 Acc:96.98%
Training: Epoch[162/300] Iteration[400/782] Loss: 0.0875 Acc:97.03%
Training: Epoch[162/300] Iteration[450/782] Loss: 0.0863 Acc:97.04%
Training: Epoch[162/300] Iteration[500/782] Loss: 0.0863 Acc:97.01%
Training: Epoch[162/300] Iteration[550/782] Loss: 0.0861 Acc:97.01%
Training: Epoch[162/300] Iteration[600/782] Loss: 0.0860 Acc:97.00%
Training: Epoch[162/300] Iteration[650/782] Loss: 0.0855 Acc:97.03%
Training: Epoch[162/300] Iteration[700/782] Loss: 0.0853 Acc:97.03%
Training: Epoch[162/300] Iteration[750/782] Loss: 0.0848 Acc:97.04%
Epoch[162/300] Train Acc: 97.04% Valid Acc:93.17% Train loss:0.0850 Valid loss:0.2281 LR:0.010000000000000002
Training: Epoch[163/300] Iteration[050/782] Loss: 0.0690 Acc:97.78%
Training: Epoch[163/300] Iteration[100/782] Loss: 0.0696 Acc:97.69%
Training: Epoch[163/300] Iteration[150/782] Loss: 0.0743 Acc:97.44%
Training: Epoch[163/300] Iteration[200/782] Loss: 0.0748 Acc:97.49%
Training: Epoch[163/300] Iteration[250/782] Loss: 0.0765 Acc:97.41%
Training: Epoch[163/300] Iteration[300/782] Loss: 0.0784 Acc:97.29%
Training: Epoch[163/300] Iteration[350/782] Loss: 0.0793 Acc:97.25%
Training: Epoch[163/300] Iteration[400/782] Loss: 0.0801 Acc:97.20%
Training: Epoch[163/300] Iteration[450/782] Loss: 0.0803 Acc:97.20%
Training: Epoch[163/300] Iteration[500/782] Loss: 0.0803 Acc:97.21%
Training: Epoch[163/300] Iteration[550/782] Loss: 0.0806 Acc:97.20%
Training: Epoch[163/300] Iteration[600/782] Loss: 0.0812 Acc:97.17%
Training: Epoch[163/300] Iteration[650/782] Loss: 0.0818 Acc:97.12%
Training: Epoch[163/300] Iteration[700/782] Loss: 0.0814 Acc:97.15%
Training: Epoch[163/300] Iteration[750/782] Loss: 0.0811 Acc:97.16%
Epoch[163/300] Train Acc: 97.15% Valid Acc:92.94% Train loss:0.0814 Valid loss:0.2412 LR:0.010000000000000002
Training: Epoch[164/300] Iteration[050/782] Loss: 0.0709 Acc:97.59%
Training: Epoch[164/300] Iteration[100/782] Loss: 0.0700 Acc:97.64%
Training: Epoch[164/300] Iteration[150/782] Loss: 0.0697 Acc:97.72%
Training: Epoch[164/300] Iteration[200/782] Loss: 0.0709 Acc:97.62%
Training: Epoch[164/300] Iteration[250/782] Loss: 0.0712 Acc:97.61%
Training: Epoch[164/300] Iteration[300/782] Loss: 0.0734 Acc:97.57%
Training: Epoch[164/300] Iteration[350/782] Loss: 0.0741 Acc:97.49%
Training: Epoch[164/300] Iteration[400/782] Loss: 0.0748 Acc:97.48%
Training: Epoch[164/300] Iteration[450/782] Loss: 0.0758 Acc:97.44%
Training: Epoch[164/300] Iteration[500/782] Loss: 0.0770 Acc:97.38%
Training: Epoch[164/300] Iteration[550/782] Loss: 0.0776 Acc:97.37%
Training: Epoch[164/300] Iteration[600/782] Loss: 0.0776 Acc:97.35%
Training: Epoch[164/300] Iteration[650/782] Loss: 0.0772 Acc:97.35%
Training: Epoch[164/300] Iteration[700/782] Loss: 0.0779 Acc:97.30%
Training: Epoch[164/300] Iteration[750/782] Loss: 0.0780 Acc:97.30%
Epoch[164/300] Train Acc: 97.27% Valid Acc:92.82% Train loss:0.0783 Valid loss:0.2338 LR:0.010000000000000002
Training: Epoch[165/300] Iteration[050/782] Loss: 0.0668 Acc:97.97%
Training: Epoch[165/300] Iteration[100/782] Loss: 0.0767 Acc:97.61%
Training: Epoch[165/300] Iteration[150/782] Loss: 0.0763 Acc:97.55%
Training: Epoch[165/300] Iteration[200/782] Loss: 0.0757 Acc:97.52%
Training: Epoch[165/300] Iteration[250/782] Loss: 0.0752 Acc:97.49%
Training: Epoch[165/300] Iteration[300/782] Loss: 0.0757 Acc:97.44%
Training: Epoch[165/300] Iteration[350/782] Loss: 0.0755 Acc:97.43%
Training: Epoch[165/300] Iteration[400/782] Loss: 0.0754 Acc:97.44%
Training: Epoch[165/300] Iteration[450/782] Loss: 0.0757 Acc:97.44%
Training: Epoch[165/300] Iteration[500/782] Loss: 0.0758 Acc:97.47%
Training: Epoch[165/300] Iteration[550/782] Loss: 0.0769 Acc:97.44%
Training: Epoch[165/300] Iteration[600/782] Loss: 0.0770 Acc:97.42%
Training: Epoch[165/300] Iteration[650/782] Loss: 0.0776 Acc:97.41%
Training: Epoch[165/300] Iteration[700/782] Loss: 0.0777 Acc:97.38%
Training: Epoch[165/300] Iteration[750/782] Loss: 0.0778 Acc:97.37%
Epoch[165/300] Train Acc: 97.37% Valid Acc:92.82% Train loss:0.0775 Valid loss:0.2407 LR:0.010000000000000002
Training: Epoch[166/300] Iteration[050/782] Loss: 0.0738 Acc:97.19%
Training: Epoch[166/300] Iteration[100/782] Loss: 0.0733 Acc:97.28%
Training: Epoch[166/300] Iteration[150/782] Loss: 0.0753 Acc:97.29%
Training: Epoch[166/300] Iteration[200/782] Loss: 0.0757 Acc:97.27%
Training: Epoch[166/300] Iteration[250/782] Loss: 0.0733 Acc:97.38%
Training: Epoch[166/300] Iteration[300/782] Loss: 0.0731 Acc:97.47%
Training: Epoch[166/300] Iteration[350/782] Loss: 0.0741 Acc:97.45%
Training: Epoch[166/300] Iteration[400/782] Loss: 0.0740 Acc:97.42%
Training: Epoch[166/300] Iteration[450/782] Loss: 0.0753 Acc:97.39%
Training: Epoch[166/300] Iteration[500/782] Loss: 0.0748 Acc:97.40%
Training: Epoch[166/300] Iteration[550/782] Loss: 0.0758 Acc:97.33%
Training: Epoch[166/300] Iteration[600/782] Loss: 0.0763 Acc:97.31%
Training: Epoch[166/300] Iteration[650/782] Loss: 0.0763 Acc:97.33%
Training: Epoch[166/300] Iteration[700/782] Loss: 0.0766 Acc:97.33%
Training: Epoch[166/300] Iteration[750/782] Loss: 0.0768 Acc:97.34%
Epoch[166/300] Train Acc: 97.31% Valid Acc:92.95% Train loss:0.0772 Valid loss:0.2383 LR:0.010000000000000002
Training: Epoch[167/300] Iteration[050/782] Loss: 0.0701 Acc:97.50%
Training: Epoch[167/300] Iteration[100/782] Loss: 0.0730 Acc:97.36%
Training: Epoch[167/300] Iteration[150/782] Loss: 0.0731 Acc:97.34%
Training: Epoch[167/300] Iteration[200/782] Loss: 0.0727 Acc:97.41%
Training: Epoch[167/300] Iteration[250/782] Loss: 0.0740 Acc:97.33%
Training: Epoch[167/300] Iteration[300/782] Loss: 0.0746 Acc:97.32%
Training: Epoch[167/300] Iteration[350/782] Loss: 0.0742 Acc:97.34%
Training: Epoch[167/300] Iteration[400/782] Loss: 0.0733 Acc:97.41%
Training: Epoch[167/300] Iteration[450/782] Loss: 0.0737 Acc:97.38%
Training: Epoch[167/300] Iteration[500/782] Loss: 0.0749 Acc:97.36%
Training: Epoch[167/300] Iteration[550/782] Loss: 0.0774 Acc:97.24%
Training: Epoch[167/300] Iteration[600/782] Loss: 0.0769 Acc:97.27%
Training: Epoch[167/300] Iteration[650/782] Loss: 0.0773 Acc:97.25%
Training: Epoch[167/300] Iteration[700/782] Loss: 0.0771 Acc:97.26%
Training: Epoch[167/300] Iteration[750/782] Loss: 0.0775 Acc:97.26%
Epoch[167/300] Train Acc: 97.26% Valid Acc:92.74% Train loss:0.0775 Valid loss:0.2387 LR:0.010000000000000002
Training: Epoch[168/300] Iteration[050/782] Loss: 0.0637 Acc:97.91%
Training: Epoch[168/300] Iteration[100/782] Loss: 0.0653 Acc:97.78%
Training: Epoch[168/300] Iteration[150/782] Loss: 0.0708 Acc:97.51%
Training: Epoch[168/300] Iteration[200/782] Loss: 0.0687 Acc:97.68%
Training: Epoch[168/300] Iteration[250/782] Loss: 0.0703 Acc:97.59%
Training: Epoch[168/300] Iteration[300/782] Loss: 0.0703 Acc:97.57%
Training: Epoch[168/300] Iteration[350/782] Loss: 0.0704 Acc:97.56%
Training: Epoch[168/300] Iteration[400/782] Loss: 0.0708 Acc:97.52%
Training: Epoch[168/300] Iteration[450/782] Loss: 0.0704 Acc:97.58%
Training: Epoch[168/300] Iteration[500/782] Loss: 0.0707 Acc:97.51%
Training: Epoch[168/300] Iteration[550/782] Loss: 0.0714 Acc:97.47%
Training: Epoch[168/300] Iteration[600/782] Loss: 0.0726 Acc:97.42%
Training: Epoch[168/300] Iteration[650/782] Loss: 0.0729 Acc:97.44%
Training: Epoch[168/300] Iteration[700/782] Loss: 0.0734 Acc:97.40%
Training: Epoch[168/300] Iteration[750/782] Loss: 0.0729 Acc:97.44%
Epoch[168/300] Train Acc: 97.42% Valid Acc:92.64% Train loss:0.0729 Valid loss:0.2504 LR:0.010000000000000002
Training: Epoch[169/300] Iteration[050/782] Loss: 0.0659 Acc:97.97%
Training: Epoch[169/300] Iteration[100/782] Loss: 0.0643 Acc:97.98%
Training: Epoch[169/300] Iteration[150/782] Loss: 0.0657 Acc:97.81%
Training: Epoch[169/300] Iteration[200/782] Loss: 0.0664 Acc:97.82%
Training: Epoch[169/300] Iteration[250/782] Loss: 0.0652 Acc:97.86%
Training: Epoch[169/300] Iteration[300/782] Loss: 0.0663 Acc:97.82%
Training: Epoch[169/300] Iteration[350/782] Loss: 0.0664 Acc:97.80%
Training: Epoch[169/300] Iteration[400/782] Loss: 0.0682 Acc:97.73%
Training: Epoch[169/300] Iteration[450/782] Loss: 0.0682 Acc:97.74%
Training: Epoch[169/300] Iteration[500/782] Loss: 0.0683 Acc:97.73%
Training: Epoch[169/300] Iteration[550/782] Loss: 0.0693 Acc:97.70%
Training: Epoch[169/300] Iteration[600/782] Loss: 0.0694 Acc:97.69%
Training: Epoch[169/300] Iteration[650/782] Loss: 0.0697 Acc:97.69%
Training: Epoch[169/300] Iteration[700/782] Loss: 0.0699 Acc:97.67%
Training: Epoch[169/300] Iteration[750/782] Loss: 0.0706 Acc:97.61%
Epoch[169/300] Train Acc: 97.62% Valid Acc:92.66% Train loss:0.0706 Valid loss:0.2504 LR:0.010000000000000002
Training: Epoch[170/300] Iteration[050/782] Loss: 0.0672 Acc:97.72%
Training: Epoch[170/300] Iteration[100/782] Loss: 0.0686 Acc:97.75%
Training: Epoch[170/300] Iteration[150/782] Loss: 0.0652 Acc:97.92%
Training: Epoch[170/300] Iteration[200/782] Loss: 0.0656 Acc:97.88%
Training: Epoch[170/300] Iteration[250/782] Loss: 0.0664 Acc:97.82%
Training: Epoch[170/300] Iteration[300/782] Loss: 0.0670 Acc:97.80%
Training: Epoch[170/300] Iteration[350/782] Loss: 0.0684 Acc:97.72%
Training: Epoch[170/300] Iteration[400/782] Loss: 0.0681 Acc:97.73%
Training: Epoch[170/300] Iteration[450/782] Loss: 0.0679 Acc:97.72%
Training: Epoch[170/300] Iteration[500/782] Loss: 0.0678 Acc:97.71%
Training: Epoch[170/300] Iteration[550/782] Loss: 0.0687 Acc:97.70%
Training: Epoch[170/300] Iteration[600/782] Loss: 0.0682 Acc:97.70%
Training: Epoch[170/300] Iteration[650/782] Loss: 0.0683 Acc:97.71%
Training: Epoch[170/300] Iteration[700/782] Loss: 0.0681 Acc:97.70%
Training: Epoch[170/300] Iteration[750/782] Loss: 0.0687 Acc:97.68%
Epoch[170/300] Train Acc: 97.69% Valid Acc:92.71% Train loss:0.0686 Valid loss:0.2447 LR:0.010000000000000002
Training: Epoch[171/300] Iteration[050/782] Loss: 0.0595 Acc:98.03%
Training: Epoch[171/300] Iteration[100/782] Loss: 0.0618 Acc:98.06%
Training: Epoch[171/300] Iteration[150/782] Loss: 0.0625 Acc:98.02%
Training: Epoch[171/300] Iteration[200/782] Loss: 0.0629 Acc:97.91%
Training: Epoch[171/300] Iteration[250/782] Loss: 0.0629 Acc:97.92%
Training: Epoch[171/300] Iteration[300/782] Loss: 0.0622 Acc:97.91%
Training: Epoch[171/300] Iteration[350/782] Loss: 0.0631 Acc:97.90%
Training: Epoch[171/300] Iteration[400/782] Loss: 0.0633 Acc:97.86%
Training: Epoch[171/300] Iteration[450/782] Loss: 0.0637 Acc:97.85%
Training: Epoch[171/300] Iteration[500/782] Loss: 0.0642 Acc:97.84%
Training: Epoch[171/300] Iteration[550/782] Loss: 0.0654 Acc:97.77%
Training: Epoch[171/300] Iteration[600/782] Loss: 0.0667 Acc:97.70%
Training: Epoch[171/300] Iteration[650/782] Loss: 0.0663 Acc:97.72%
Training: Epoch[171/300] Iteration[700/782] Loss: 0.0672 Acc:97.68%
Training: Epoch[171/300] Iteration[750/782] Loss: 0.0674 Acc:97.66%
Epoch[171/300] Train Acc: 97.64% Valid Acc:92.74% Train loss:0.0678 Valid loss:0.2485 LR:0.010000000000000002
Training: Epoch[172/300] Iteration[050/782] Loss: 0.0727 Acc:97.34%
Training: Epoch[172/300] Iteration[100/782] Loss: 0.0687 Acc:97.52%
Training: Epoch[172/300] Iteration[150/782] Loss: 0.0660 Acc:97.56%
Training: Epoch[172/300] Iteration[200/782] Loss: 0.0668 Acc:97.56%
Training: Epoch[172/300] Iteration[250/782] Loss: 0.0684 Acc:97.52%
Training: Epoch[172/300] Iteration[300/782] Loss: 0.0673 Acc:97.59%
Training: Epoch[172/300] Iteration[350/782] Loss: 0.0673 Acc:97.59%
Training: Epoch[172/300] Iteration[400/782] Loss: 0.0688 Acc:97.53%
Training: Epoch[172/300] Iteration[450/782] Loss: 0.0679 Acc:97.58%
Training: Epoch[172/300] Iteration[500/782] Loss: 0.0686 Acc:97.55%
Training: Epoch[172/300] Iteration[550/782] Loss: 0.0684 Acc:97.56%
Training: Epoch[172/300] Iteration[600/782] Loss: 0.0690 Acc:97.54%
Training: Epoch[172/300] Iteration[650/782] Loss: 0.0694 Acc:97.53%
Training: Epoch[172/300] Iteration[700/782] Loss: 0.0702 Acc:97.52%
Training: Epoch[172/300] Iteration[750/782] Loss: 0.0706 Acc:97.51%
Epoch[172/300] Train Acc: 97.52% Valid Acc:92.87% Train loss:0.0710 Valid loss:0.2468 LR:0.010000000000000002
Training: Epoch[173/300] Iteration[050/782] Loss: 0.0658 Acc:97.66%
Training: Epoch[173/300] Iteration[100/782] Loss: 0.0668 Acc:97.70%
Training: Epoch[173/300] Iteration[150/782] Loss: 0.0659 Acc:97.75%
Training: Epoch[173/300] Iteration[200/782] Loss: 0.0636 Acc:97.90%
Training: Epoch[173/300] Iteration[250/782] Loss: 0.0640 Acc:97.89%
Training: Epoch[173/300] Iteration[300/782] Loss: 0.0643 Acc:97.87%
Training: Epoch[173/300] Iteration[350/782] Loss: 0.0658 Acc:97.80%
Training: Epoch[173/300] Iteration[400/782] Loss: 0.0661 Acc:97.75%
Training: Epoch[173/300] Iteration[450/782] Loss: 0.0662 Acc:97.73%
Training: Epoch[173/300] Iteration[500/782] Loss: 0.0667 Acc:97.71%
Training: Epoch[173/300] Iteration[550/782] Loss: 0.0680 Acc:97.68%
Training: Epoch[173/300] Iteration[600/782] Loss: 0.0684 Acc:97.67%
Training: Epoch[173/300] Iteration[650/782] Loss: 0.0688 Acc:97.66%
Training: Epoch[173/300] Iteration[700/782] Loss: 0.0691 Acc:97.63%
Training: Epoch[173/300] Iteration[750/782] Loss: 0.0686 Acc:97.65%
Epoch[173/300] Train Acc: 97.64% Valid Acc:92.76% Train loss:0.0695 Valid loss:0.2470 LR:0.010000000000000002
Training: Epoch[174/300] Iteration[050/782] Loss: 0.0670 Acc:97.66%
Training: Epoch[174/300] Iteration[100/782] Loss: 0.0615 Acc:97.95%
Training: Epoch[174/300] Iteration[150/782] Loss: 0.0632 Acc:97.93%
Training: Epoch[174/300] Iteration[200/782] Loss: 0.0615 Acc:97.97%
Training: Epoch[174/300] Iteration[250/782] Loss: 0.0619 Acc:98.01%
Training: Epoch[174/300] Iteration[300/782] Loss: 0.0625 Acc:97.94%
Training: Epoch[174/300] Iteration[350/782] Loss: 0.0632 Acc:97.92%
Training: Epoch[174/300] Iteration[400/782] Loss: 0.0628 Acc:97.93%
Training: Epoch[174/300] Iteration[450/782] Loss: 0.0637 Acc:97.88%
Training: Epoch[174/300] Iteration[500/782] Loss: 0.0642 Acc:97.83%
Training: Epoch[174/300] Iteration[550/782] Loss: 0.0640 Acc:97.82%
Training: Epoch[174/300] Iteration[600/782] Loss: 0.0645 Acc:97.81%
Training: Epoch[174/300] Iteration[650/782] Loss: 0.0640 Acc:97.85%
Training: Epoch[174/300] Iteration[700/782] Loss: 0.0638 Acc:97.85%
Training: Epoch[174/300] Iteration[750/782] Loss: 0.0639 Acc:97.84%
Epoch[174/300] Train Acc: 97.83% Valid Acc:92.66% Train loss:0.0641 Valid loss:0.2509 LR:0.010000000000000002
Training: Epoch[175/300] Iteration[050/782] Loss: 0.0581 Acc:98.12%
Training: Epoch[175/300] Iteration[100/782] Loss: 0.0634 Acc:97.88%
Training: Epoch[175/300] Iteration[150/782] Loss: 0.0630 Acc:97.98%
Training: Epoch[175/300] Iteration[200/782] Loss: 0.0646 Acc:97.93%
Training: Epoch[175/300] Iteration[250/782] Loss: 0.0639 Acc:97.91%
Training: Epoch[175/300] Iteration[300/782] Loss: 0.0627 Acc:97.94%
Training: Epoch[175/300] Iteration[350/782] Loss: 0.0623 Acc:97.94%
Training: Epoch[175/300] Iteration[400/782] Loss: 0.0626 Acc:97.93%
Training: Epoch[175/300] Iteration[450/782] Loss: 0.0624 Acc:97.94%
Training: Epoch[175/300] Iteration[500/782] Loss: 0.0625 Acc:97.93%
Training: Epoch[175/300] Iteration[550/782] Loss: 0.0622 Acc:97.94%
Training: Epoch[175/300] Iteration[600/782] Loss: 0.0627 Acc:97.91%
Training: Epoch[175/300] Iteration[650/782] Loss: 0.0627 Acc:97.90%
Training: Epoch[175/300] Iteration[700/782] Loss: 0.0630 Acc:97.87%
Training: Epoch[175/300] Iteration[750/782] Loss: 0.0630 Acc:97.86%
Epoch[175/300] Train Acc: 97.85% Valid Acc:92.73% Train loss:0.0631 Valid loss:0.2556 LR:0.010000000000000002
Training: Epoch[176/300] Iteration[050/782] Loss: 0.0591 Acc:97.97%
Training: Epoch[176/300] Iteration[100/782] Loss: 0.0581 Acc:98.02%
Training: Epoch[176/300] Iteration[150/782] Loss: 0.0582 Acc:98.02%
Training: Epoch[176/300] Iteration[200/782] Loss: 0.0616 Acc:97.84%
Training: Epoch[176/300] Iteration[250/782] Loss: 0.0607 Acc:97.86%
Training: Epoch[176/300] Iteration[300/782] Loss: 0.0609 Acc:97.87%
Training: Epoch[176/300] Iteration[350/782] Loss: 0.0622 Acc:97.85%
Training: Epoch[176/300] Iteration[400/782] Loss: 0.0622 Acc:97.84%
Training: Epoch[176/300] Iteration[450/782] Loss: 0.0626 Acc:97.85%
Training: Epoch[176/300] Iteration[500/782] Loss: 0.0626 Acc:97.87%
Training: Epoch[176/300] Iteration[550/782] Loss: 0.0633 Acc:97.83%
Training: Epoch[176/300] Iteration[600/782] Loss: 0.0629 Acc:97.84%
Training: Epoch[176/300] Iteration[650/782] Loss: 0.0626 Acc:97.85%
Training: Epoch[176/300] Iteration[700/782] Loss: 0.0632 Acc:97.83%
Training: Epoch[176/300] Iteration[750/782] Loss: 0.0640 Acc:97.82%
Epoch[176/300] Train Acc: 97.79% Valid Acc:92.81% Train loss:0.0646 Valid loss:0.2548 LR:0.010000000000000002
Training: Epoch[177/300] Iteration[050/782] Loss: 0.0572 Acc:98.12%
Training: Epoch[177/300] Iteration[100/782] Loss: 0.0624 Acc:97.88%
Training: Epoch[177/300] Iteration[150/782] Loss: 0.0618 Acc:97.89%
Training: Epoch[177/300] Iteration[200/782] Loss: 0.0599 Acc:98.03%
Training: Epoch[177/300] Iteration[250/782] Loss: 0.0596 Acc:98.04%
Training: Epoch[177/300] Iteration[300/782] Loss: 0.0589 Acc:98.03%
Training: Epoch[177/300] Iteration[350/782] Loss: 0.0594 Acc:98.01%
Training: Epoch[177/300] Iteration[400/782] Loss: 0.0607 Acc:97.95%
Training: Epoch[177/300] Iteration[450/782] Loss: 0.0615 Acc:97.93%
Training: Epoch[177/300] Iteration[500/782] Loss: 0.0616 Acc:97.96%
Training: Epoch[177/300] Iteration[550/782] Loss: 0.0622 Acc:97.93%
Training: Epoch[177/300] Iteration[600/782] Loss: 0.0625 Acc:97.90%
Training: Epoch[177/300] Iteration[650/782] Loss: 0.0634 Acc:97.85%
Training: Epoch[177/300] Iteration[700/782] Loss: 0.0631 Acc:97.85%
Training: Epoch[177/300] Iteration[750/782] Loss: 0.0627 Acc:97.87%
Epoch[177/300] Train Acc: 97.87% Valid Acc:92.72% Train loss:0.0628 Valid loss:0.2563 LR:0.010000000000000002
Training: Epoch[178/300] Iteration[050/782] Loss: 0.0584 Acc:98.09%
Training: Epoch[178/300] Iteration[100/782] Loss: 0.0533 Acc:98.33%
Training: Epoch[178/300] Iteration[150/782] Loss: 0.0533 Acc:98.23%
Training: Epoch[178/300] Iteration[200/782] Loss: 0.0536 Acc:98.17%
Training: Epoch[178/300] Iteration[250/782] Loss: 0.0547 Acc:98.13%
Training: Epoch[178/300] Iteration[300/782] Loss: 0.0557 Acc:98.09%
Training: Epoch[178/300] Iteration[350/782] Loss: 0.0573 Acc:98.06%
Training: Epoch[178/300] Iteration[400/782] Loss: 0.0575 Acc:98.02%
Training: Epoch[178/300] Iteration[450/782] Loss: 0.0576 Acc:98.01%
Training: Epoch[178/300] Iteration[500/782] Loss: 0.0584 Acc:97.98%
Training: Epoch[178/300] Iteration[550/782] Loss: 0.0589 Acc:97.95%
Training: Epoch[178/300] Iteration[600/782] Loss: 0.0591 Acc:97.94%
Training: Epoch[178/300] Iteration[650/782] Loss: 0.0594 Acc:97.94%
Training: Epoch[178/300] Iteration[700/782] Loss: 0.0599 Acc:97.92%
Training: Epoch[178/300] Iteration[750/782] Loss: 0.0606 Acc:97.87%
Epoch[178/300] Train Acc: 97.84% Valid Acc:92.92% Train loss:0.0613 Valid loss:0.2587 LR:0.010000000000000002
Training: Epoch[179/300] Iteration[050/782] Loss: 0.0679 Acc:97.81%
Training: Epoch[179/300] Iteration[100/782] Loss: 0.0653 Acc:97.81%
Training: Epoch[179/300] Iteration[150/782] Loss: 0.0626 Acc:97.81%
Training: Epoch[179/300] Iteration[200/782] Loss: 0.0619 Acc:97.84%
Training: Epoch[179/300] Iteration[250/782] Loss: 0.0610 Acc:97.88%
Training: Epoch[179/300] Iteration[300/782] Loss: 0.0631 Acc:97.77%
Training: Epoch[179/300] Iteration[350/782] Loss: 0.0637 Acc:97.74%
Training: Epoch[179/300] Iteration[400/782] Loss: 0.0630 Acc:97.80%
Training: Epoch[179/300] Iteration[450/782] Loss: 0.0627 Acc:97.80%
Training: Epoch[179/300] Iteration[500/782] Loss: 0.0620 Acc:97.83%
Training: Epoch[179/300] Iteration[550/782] Loss: 0.0617 Acc:97.85%
Training: Epoch[179/300] Iteration[600/782] Loss: 0.0617 Acc:97.84%
Training: Epoch[179/300] Iteration[650/782] Loss: 0.0617 Acc:97.82%
Training: Epoch[179/300] Iteration[700/782] Loss: 0.0613 Acc:97.85%
Training: Epoch[179/300] Iteration[750/782] Loss: 0.0620 Acc:97.82%
Epoch[179/300] Train Acc: 97.81% Valid Acc:92.50% Train loss:0.0622 Valid loss:0.2699 LR:0.010000000000000002
Training: Epoch[180/300] Iteration[050/782] Loss: 0.0509 Acc:98.38%
Training: Epoch[180/300] Iteration[100/782] Loss: 0.0543 Acc:98.16%
Training: Epoch[180/300] Iteration[150/782] Loss: 0.0558 Acc:98.05%
Training: Epoch[180/300] Iteration[200/782] Loss: 0.0552 Acc:98.09%
Training: Epoch[180/300] Iteration[250/782] Loss: 0.0571 Acc:98.02%
Training: Epoch[180/300] Iteration[300/782] Loss: 0.0567 Acc:98.06%
Training: Epoch[180/300] Iteration[350/782] Loss: 0.0567 Acc:98.04%
Training: Epoch[180/300] Iteration[400/782] Loss: 0.0582 Acc:98.00%
Training: Epoch[180/300] Iteration[450/782] Loss: 0.0590 Acc:97.98%
Training: Epoch[180/300] Iteration[500/782] Loss: 0.0597 Acc:97.96%
Training: Epoch[180/300] Iteration[550/782] Loss: 0.0598 Acc:97.96%
Training: Epoch[180/300] Iteration[600/782] Loss: 0.0596 Acc:97.98%
Training: Epoch[180/300] Iteration[650/782] Loss: 0.0601 Acc:97.97%
Training: Epoch[180/300] Iteration[700/782] Loss: 0.0609 Acc:97.94%
Training: Epoch[180/300] Iteration[750/782] Loss: 0.0614 Acc:97.91%
Epoch[180/300] Train Acc: 97.92% Valid Acc:92.63% Train loss:0.0615 Valid loss:0.2681 LR:0.010000000000000002
Training: Epoch[181/300] Iteration[050/782] Loss: 0.0571 Acc:98.00%
Training: Epoch[181/300] Iteration[100/782] Loss: 0.0538 Acc:98.19%
Training: Epoch[181/300] Iteration[150/782] Loss: 0.0581 Acc:97.98%
Training: Epoch[181/300] Iteration[200/782] Loss: 0.0615 Acc:97.80%
Training: Epoch[181/300] Iteration[250/782] Loss: 0.0624 Acc:97.78%
Training: Epoch[181/300] Iteration[300/782] Loss: 0.0613 Acc:97.80%
Training: Epoch[181/300] Iteration[350/782] Loss: 0.0615 Acc:97.78%
Training: Epoch[181/300] Iteration[400/782] Loss: 0.0617 Acc:97.82%
Training: Epoch[181/300] Iteration[450/782] Loss: 0.0621 Acc:97.75%
Training: Epoch[181/300] Iteration[500/782] Loss: 0.0622 Acc:97.77%
Training: Epoch[181/300] Iteration[550/782] Loss: 0.0620 Acc:97.80%
Training: Epoch[181/300] Iteration[600/782] Loss: 0.0619 Acc:97.81%
Training: Epoch[181/300] Iteration[650/782] Loss: 0.0619 Acc:97.81%
Training: Epoch[181/300] Iteration[700/782] Loss: 0.0618 Acc:97.82%
Training: Epoch[181/300] Iteration[750/782] Loss: 0.0622 Acc:97.80%
Epoch[181/300] Train Acc: 97.81% Valid Acc:92.54% Train loss:0.0620 Valid loss:0.2678 LR:0.010000000000000002
Training: Epoch[182/300] Iteration[050/782] Loss: 0.0547 Acc:98.12%
Training: Epoch[182/300] Iteration[100/782] Loss: 0.0608 Acc:98.00%
Training: Epoch[182/300] Iteration[150/782] Loss: 0.0623 Acc:97.91%
Training: Epoch[182/300] Iteration[200/782] Loss: 0.0602 Acc:98.00%
Training: Epoch[182/300] Iteration[250/782] Loss: 0.0612 Acc:97.96%
Training: Epoch[182/300] Iteration[300/782] Loss: 0.0616 Acc:97.94%
Training: Epoch[182/300] Iteration[350/782] Loss: 0.0618 Acc:97.91%
Training: Epoch[182/300] Iteration[400/782] Loss: 0.0611 Acc:97.95%
Training: Epoch[182/300] Iteration[450/782] Loss: 0.0602 Acc:97.97%
Training: Epoch[182/300] Iteration[500/782] Loss: 0.0606 Acc:97.94%
Training: Epoch[182/300] Iteration[550/782] Loss: 0.0611 Acc:97.91%
Training: Epoch[182/300] Iteration[600/782] Loss: 0.0604 Acc:97.93%
Training: Epoch[182/300] Iteration[650/782] Loss: 0.0601 Acc:97.94%
Training: Epoch[182/300] Iteration[700/782] Loss: 0.0597 Acc:97.95%
Training: Epoch[182/300] Iteration[750/782] Loss: 0.0595 Acc:97.94%
Epoch[182/300] Train Acc: 97.95% Valid Acc:92.34% Train loss:0.0596 Valid loss:0.2839 LR:0.010000000000000002
Training: Epoch[183/300] Iteration[050/782] Loss: 0.0625 Acc:97.84%
Training: Epoch[183/300] Iteration[100/782] Loss: 0.0588 Acc:97.97%
Training: Epoch[183/300] Iteration[150/782] Loss: 0.0559 Acc:98.03%
Training: Epoch[183/300] Iteration[200/782] Loss: 0.0551 Acc:98.05%
Training: Epoch[183/300] Iteration[250/782] Loss: 0.0561 Acc:98.04%
Training: Epoch[183/300] Iteration[300/782] Loss: 0.0572 Acc:98.02%
Training: Epoch[183/300] Iteration[350/782] Loss: 0.0560 Acc:98.08%
Training: Epoch[183/300] Iteration[400/782] Loss: 0.0565 Acc:98.06%
Training: Epoch[183/300] Iteration[450/782] Loss: 0.0572 Acc:98.05%
Training: Epoch[183/300] Iteration[500/782] Loss: 0.0575 Acc:98.02%
Training: Epoch[183/300] Iteration[550/782] Loss: 0.0577 Acc:98.01%
Training: Epoch[183/300] Iteration[600/782] Loss: 0.0582 Acc:97.97%
Training: Epoch[183/300] Iteration[650/782] Loss: 0.0594 Acc:97.93%
Training: Epoch[183/300] Iteration[700/782] Loss: 0.0594 Acc:97.93%
Training: Epoch[183/300] Iteration[750/782] Loss: 0.0595 Acc:97.93%
Epoch[183/300] Train Acc: 97.93% Valid Acc:92.51% Train loss:0.0596 Valid loss:0.2747 LR:0.010000000000000002
Training: Epoch[184/300] Iteration[050/782] Loss: 0.0568 Acc:97.84%
Training: Epoch[184/300] Iteration[100/782] Loss: 0.0584 Acc:97.84%
Training: Epoch[184/300] Iteration[150/782] Loss: 0.0593 Acc:97.85%
Training: Epoch[184/300] Iteration[200/782] Loss: 0.0604 Acc:97.80%
Training: Epoch[184/300] Iteration[250/782] Loss: 0.0605 Acc:97.79%
Training: Epoch[184/300] Iteration[300/782] Loss: 0.0607 Acc:97.80%
Training: Epoch[184/300] Iteration[350/782] Loss: 0.0605 Acc:97.83%
Training: Epoch[184/300] Iteration[400/782] Loss: 0.0603 Acc:97.82%
Training: Epoch[184/300] Iteration[450/782] Loss: 0.0599 Acc:97.84%
Training: Epoch[184/300] Iteration[500/782] Loss: 0.0599 Acc:97.87%
Training: Epoch[184/300] Iteration[550/782] Loss: 0.0603 Acc:97.86%
Training: Epoch[184/300] Iteration[600/782] Loss: 0.0604 Acc:97.86%
Training: Epoch[184/300] Iteration[650/782] Loss: 0.0608 Acc:97.83%
Training: Epoch[184/300] Iteration[700/782] Loss: 0.0609 Acc:97.82%
Training: Epoch[184/300] Iteration[750/782] Loss: 0.0608 Acc:97.81%
Epoch[184/300] Train Acc: 97.81% Valid Acc:92.65% Train loss:0.0610 Valid loss:0.2690 LR:0.010000000000000002
Training: Epoch[185/300] Iteration[050/782] Loss: 0.0565 Acc:98.25%
Training: Epoch[185/300] Iteration[100/782] Loss: 0.0543 Acc:98.31%
Training: Epoch[185/300] Iteration[150/782] Loss: 0.0548 Acc:98.19%
Training: Epoch[185/300] Iteration[200/782] Loss: 0.0572 Acc:98.04%
Training: Epoch[185/300] Iteration[250/782] Loss: 0.0599 Acc:97.99%
Training: Epoch[185/300] Iteration[300/782] Loss: 0.0599 Acc:98.00%
Training: Epoch[185/300] Iteration[350/782] Loss: 0.0589 Acc:98.03%
Training: Epoch[185/300] Iteration[400/782] Loss: 0.0600 Acc:97.98%
Training: Epoch[185/300] Iteration[450/782] Loss: 0.0600 Acc:97.98%
Training: Epoch[185/300] Iteration[500/782] Loss: 0.0597 Acc:97.98%
Training: Epoch[185/300] Iteration[550/782] Loss: 0.0593 Acc:98.01%
Training: Epoch[185/300] Iteration[600/782] Loss: 0.0594 Acc:98.02%
Training: Epoch[185/300] Iteration[650/782] Loss: 0.0602 Acc:97.99%
Training: Epoch[185/300] Iteration[700/782] Loss: 0.0606 Acc:97.97%
Training: Epoch[185/300] Iteration[750/782] Loss: 0.0610 Acc:97.95%
Epoch[185/300] Train Acc: 97.93% Valid Acc:92.40% Train loss:0.0616 Valid loss:0.2712 LR:0.010000000000000002
Training: Epoch[186/300] Iteration[050/782] Loss: 0.0560 Acc:98.25%
Training: Epoch[186/300] Iteration[100/782] Loss: 0.0564 Acc:98.17%
Training: Epoch[186/300] Iteration[150/782] Loss: 0.0577 Acc:97.97%
Training: Epoch[186/300] Iteration[200/782] Loss: 0.0599 Acc:97.88%
Training: Epoch[186/300] Iteration[250/782] Loss: 0.0597 Acc:97.90%
Training: Epoch[186/300] Iteration[300/782] Loss: 0.0592 Acc:97.90%
Training: Epoch[186/300] Iteration[350/782] Loss: 0.0593 Acc:97.90%
Training: Epoch[186/300] Iteration[400/782] Loss: 0.0583 Acc:97.93%
Training: Epoch[186/300] Iteration[450/782] Loss: 0.0583 Acc:97.92%
Training: Epoch[186/300] Iteration[500/782] Loss: 0.0583 Acc:97.94%
Training: Epoch[186/300] Iteration[550/782] Loss: 0.0592 Acc:97.92%
Training: Epoch[186/300] Iteration[600/782] Loss: 0.0605 Acc:97.89%
Training: Epoch[186/300] Iteration[650/782] Loss: 0.0611 Acc:97.87%
Training: Epoch[186/300] Iteration[700/782] Loss: 0.0609 Acc:97.89%
Training: Epoch[186/300] Iteration[750/782] Loss: 0.0607 Acc:97.88%
Epoch[186/300] Train Acc: 97.88% Valid Acc:92.31% Train loss:0.0609 Valid loss:0.2830 LR:0.010000000000000002
Training: Epoch[187/300] Iteration[050/782] Loss: 0.0586 Acc:98.06%
Training: Epoch[187/300] Iteration[100/782] Loss: 0.0555 Acc:98.08%
Training: Epoch[187/300] Iteration[150/782] Loss: 0.0531 Acc:98.24%
Training: Epoch[187/300] Iteration[200/782] Loss: 0.0529 Acc:98.30%
Training: Epoch[187/300] Iteration[250/782] Loss: 0.0542 Acc:98.26%
Training: Epoch[187/300] Iteration[300/782] Loss: 0.0552 Acc:98.19%
Training: Epoch[187/300] Iteration[350/782] Loss: 0.0564 Acc:98.12%
Training: Epoch[187/300] Iteration[400/782] Loss: 0.0577 Acc:98.05%
Training: Epoch[187/300] Iteration[450/782] Loss: 0.0577 Acc:98.04%
Training: Epoch[187/300] Iteration[500/782] Loss: 0.0584 Acc:98.03%
Training: Epoch[187/300] Iteration[550/782] Loss: 0.0579 Acc:98.04%
Training: Epoch[187/300] Iteration[600/782] Loss: 0.0576 Acc:98.04%
Training: Epoch[187/300] Iteration[650/782] Loss: 0.0577 Acc:98.03%
Training: Epoch[187/300] Iteration[700/782] Loss: 0.0585 Acc:97.98%
Training: Epoch[187/300] Iteration[750/782] Loss: 0.0585 Acc:97.98%
Epoch[187/300] Train Acc: 97.97% Valid Acc:92.69% Train loss:0.0589 Valid loss:0.2653 LR:0.010000000000000002
Training: Epoch[188/300] Iteration[050/782] Loss: 0.0611 Acc:98.03%
Training: Epoch[188/300] Iteration[100/782] Loss: 0.0551 Acc:98.19%
Training: Epoch[188/300] Iteration[150/782] Loss: 0.0569 Acc:98.09%
Training: Epoch[188/300] Iteration[200/782] Loss: 0.0589 Acc:97.95%
Training: Epoch[188/300] Iteration[250/782] Loss: 0.0589 Acc:98.01%
Training: Epoch[188/300] Iteration[300/782] Loss: 0.0600 Acc:97.94%
Training: Epoch[188/300] Iteration[350/782] Loss: 0.0601 Acc:97.95%
Training: Epoch[188/300] Iteration[400/782] Loss: 0.0603 Acc:97.95%
Training: Epoch[188/300] Iteration[450/782] Loss: 0.0595 Acc:98.00%
Training: Epoch[188/300] Iteration[500/782] Loss: 0.0593 Acc:97.98%
Training: Epoch[188/300] Iteration[550/782] Loss: 0.0594 Acc:97.98%
Training: Epoch[188/300] Iteration[600/782] Loss: 0.0590 Acc:98.01%
Training: Epoch[188/300] Iteration[650/782] Loss: 0.0598 Acc:97.97%
Training: Epoch[188/300] Iteration[700/782] Loss: 0.0607 Acc:97.93%
Training: Epoch[188/300] Iteration[750/782] Loss: 0.0612 Acc:97.92%
Epoch[188/300] Train Acc: 97.93% Valid Acc:92.73% Train loss:0.0612 Valid loss:0.2703 LR:0.010000000000000002
Training: Epoch[189/300] Iteration[050/782] Loss: 0.0599 Acc:98.06%
Training: Epoch[189/300] Iteration[100/782] Loss: 0.0587 Acc:98.03%
Training: Epoch[189/300] Iteration[150/782] Loss: 0.0581 Acc:98.05%
Training: Epoch[189/300] Iteration[200/782] Loss: 0.0567 Acc:98.05%
Training: Epoch[189/300] Iteration[250/782] Loss: 0.0568 Acc:98.04%
Training: Epoch[189/300] Iteration[300/782] Loss: 0.0580 Acc:98.00%
Training: Epoch[189/300] Iteration[350/782] Loss: 0.0591 Acc:98.02%
Training: Epoch[189/300] Iteration[400/782] Loss: 0.0591 Acc:98.02%
Training: Epoch[189/300] Iteration[450/782] Loss: 0.0591 Acc:98.00%
Training: Epoch[189/300] Iteration[500/782] Loss: 0.0588 Acc:97.98%
Training: Epoch[189/300] Iteration[550/782] Loss: 0.0598 Acc:97.95%
Training: Epoch[189/300] Iteration[600/782] Loss: 0.0594 Acc:97.97%
Training: Epoch[189/300] Iteration[650/782] Loss: 0.0591 Acc:97.96%
Training: Epoch[189/300] Iteration[700/782] Loss: 0.0595 Acc:97.95%
Training: Epoch[189/300] Iteration[750/782] Loss: 0.0594 Acc:97.96%
Epoch[189/300] Train Acc: 97.98% Valid Acc:92.73% Train loss:0.0591 Valid loss:0.2672 LR:0.010000000000000002
Training: Epoch[190/300] Iteration[050/782] Loss: 0.0509 Acc:98.31%
Training: Epoch[190/300] Iteration[100/782] Loss: 0.0512 Acc:98.30%
Training: Epoch[190/300] Iteration[150/782] Loss: 0.0502 Acc:98.28%
Training: Epoch[190/300] Iteration[200/782] Loss: 0.0529 Acc:98.19%
Training: Epoch[190/300] Iteration[250/782] Loss: 0.0519 Acc:98.23%
Training: Epoch[190/300] Iteration[300/782] Loss: 0.0542 Acc:98.14%
Training: Epoch[190/300] Iteration[350/782] Loss: 0.0554 Acc:98.10%
Training: Epoch[190/300] Iteration[400/782] Loss: 0.0554 Acc:98.12%
Training: Epoch[190/300] Iteration[450/782] Loss: 0.0560 Acc:98.12%
Training: Epoch[190/300] Iteration[500/782] Loss: 0.0564 Acc:98.08%
Training: Epoch[190/300] Iteration[550/782] Loss: 0.0560 Acc:98.09%
Training: Epoch[190/300] Iteration[600/782] Loss: 0.0556 Acc:98.12%
Training: Epoch[190/300] Iteration[650/782] Loss: 0.0560 Acc:98.11%
Training: Epoch[190/300] Iteration[700/782] Loss: 0.0562 Acc:98.10%
Training: Epoch[190/300] Iteration[750/782] Loss: 0.0572 Acc:98.06%
Epoch[190/300] Train Acc: 98.07% Valid Acc:92.36% Train loss:0.0571 Valid loss:0.2900 LR:0.010000000000000002
Training: Epoch[191/300] Iteration[050/782] Loss: 0.0543 Acc:98.06%
Training: Epoch[191/300] Iteration[100/782] Loss: 0.0549 Acc:98.02%
Training: Epoch[191/300] Iteration[150/782] Loss: 0.0593 Acc:97.99%
Training: Epoch[191/300] Iteration[200/782] Loss: 0.0601 Acc:97.95%
Training: Epoch[191/300] Iteration[250/782] Loss: 0.0578 Acc:98.01%
Training: Epoch[191/300] Iteration[300/782] Loss: 0.0565 Acc:98.07%
Training: Epoch[191/300] Iteration[350/782] Loss: 0.0565 Acc:98.06%
Training: Epoch[191/300] Iteration[400/782] Loss: 0.0569 Acc:98.05%
Training: Epoch[191/300] Iteration[450/782] Loss: 0.0572 Acc:98.05%
Training: Epoch[191/300] Iteration[500/782] Loss: 0.0587 Acc:97.97%
Training: Epoch[191/300] Iteration[550/782] Loss: 0.0592 Acc:97.98%
Training: Epoch[191/300] Iteration[600/782] Loss: 0.0594 Acc:97.97%
Training: Epoch[191/300] Iteration[650/782] Loss: 0.0598 Acc:97.97%
Training: Epoch[191/300] Iteration[700/782] Loss: 0.0594 Acc:97.97%
Training: Epoch[191/300] Iteration[750/782] Loss: 0.0596 Acc:97.96%
Epoch[191/300] Train Acc: 97.96% Valid Acc:92.65% Train loss:0.0597 Valid loss:0.2770 LR:0.010000000000000002
Training: Epoch[192/300] Iteration[050/782] Loss: 0.0577 Acc:98.22%
Training: Epoch[192/300] Iteration[100/782] Loss: 0.0514 Acc:98.41%
Training: Epoch[192/300] Iteration[150/782] Loss: 0.0508 Acc:98.35%
Training: Epoch[192/300] Iteration[200/782] Loss: 0.0523 Acc:98.27%
Training: Epoch[192/300] Iteration[250/782] Loss: 0.0506 Acc:98.34%
Training: Epoch[192/300] Iteration[300/782] Loss: 0.0503 Acc:98.31%
Training: Epoch[192/300] Iteration[350/782] Loss: 0.0499 Acc:98.38%
Training: Epoch[192/300] Iteration[400/782] Loss: 0.0502 Acc:98.33%
Training: Epoch[192/300] Iteration[450/782] Loss: 0.0519 Acc:98.26%
Training: Epoch[192/300] Iteration[500/782] Loss: 0.0527 Acc:98.21%
Training: Epoch[192/300] Iteration[550/782] Loss: 0.0528 Acc:98.22%
Training: Epoch[192/300] Iteration[600/782] Loss: 0.0535 Acc:98.20%
Training: Epoch[192/300] Iteration[650/782] Loss: 0.0546 Acc:98.17%
Training: Epoch[192/300] Iteration[700/782] Loss: 0.0551 Acc:98.13%
Training: Epoch[192/300] Iteration[750/782] Loss: 0.0553 Acc:98.15%
Epoch[192/300] Train Acc: 98.11% Valid Acc:92.13% Train loss:0.0558 Valid loss:0.2861 LR:0.010000000000000002
Training: Epoch[193/300] Iteration[050/782] Loss: 0.0476 Acc:98.38%
Training: Epoch[193/300] Iteration[100/782] Loss: 0.0542 Acc:98.16%
Training: Epoch[193/300] Iteration[150/782] Loss: 0.0511 Acc:98.29%
Training: Epoch[193/300] Iteration[200/782] Loss: 0.0522 Acc:98.27%
Training: Epoch[193/300] Iteration[250/782] Loss: 0.0533 Acc:98.19%
Training: Epoch[193/300] Iteration[300/782] Loss: 0.0525 Acc:98.21%
Training: Epoch[193/300] Iteration[350/782] Loss: 0.0525 Acc:98.22%
Training: Epoch[193/300] Iteration[400/782] Loss: 0.0524 Acc:98.23%
Training: Epoch[193/300] Iteration[450/782] Loss: 0.0521 Acc:98.23%
Training: Epoch[193/300] Iteration[500/782] Loss: 0.0532 Acc:98.21%
Training: Epoch[193/300] Iteration[550/782] Loss: 0.0534 Acc:98.20%
Training: Epoch[193/300] Iteration[600/782] Loss: 0.0535 Acc:98.19%
Training: Epoch[193/300] Iteration[650/782] Loss: 0.0534 Acc:98.18%
Training: Epoch[193/300] Iteration[700/782] Loss: 0.0543 Acc:98.15%
Training: Epoch[193/300] Iteration[750/782] Loss: 0.0549 Acc:98.13%
Epoch[193/300] Train Acc: 98.13% Valid Acc:92.50% Train loss:0.0552 Valid loss:0.2707 LR:0.010000000000000002
Training: Epoch[194/300] Iteration[050/782] Loss: 0.0536 Acc:98.12%
Training: Epoch[194/300] Iteration[100/782] Loss: 0.0511 Acc:98.22%
Training: Epoch[194/300] Iteration[150/782] Loss: 0.0513 Acc:98.31%
Training: Epoch[194/300] Iteration[200/782] Loss: 0.0527 Acc:98.26%
Training: Epoch[194/300] Iteration[250/782] Loss: 0.0556 Acc:98.15%
Training: Epoch[194/300] Iteration[300/782] Loss: 0.0559 Acc:98.15%
Training: Epoch[194/300] Iteration[350/782] Loss: 0.0568 Acc:98.09%
Training: Epoch[194/300] Iteration[400/782] Loss: 0.0576 Acc:98.04%
Training: Epoch[194/300] Iteration[450/782] Loss: 0.0575 Acc:98.03%
Training: Epoch[194/300] Iteration[500/782] Loss: 0.0574 Acc:98.00%
Training: Epoch[194/300] Iteration[550/782] Loss: 0.0573 Acc:98.01%
Training: Epoch[194/300] Iteration[600/782] Loss: 0.0569 Acc:98.03%
Training: Epoch[194/300] Iteration[650/782] Loss: 0.0577 Acc:98.00%
Training: Epoch[194/300] Iteration[700/782] Loss: 0.0584 Acc:97.96%
Training: Epoch[194/300] Iteration[750/782] Loss: 0.0589 Acc:97.94%
Epoch[194/300] Train Acc: 97.94% Valid Acc:92.14% Train loss:0.0594 Valid loss:0.2964 LR:0.010000000000000002
Training: Epoch[195/300] Iteration[050/782] Loss: 0.0677 Acc:97.69%
Training: Epoch[195/300] Iteration[100/782] Loss: 0.0587 Acc:97.89%
Training: Epoch[195/300] Iteration[150/782] Loss: 0.0572 Acc:98.00%
Training: Epoch[195/300] Iteration[200/782] Loss: 0.0568 Acc:98.05%
Training: Epoch[195/300] Iteration[250/782] Loss: 0.0565 Acc:98.08%
Training: Epoch[195/300] Iteration[300/782] Loss: 0.0577 Acc:98.03%
Training: Epoch[195/300] Iteration[350/782] Loss: 0.0581 Acc:98.03%
Training: Epoch[195/300] Iteration[400/782] Loss: 0.0592 Acc:97.98%
Training: Epoch[195/300] Iteration[450/782] Loss: 0.0586 Acc:98.02%
Training: Epoch[195/300] Iteration[500/782] Loss: 0.0589 Acc:98.01%
Training: Epoch[195/300] Iteration[550/782] Loss: 0.0587 Acc:97.99%
Training: Epoch[195/300] Iteration[600/782] Loss: 0.0586 Acc:97.99%
Training: Epoch[195/300] Iteration[650/782] Loss: 0.0588 Acc:97.99%
Training: Epoch[195/300] Iteration[700/782] Loss: 0.0587 Acc:97.99%
Training: Epoch[195/300] Iteration[750/782] Loss: 0.0590 Acc:97.98%
Epoch[195/300] Train Acc: 97.99% Valid Acc:92.53% Train loss:0.0590 Valid loss:0.2685 LR:0.010000000000000002
Training: Epoch[196/300] Iteration[050/782] Loss: 0.0494 Acc:98.41%
Training: Epoch[196/300] Iteration[100/782] Loss: 0.0545 Acc:98.08%
Training: Epoch[196/300] Iteration[150/782] Loss: 0.0569 Acc:98.05%
Training: Epoch[196/300] Iteration[200/782] Loss: 0.0569 Acc:98.12%
Training: Epoch[196/300] Iteration[250/782] Loss: 0.0564 Acc:98.15%
Training: Epoch[196/300] Iteration[300/782] Loss: 0.0560 Acc:98.13%
Training: Epoch[196/300] Iteration[350/782] Loss: 0.0566 Acc:98.09%
Training: Epoch[196/300] Iteration[400/782] Loss: 0.0580 Acc:98.00%
Training: Epoch[196/300] Iteration[450/782] Loss: 0.0578 Acc:98.02%
Training: Epoch[196/300] Iteration[500/782] Loss: 0.0575 Acc:98.02%
Training: Epoch[196/300] Iteration[550/782] Loss: 0.0576 Acc:98.02%
Training: Epoch[196/300] Iteration[600/782] Loss: 0.0571 Acc:98.03%
Training: Epoch[196/300] Iteration[650/782] Loss: 0.0571 Acc:98.04%
Training: Epoch[196/300] Iteration[700/782] Loss: 0.0567 Acc:98.07%
Training: Epoch[196/300] Iteration[750/782] Loss: 0.0574 Acc:98.04%
Epoch[196/300] Train Acc: 98.05% Valid Acc:91.93% Train loss:0.0576 Valid loss:0.3010 LR:0.010000000000000002
Training: Epoch[197/300] Iteration[050/782] Loss: 0.0556 Acc:98.12%
Training: Epoch[197/300] Iteration[100/782] Loss: 0.0545 Acc:98.06%
Training: Epoch[197/300] Iteration[150/782] Loss: 0.0543 Acc:98.12%
Training: Epoch[197/300] Iteration[200/782] Loss: 0.0558 Acc:98.06%
Training: Epoch[197/300] Iteration[250/782] Loss: 0.0578 Acc:97.97%
Training: Epoch[197/300] Iteration[300/782] Loss: 0.0565 Acc:98.06%
Training: Epoch[197/300] Iteration[350/782] Loss: 0.0552 Acc:98.11%
Training: Epoch[197/300] Iteration[400/782] Loss: 0.0552 Acc:98.12%
Training: Epoch[197/300] Iteration[450/782] Loss: 0.0545 Acc:98.11%
Training: Epoch[197/300] Iteration[500/782] Loss: 0.0551 Acc:98.08%
Training: Epoch[197/300] Iteration[550/782] Loss: 0.0549 Acc:98.09%
Training: Epoch[197/300] Iteration[600/782] Loss: 0.0548 Acc:98.10%
Training: Epoch[197/300] Iteration[650/782] Loss: 0.0557 Acc:98.07%
Training: Epoch[197/300] Iteration[700/782] Loss: 0.0560 Acc:98.06%
Training: Epoch[197/300] Iteration[750/782] Loss: 0.0564 Acc:98.05%
Epoch[197/300] Train Acc: 98.04% Valid Acc:92.17% Train loss:0.0577 Valid loss:0.2814 LR:0.010000000000000002
Training: Epoch[198/300] Iteration[050/782] Loss: 0.0590 Acc:98.03%
Training: Epoch[198/300] Iteration[100/782] Loss: 0.0519 Acc:98.33%
Training: Epoch[198/300] Iteration[150/782] Loss: 0.0544 Acc:98.15%
Training: Epoch[198/300] Iteration[200/782] Loss: 0.0557 Acc:98.12%
Training: Epoch[198/300] Iteration[250/782] Loss: 0.0570 Acc:98.06%
Training: Epoch[198/300] Iteration[300/782] Loss: 0.0564 Acc:98.08%
Training: Epoch[198/300] Iteration[350/782] Loss: 0.0564 Acc:98.12%
Training: Epoch[198/300] Iteration[400/782] Loss: 0.0562 Acc:98.14%
Training: Epoch[198/300] Iteration[450/782] Loss: 0.0560 Acc:98.14%
Training: Epoch[198/300] Iteration[500/782] Loss: 0.0569 Acc:98.11%
Training: Epoch[198/300] Iteration[550/782] Loss: 0.0575 Acc:98.08%
Training: Epoch[198/300] Iteration[600/782] Loss: 0.0568 Acc:98.09%
Training: Epoch[198/300] Iteration[650/782] Loss: 0.0572 Acc:98.08%
Training: Epoch[198/300] Iteration[700/782] Loss: 0.0578 Acc:98.05%
Training: Epoch[198/300] Iteration[750/782] Loss: 0.0581 Acc:98.03%
Epoch[198/300] Train Acc: 98.00% Valid Acc:92.56% Train loss:0.0590 Valid loss:0.2771 LR:0.010000000000000002
Training: Epoch[199/300] Iteration[050/782] Loss: 0.0445 Acc:98.34%
Training: Epoch[199/300] Iteration[100/782] Loss: 0.0486 Acc:98.22%
Training: Epoch[199/300] Iteration[150/782] Loss: 0.0527 Acc:98.18%
Training: Epoch[199/300] Iteration[200/782] Loss: 0.0550 Acc:98.01%
Training: Epoch[199/300] Iteration[250/782] Loss: 0.0559 Acc:97.97%
Training: Epoch[199/300] Iteration[300/782] Loss: 0.0556 Acc:97.98%
Training: Epoch[199/300] Iteration[350/782] Loss: 0.0555 Acc:98.02%
Training: Epoch[199/300] Iteration[400/782] Loss: 0.0562 Acc:98.00%
Training: Epoch[199/300] Iteration[450/782] Loss: 0.0562 Acc:98.02%
Training: Epoch[199/300] Iteration[500/782] Loss: 0.0563 Acc:98.02%
Training: Epoch[199/300] Iteration[550/782] Loss: 0.0562 Acc:98.05%
Training: Epoch[199/300] Iteration[600/782] Loss: 0.0559 Acc:98.07%
Training: Epoch[199/300] Iteration[650/782] Loss: 0.0568 Acc:98.03%
Training: Epoch[199/300] Iteration[700/782] Loss: 0.0573 Acc:98.02%
Training: Epoch[199/300] Iteration[750/782] Loss: 0.0577 Acc:98.01%
Epoch[199/300] Train Acc: 97.98% Valid Acc:92.41% Train loss:0.0586 Valid loss:0.2695 LR:0.010000000000000002
Training: Epoch[200/300] Iteration[050/782] Loss: 0.0505 Acc:98.12%
Training: Epoch[200/300] Iteration[100/782] Loss: 0.0494 Acc:98.22%
Training: Epoch[200/300] Iteration[150/782] Loss: 0.0506 Acc:98.20%
Training: Epoch[200/300] Iteration[200/782] Loss: 0.0542 Acc:98.03%
Training: Epoch[200/300] Iteration[250/782] Loss: 0.0523 Acc:98.13%
Training: Epoch[200/300] Iteration[300/782] Loss: 0.0526 Acc:98.16%
Training: Epoch[200/300] Iteration[350/782] Loss: 0.0546 Acc:98.09%
Training: Epoch[200/300] Iteration[400/782] Loss: 0.0555 Acc:98.04%
Training: Epoch[200/300] Iteration[450/782] Loss: 0.0553 Acc:98.02%
Training: Epoch[200/300] Iteration[500/782] Loss: 0.0558 Acc:98.02%
Training: Epoch[200/300] Iteration[550/782] Loss: 0.0558 Acc:98.05%
Training: Epoch[200/300] Iteration[600/782] Loss: 0.0558 Acc:98.07%
Training: Epoch[200/300] Iteration[650/782] Loss: 0.0560 Acc:98.06%
Training: Epoch[200/300] Iteration[700/782] Loss: 0.0562 Acc:98.04%
Training: Epoch[200/300] Iteration[750/782] Loss: 0.0570 Acc:98.01%
Epoch[200/300] Train Acc: 98.00% Valid Acc:92.19% Train loss:0.0571 Valid loss:0.2850 LR:0.010000000000000002
Training: Epoch[201/300] Iteration[050/782] Loss: 0.0612 Acc:97.78%
Training: Epoch[201/300] Iteration[100/782] Loss: 0.0577 Acc:97.95%
Training: Epoch[201/300] Iteration[150/782] Loss: 0.0561 Acc:98.08%
Training: Epoch[201/300] Iteration[200/782] Loss: 0.0543 Acc:98.17%
Training: Epoch[201/300] Iteration[250/782] Loss: 0.0542 Acc:98.14%
Training: Epoch[201/300] Iteration[300/782] Loss: 0.0554 Acc:98.11%
Training: Epoch[201/300] Iteration[350/782] Loss: 0.0563 Acc:98.09%
Training: Epoch[201/300] Iteration[400/782] Loss: 0.0565 Acc:98.10%
Training: Epoch[201/300] Iteration[450/782] Loss: 0.0579 Acc:98.06%
Training: Epoch[201/300] Iteration[500/782] Loss: 0.0572 Acc:98.08%
Training: Epoch[201/300] Iteration[550/782] Loss: 0.0582 Acc:98.04%
Training: Epoch[201/300] Iteration[600/782] Loss: 0.0586 Acc:98.02%
Training: Epoch[201/300] Iteration[650/782] Loss: 0.0581 Acc:98.02%
Training: Epoch[201/300] Iteration[700/782] Loss: 0.0585 Acc:98.00%
Training: Epoch[201/300] Iteration[750/782] Loss: 0.0589 Acc:97.97%
Epoch[201/300] Train Acc: 97.91% Valid Acc:91.93% Train loss:0.0606 Valid loss:0.3017 LR:0.010000000000000002
Training: Epoch[202/300] Iteration[050/782] Loss: 0.0526 Acc:98.25%
Training: Epoch[202/300] Iteration[100/782] Loss: 0.0497 Acc:98.33%
Training: Epoch[202/300] Iteration[150/782] Loss: 0.0492 Acc:98.25%
Training: Epoch[202/300] Iteration[200/782] Loss: 0.0535 Acc:98.13%
Training: Epoch[202/300] Iteration[250/782] Loss: 0.0550 Acc:98.09%
Training: Epoch[202/300] Iteration[300/782] Loss: 0.0549 Acc:98.10%
Training: Epoch[202/300] Iteration[350/782] Loss: 0.0566 Acc:98.04%
Training: Epoch[202/300] Iteration[400/782] Loss: 0.0566 Acc:98.05%
Training: Epoch[202/300] Iteration[450/782] Loss: 0.0566 Acc:98.06%
Training: Epoch[202/300] Iteration[500/782] Loss: 0.0572 Acc:98.03%
Training: Epoch[202/300] Iteration[550/782] Loss: 0.0581 Acc:98.00%
Training: Epoch[202/300] Iteration[600/782] Loss: 0.0580 Acc:98.01%
Training: Epoch[202/300] Iteration[650/782] Loss: 0.0579 Acc:98.02%
Training: Epoch[202/300] Iteration[700/782] Loss: 0.0585 Acc:97.98%
Training: Epoch[202/300] Iteration[750/782] Loss: 0.0589 Acc:97.96%
Epoch[202/300] Train Acc: 97.96% Valid Acc:92.16% Train loss:0.0589 Valid loss:0.2851 LR:0.010000000000000002
Training: Epoch[203/300] Iteration[050/782] Loss: 0.0579 Acc:97.81%
Training: Epoch[203/300] Iteration[100/782] Loss: 0.0564 Acc:97.94%
Training: Epoch[203/300] Iteration[150/782] Loss: 0.0557 Acc:97.99%
Training: Epoch[203/300] Iteration[200/782] Loss: 0.0543 Acc:98.11%
Training: Epoch[203/300] Iteration[250/782] Loss: 0.0557 Acc:98.09%
Training: Epoch[203/300] Iteration[300/782] Loss: 0.0550 Acc:98.07%
Training: Epoch[203/300] Iteration[350/782] Loss: 0.0548 Acc:98.09%
Training: Epoch[203/300] Iteration[400/782] Loss: 0.0550 Acc:98.07%
Training: Epoch[203/300] Iteration[450/782] Loss: 0.0561 Acc:98.02%
Training: Epoch[203/300] Iteration[500/782] Loss: 0.0558 Acc:98.04%
Training: Epoch[203/300] Iteration[550/782] Loss: 0.0566 Acc:98.02%
Training: Epoch[203/300] Iteration[600/782] Loss: 0.0564 Acc:98.01%
Training: Epoch[203/300] Iteration[650/782] Loss: 0.0574 Acc:97.96%
Training: Epoch[203/300] Iteration[700/782] Loss: 0.0572 Acc:97.98%
Training: Epoch[203/300] Iteration[750/782] Loss: 0.0577 Acc:97.97%
Epoch[203/300] Train Acc: 97.96% Valid Acc:92.17% Train loss:0.0584 Valid loss:0.2924 LR:0.010000000000000002
Training: Epoch[204/300] Iteration[050/782] Loss: 0.0623 Acc:98.00%
Training: Epoch[204/300] Iteration[100/782] Loss: 0.0554 Acc:98.25%
Training: Epoch[204/300] Iteration[150/782] Loss: 0.0595 Acc:98.03%
Training: Epoch[204/300] Iteration[200/782] Loss: 0.0607 Acc:97.96%
Training: Epoch[204/300] Iteration[250/782] Loss: 0.0644 Acc:97.81%
Training: Epoch[204/300] Iteration[300/782] Loss: 0.0640 Acc:97.81%
Training: Epoch[204/300] Iteration[350/782] Loss: 0.0628 Acc:97.83%
Training: Epoch[204/300] Iteration[400/782] Loss: 0.0618 Acc:97.88%
Training: Epoch[204/300] Iteration[450/782] Loss: 0.0620 Acc:97.86%
Training: Epoch[204/300] Iteration[500/782] Loss: 0.0617 Acc:97.86%
Training: Epoch[204/300] Iteration[550/782] Loss: 0.0611 Acc:97.87%
Training: Epoch[204/300] Iteration[600/782] Loss: 0.0608 Acc:97.87%
Training: Epoch[204/300] Iteration[650/782] Loss: 0.0603 Acc:97.89%
Training: Epoch[204/300] Iteration[700/782] Loss: 0.0596 Acc:97.93%
Training: Epoch[204/300] Iteration[750/782] Loss: 0.0598 Acc:97.91%
Epoch[204/300] Train Acc: 97.88% Valid Acc:91.57% Train loss:0.0604 Valid loss:0.3116 LR:0.010000000000000002
Training: Epoch[205/300] Iteration[050/782] Loss: 0.0584 Acc:97.81%
Training: Epoch[205/300] Iteration[100/782] Loss: 0.0540 Acc:98.06%
Training: Epoch[205/300] Iteration[150/782] Loss: 0.0526 Acc:98.21%
Training: Epoch[205/300] Iteration[200/782] Loss: 0.0527 Acc:98.16%
Training: Epoch[205/300] Iteration[250/782] Loss: 0.0521 Acc:98.15%
Training: Epoch[205/300] Iteration[300/782] Loss: 0.0529 Acc:98.14%
Training: Epoch[205/300] Iteration[350/782] Loss: 0.0535 Acc:98.14%
Training: Epoch[205/300] Iteration[400/782] Loss: 0.0545 Acc:98.16%
Training: Epoch[205/300] Iteration[450/782] Loss: 0.0563 Acc:98.07%
Training: Epoch[205/300] Iteration[500/782] Loss: 0.0567 Acc:98.05%
Training: Epoch[205/300] Iteration[550/782] Loss: 0.0572 Acc:98.05%
Training: Epoch[205/300] Iteration[600/782] Loss: 0.0578 Acc:98.02%
Training: Epoch[205/300] Iteration[650/782] Loss: 0.0592 Acc:97.97%
Training: Epoch[205/300] Iteration[700/782] Loss: 0.0592 Acc:97.97%
Training: Epoch[205/300] Iteration[750/782] Loss: 0.0593 Acc:97.97%
Epoch[205/300] Train Acc: 97.98% Valid Acc:92.27% Train loss:0.0599 Valid loss:0.2891 LR:0.010000000000000002
Training: Epoch[206/300] Iteration[050/782] Loss: 0.0647 Acc:97.59%
Training: Epoch[206/300] Iteration[100/782] Loss: 0.0623 Acc:97.80%
Training: Epoch[206/300] Iteration[150/782] Loss: 0.0613 Acc:97.85%
Training: Epoch[206/300] Iteration[200/782] Loss: 0.0606 Acc:97.91%
Training: Epoch[206/300] Iteration[250/782] Loss: 0.0599 Acc:97.91%
Training: Epoch[206/300] Iteration[300/782] Loss: 0.0604 Acc:97.88%
Training: Epoch[206/300] Iteration[350/782] Loss: 0.0605 Acc:97.86%
Training: Epoch[206/300] Iteration[400/782] Loss: 0.0611 Acc:97.83%
Training: Epoch[206/300] Iteration[450/782] Loss: 0.0613 Acc:97.81%
Training: Epoch[206/300] Iteration[500/782] Loss: 0.0603 Acc:97.85%
Training: Epoch[206/300] Iteration[550/782] Loss: 0.0605 Acc:97.84%
Training: Epoch[206/300] Iteration[600/782] Loss: 0.0607 Acc:97.81%
Training: Epoch[206/300] Iteration[650/782] Loss: 0.0612 Acc:97.80%
Training: Epoch[206/300] Iteration[700/782] Loss: 0.0613 Acc:97.78%
Training: Epoch[206/300] Iteration[750/782] Loss: 0.0615 Acc:97.79%
Epoch[206/300] Train Acc: 97.77% Valid Acc:92.44% Train loss:0.0620 Valid loss:0.2771 LR:0.010000000000000002
Training: Epoch[207/300] Iteration[050/782] Loss: 0.0572 Acc:98.12%
Training: Epoch[207/300] Iteration[100/782] Loss: 0.0566 Acc:98.20%
Training: Epoch[207/300] Iteration[150/782] Loss: 0.0582 Acc:98.19%
Training: Epoch[207/300] Iteration[200/782] Loss: 0.0564 Acc:98.27%
Training: Epoch[207/300] Iteration[250/782] Loss: 0.0551 Acc:98.30%
Training: Epoch[207/300] Iteration[300/782] Loss: 0.0563 Acc:98.24%
Training: Epoch[207/300] Iteration[350/782] Loss: 0.0569 Acc:98.15%
Training: Epoch[207/300] Iteration[400/782] Loss: 0.0593 Acc:98.03%
Training: Epoch[207/300] Iteration[450/782] Loss: 0.0595 Acc:98.01%
Training: Epoch[207/300] Iteration[500/782] Loss: 0.0608 Acc:97.97%
Training: Epoch[207/300] Iteration[550/782] Loss: 0.0610 Acc:97.97%
Training: Epoch[207/300] Iteration[600/782] Loss: 0.0610 Acc:97.98%
Training: Epoch[207/300] Iteration[650/782] Loss: 0.0614 Acc:97.95%
Training: Epoch[207/300] Iteration[700/782] Loss: 0.0618 Acc:97.93%
Training: Epoch[207/300] Iteration[750/782] Loss: 0.0626 Acc:97.89%
Epoch[207/300] Train Acc: 97.87% Valid Acc:92.00% Train loss:0.0629 Valid loss:0.2956 LR:0.010000000000000002
Training: Epoch[208/300] Iteration[050/782] Loss: 0.0598 Acc:97.75%
Training: Epoch[208/300] Iteration[100/782] Loss: 0.0569 Acc:98.00%
Training: Epoch[208/300] Iteration[150/782] Loss: 0.0567 Acc:98.01%
Training: Epoch[208/300] Iteration[200/782] Loss: 0.0574 Acc:97.95%
Training: Epoch[208/300] Iteration[250/782] Loss: 0.0585 Acc:97.97%
Training: Epoch[208/300] Iteration[300/782] Loss: 0.0581 Acc:98.05%
Training: Epoch[208/300] Iteration[350/782] Loss: 0.0574 Acc:98.07%
Training: Epoch[208/300] Iteration[400/782] Loss: 0.0571 Acc:98.06%
Training: Epoch[208/300] Iteration[450/782] Loss: 0.0575 Acc:98.03%
Training: Epoch[208/300] Iteration[500/782] Loss: 0.0571 Acc:98.07%
Training: Epoch[208/300] Iteration[550/782] Loss: 0.0581 Acc:98.02%
Training: Epoch[208/300] Iteration[600/782] Loss: 0.0580 Acc:98.02%
Training: Epoch[208/300] Iteration[650/782] Loss: 0.0585 Acc:98.01%
Training: Epoch[208/300] Iteration[700/782] Loss: 0.0600 Acc:97.95%
Training: Epoch[208/300] Iteration[750/782] Loss: 0.0603 Acc:97.93%
Epoch[208/300] Train Acc: 97.94% Valid Acc:92.22% Train loss:0.0602 Valid loss:0.2862 LR:0.010000000000000002
Training: Epoch[209/300] Iteration[050/782] Loss: 0.0634 Acc:97.72%
Training: Epoch[209/300] Iteration[100/782] Loss: 0.0581 Acc:98.00%
Training: Epoch[209/300] Iteration[150/782] Loss: 0.0591 Acc:98.04%
Training: Epoch[209/300] Iteration[200/782] Loss: 0.0580 Acc:98.06%
Training: Epoch[209/300] Iteration[250/782] Loss: 0.0569 Acc:98.07%
Training: Epoch[209/300] Iteration[300/782] Loss: 0.0589 Acc:98.01%
Training: Epoch[209/300] Iteration[350/782] Loss: 0.0593 Acc:97.98%
Training: Epoch[209/300] Iteration[400/782] Loss: 0.0607 Acc:97.91%
Training: Epoch[209/300] Iteration[450/782] Loss: 0.0608 Acc:97.89%
Training: Epoch[209/300] Iteration[500/782] Loss: 0.0609 Acc:97.87%
Training: Epoch[209/300] Iteration[550/782] Loss: 0.0602 Acc:97.89%
Training: Epoch[209/300] Iteration[600/782] Loss: 0.0588 Acc:97.95%
Training: Epoch[209/300] Iteration[650/782] Loss: 0.0585 Acc:97.97%
Training: Epoch[209/300] Iteration[700/782] Loss: 0.0583 Acc:97.99%
Training: Epoch[209/300] Iteration[750/782] Loss: 0.0585 Acc:97.99%
Epoch[209/300] Train Acc: 98.00% Valid Acc:92.06% Train loss:0.0582 Valid loss:0.2973 LR:0.010000000000000002
Training: Epoch[210/300] Iteration[050/782] Loss: 0.0533 Acc:98.31%
Training: Epoch[210/300] Iteration[100/782] Loss: 0.0569 Acc:98.17%
Training: Epoch[210/300] Iteration[150/782] Loss: 0.0545 Acc:98.27%
Training: Epoch[210/300] Iteration[200/782] Loss: 0.0547 Acc:98.26%
Training: Epoch[210/300] Iteration[250/782] Loss: 0.0572 Acc:98.14%
Training: Epoch[210/300] Iteration[300/782] Loss: 0.0567 Acc:98.11%
Training: Epoch[210/300] Iteration[350/782] Loss: 0.0575 Acc:98.06%
Training: Epoch[210/300] Iteration[400/782] Loss: 0.0578 Acc:98.05%
Training: Epoch[210/300] Iteration[450/782] Loss: 0.0574 Acc:98.03%
Training: Epoch[210/300] Iteration[500/782] Loss: 0.0571 Acc:98.03%
Training: Epoch[210/300] Iteration[550/782] Loss: 0.0569 Acc:98.05%
Training: Epoch[210/300] Iteration[600/782] Loss: 0.0571 Acc:98.04%
Training: Epoch[210/300] Iteration[650/782] Loss: 0.0576 Acc:98.02%
Training: Epoch[210/300] Iteration[700/782] Loss: 0.0578 Acc:98.01%
Training: Epoch[210/300] Iteration[750/782] Loss: 0.0590 Acc:97.98%
Epoch[210/300] Train Acc: 97.97% Valid Acc:92.33% Train loss:0.0593 Valid loss:0.2870 LR:0.010000000000000002
Training: Epoch[211/300] Iteration[050/782] Loss: 0.0626 Acc:97.72%
Training: Epoch[211/300] Iteration[100/782] Loss: 0.0635 Acc:97.58%
Training: Epoch[211/300] Iteration[150/782] Loss: 0.0686 Acc:97.41%
Training: Epoch[211/300] Iteration[200/782] Loss: 0.0649 Acc:97.60%
Training: Epoch[211/300] Iteration[250/782] Loss: 0.0625 Acc:97.74%
Training: Epoch[211/300] Iteration[300/782] Loss: 0.0606 Acc:97.80%
Training: Epoch[211/300] Iteration[350/782] Loss: 0.0600 Acc:97.84%
Training: Epoch[211/300] Iteration[400/782] Loss: 0.0601 Acc:97.84%
Training: Epoch[211/300] Iteration[450/782] Loss: 0.0602 Acc:97.85%
Training: Epoch[211/300] Iteration[500/782] Loss: 0.0595 Acc:97.89%
Training: Epoch[211/300] Iteration[550/782] Loss: 0.0599 Acc:97.86%
Training: Epoch[211/300] Iteration[600/782] Loss: 0.0599 Acc:97.88%
Training: Epoch[211/300] Iteration[650/782] Loss: 0.0603 Acc:97.87%
Training: Epoch[211/300] Iteration[700/782] Loss: 0.0606 Acc:97.85%
Training: Epoch[211/300] Iteration[750/782] Loss: 0.0604 Acc:97.86%
Epoch[211/300] Train Acc: 97.85% Valid Acc:92.01% Train loss:0.0609 Valid loss:0.3034 LR:0.010000000000000002
Training: Epoch[212/300] Iteration[050/782] Loss: 0.0608 Acc:97.78%
Training: Epoch[212/300] Iteration[100/782] Loss: 0.0620 Acc:97.80%
Training: Epoch[212/300] Iteration[150/782] Loss: 0.0635 Acc:97.76%
Training: Epoch[212/300] Iteration[200/782] Loss: 0.0626 Acc:97.82%
Training: Epoch[212/300] Iteration[250/782] Loss: 0.0642 Acc:97.80%
Training: Epoch[212/300] Iteration[300/782] Loss: 0.0628 Acc:97.88%
Training: Epoch[212/300] Iteration[350/782] Loss: 0.0617 Acc:97.91%
Training: Epoch[212/300] Iteration[400/782] Loss: 0.0614 Acc:97.91%
Training: Epoch[212/300] Iteration[450/782] Loss: 0.0605 Acc:97.94%
Training: Epoch[212/300] Iteration[500/782] Loss: 0.0602 Acc:97.96%
Training: Epoch[212/300] Iteration[550/782] Loss: 0.0609 Acc:97.92%
Training: Epoch[212/300] Iteration[600/782] Loss: 0.0624 Acc:97.85%
Training: Epoch[212/300] Iteration[650/782] Loss: 0.0625 Acc:97.82%
Training: Epoch[212/300] Iteration[700/782] Loss: 0.0629 Acc:97.81%
Training: Epoch[212/300] Iteration[750/782] Loss: 0.0636 Acc:97.80%
Epoch[212/300] Train Acc: 97.81% Valid Acc:92.40% Train loss:0.0634 Valid loss:0.2877 LR:0.010000000000000002
Training: Epoch[213/300] Iteration[050/782] Loss: 0.0544 Acc:98.22%
Training: Epoch[213/300] Iteration[100/782] Loss: 0.0573 Acc:97.94%
Training: Epoch[213/300] Iteration[150/782] Loss: 0.0585 Acc:97.97%
Training: Epoch[213/300] Iteration[200/782] Loss: 0.0590 Acc:98.02%
Training: Epoch[213/300] Iteration[250/782] Loss: 0.0595 Acc:97.99%
Training: Epoch[213/300] Iteration[300/782] Loss: 0.0574 Acc:98.10%
Training: Epoch[213/300] Iteration[350/782] Loss: 0.0574 Acc:98.10%
Training: Epoch[213/300] Iteration[400/782] Loss: 0.0576 Acc:98.09%
Training: Epoch[213/300] Iteration[450/782] Loss: 0.0591 Acc:98.03%
Training: Epoch[213/300] Iteration[500/782] Loss: 0.0585 Acc:98.03%
Training: Epoch[213/300] Iteration[550/782] Loss: 0.0581 Acc:98.05%
Training: Epoch[213/300] Iteration[600/782] Loss: 0.0604 Acc:97.95%
Training: Epoch[213/300] Iteration[650/782] Loss: 0.0614 Acc:97.90%
Training: Epoch[213/300] Iteration[700/782] Loss: 0.0613 Acc:97.89%
Training: Epoch[213/300] Iteration[750/782] Loss: 0.0618 Acc:97.88%
Epoch[213/300] Train Acc: 97.89% Valid Acc:91.59% Train loss:0.0614 Valid loss:0.3110 LR:0.010000000000000002
Training: Epoch[214/300] Iteration[050/782] Loss: 0.0609 Acc:97.75%
Training: Epoch[214/300] Iteration[100/782] Loss: 0.0581 Acc:97.89%
Training: Epoch[214/300] Iteration[150/782] Loss: 0.0563 Acc:97.98%
Training: Epoch[214/300] Iteration[200/782] Loss: 0.0579 Acc:97.97%
Training: Epoch[214/300] Iteration[250/782] Loss: 0.0565 Acc:98.01%
Training: Epoch[214/300] Iteration[300/782] Loss: 0.0571 Acc:97.96%
Training: Epoch[214/300] Iteration[350/782] Loss: 0.0575 Acc:97.93%
Training: Epoch[214/300] Iteration[400/782] Loss: 0.0577 Acc:97.94%
Training: Epoch[214/300] Iteration[450/782] Loss: 0.0587 Acc:97.88%
Training: Epoch[214/300] Iteration[500/782] Loss: 0.0594 Acc:97.86%
Training: Epoch[214/300] Iteration[550/782] Loss: 0.0592 Acc:97.86%
Training: Epoch[214/300] Iteration[600/782] Loss: 0.0593 Acc:97.86%
Training: Epoch[214/300] Iteration[650/782] Loss: 0.0593 Acc:97.88%
Training: Epoch[214/300] Iteration[700/782] Loss: 0.0587 Acc:97.92%
Training: Epoch[214/300] Iteration[750/782] Loss: 0.0590 Acc:97.91%
Epoch[214/300] Train Acc: 97.92% Valid Acc:92.35% Train loss:0.0585 Valid loss:0.2776 LR:0.010000000000000002
Training: Epoch[215/300] Iteration[050/782] Loss: 0.0543 Acc:98.06%
Training: Epoch[215/300] Iteration[100/782] Loss: 0.0528 Acc:98.20%
Training: Epoch[215/300] Iteration[150/782] Loss: 0.0516 Acc:98.26%
Training: Epoch[215/300] Iteration[200/782] Loss: 0.0518 Acc:98.22%
Training: Epoch[215/300] Iteration[250/782] Loss: 0.0530 Acc:98.17%
Training: Epoch[215/300] Iteration[300/782] Loss: 0.0539 Acc:98.13%
Training: Epoch[215/300] Iteration[350/782] Loss: 0.0558 Acc:98.05%
Training: Epoch[215/300] Iteration[400/782] Loss: 0.0564 Acc:98.05%
Training: Epoch[215/300] Iteration[450/782] Loss: 0.0564 Acc:98.06%
Training: Epoch[215/300] Iteration[500/782] Loss: 0.0552 Acc:98.11%
Training: Epoch[215/300] Iteration[550/782] Loss: 0.0555 Acc:98.11%
Training: Epoch[215/300] Iteration[600/782] Loss: 0.0562 Acc:98.09%
Training: Epoch[215/300] Iteration[650/782] Loss: 0.0570 Acc:98.05%
Training: Epoch[215/300] Iteration[700/782] Loss: 0.0580 Acc:98.02%
Training: Epoch[215/300] Iteration[750/782] Loss: 0.0586 Acc:97.98%
Epoch[215/300] Train Acc: 97.95% Valid Acc:92.05% Train loss:0.0595 Valid loss:0.3002 LR:0.010000000000000002
Training: Epoch[216/300] Iteration[050/782] Loss: 0.0602 Acc:97.88%
Training: Epoch[216/300] Iteration[100/782] Loss: 0.0582 Acc:97.94%
Training: Epoch[216/300] Iteration[150/782] Loss: 0.0593 Acc:98.01%
Training: Epoch[216/300] Iteration[200/782] Loss: 0.0604 Acc:97.88%
Training: Epoch[216/300] Iteration[250/782] Loss: 0.0607 Acc:97.83%
Training: Epoch[216/300] Iteration[300/782] Loss: 0.0623 Acc:97.77%
Training: Epoch[216/300] Iteration[350/782] Loss: 0.0632 Acc:97.72%
Training: Epoch[216/300] Iteration[400/782] Loss: 0.0644 Acc:97.63%
Training: Epoch[216/300] Iteration[450/782] Loss: 0.0648 Acc:97.63%
Training: Epoch[216/300] Iteration[500/782] Loss: 0.0659 Acc:97.60%
Training: Epoch[216/300] Iteration[550/782] Loss: 0.0659 Acc:97.61%
Training: Epoch[216/300] Iteration[600/782] Loss: 0.0657 Acc:97.62%
Training: Epoch[216/300] Iteration[650/782] Loss: 0.0657 Acc:97.61%
Training: Epoch[216/300] Iteration[700/782] Loss: 0.0650 Acc:97.66%
Training: Epoch[216/300] Iteration[750/782] Loss: 0.0643 Acc:97.69%
Epoch[216/300] Train Acc: 97.69% Valid Acc:92.23% Train loss:0.0644 Valid loss:0.3026 LR:0.010000000000000002
Training: Epoch[217/300] Iteration[050/782] Loss: 0.0548 Acc:98.16%
Training: Epoch[217/300] Iteration[100/782] Loss: 0.0561 Acc:98.14%
Training: Epoch[217/300] Iteration[150/782] Loss: 0.0594 Acc:97.92%
Training: Epoch[217/300] Iteration[200/782] Loss: 0.0610 Acc:97.93%
Training: Epoch[217/300] Iteration[250/782] Loss: 0.0624 Acc:97.92%
Training: Epoch[217/300] Iteration[300/782] Loss: 0.0629 Acc:97.82%
Training: Epoch[217/300] Iteration[350/782] Loss: 0.0640 Acc:97.77%
Training: Epoch[217/300] Iteration[400/782] Loss: 0.0621 Acc:97.86%
Training: Epoch[217/300] Iteration[450/782] Loss: 0.0624 Acc:97.85%
Training: Epoch[217/300] Iteration[500/782] Loss: 0.0627 Acc:97.82%
Training: Epoch[217/300] Iteration[550/782] Loss: 0.0629 Acc:97.81%
Training: Epoch[217/300] Iteration[600/782] Loss: 0.0638 Acc:97.78%
Training: Epoch[217/300] Iteration[650/782] Loss: 0.0643 Acc:97.77%
Training: Epoch[217/300] Iteration[700/782] Loss: 0.0637 Acc:97.79%
Training: Epoch[217/300] Iteration[750/782] Loss: 0.0642 Acc:97.79%
Epoch[217/300] Train Acc: 97.77% Valid Acc:91.84% Train loss:0.0648 Valid loss:0.2941 LR:0.010000000000000002
Training: Epoch[218/300] Iteration[050/782] Loss: 0.0577 Acc:98.06%
Training: Epoch[218/300] Iteration[100/782] Loss: 0.0558 Acc:98.19%
Training: Epoch[218/300] Iteration[150/782] Loss: 0.0550 Acc:98.26%
Training: Epoch[218/300] Iteration[200/782] Loss: 0.0552 Acc:98.23%
Training: Epoch[218/300] Iteration[250/782] Loss: 0.0545 Acc:98.24%
Training: Epoch[218/300] Iteration[300/782] Loss: 0.0569 Acc:98.15%
Training: Epoch[218/300] Iteration[350/782] Loss: 0.0576 Acc:98.12%
Training: Epoch[218/300] Iteration[400/782] Loss: 0.0582 Acc:98.12%
Training: Epoch[218/300] Iteration[450/782] Loss: 0.0588 Acc:98.08%
Training: Epoch[218/300] Iteration[500/782] Loss: 0.0592 Acc:98.08%
Training: Epoch[218/300] Iteration[550/782] Loss: 0.0585 Acc:98.12%
Training: Epoch[218/300] Iteration[600/782] Loss: 0.0577 Acc:98.14%
Training: Epoch[218/300] Iteration[650/782] Loss: 0.0579 Acc:98.11%
Training: Epoch[218/300] Iteration[700/782] Loss: 0.0576 Acc:98.12%
Training: Epoch[218/300] Iteration[750/782] Loss: 0.0576 Acc:98.10%
Epoch[218/300] Train Acc: 98.08% Valid Acc:92.25% Train loss:0.0582 Valid loss:0.2931 LR:0.010000000000000002
Training: Epoch[219/300] Iteration[050/782] Loss: 0.0625 Acc:97.78%
Training: Epoch[219/300] Iteration[100/782] Loss: 0.0610 Acc:97.88%
Training: Epoch[219/300] Iteration[150/782] Loss: 0.0622 Acc:97.80%
Training: Epoch[219/300] Iteration[200/782] Loss: 0.0612 Acc:97.81%
Training: Epoch[219/300] Iteration[250/782] Loss: 0.0602 Acc:97.87%
Training: Epoch[219/300] Iteration[300/782] Loss: 0.0595 Acc:97.91%
Training: Epoch[219/300] Iteration[350/782] Loss: 0.0594 Acc:97.95%
Training: Epoch[219/300] Iteration[400/782] Loss: 0.0601 Acc:97.90%
Training: Epoch[219/300] Iteration[450/782] Loss: 0.0609 Acc:97.86%
Training: Epoch[219/300] Iteration[500/782] Loss: 0.0601 Acc:97.88%
Training: Epoch[219/300] Iteration[550/782] Loss: 0.0607 Acc:97.87%
Training: Epoch[219/300] Iteration[600/782] Loss: 0.0609 Acc:97.86%
Training: Epoch[219/300] Iteration[650/782] Loss: 0.0610 Acc:97.86%
Training: Epoch[219/300] Iteration[700/782] Loss: 0.0612 Acc:97.84%
Training: Epoch[219/300] Iteration[750/782] Loss: 0.0611 Acc:97.84%
Epoch[219/300] Train Acc: 97.84% Valid Acc:92.10% Train loss:0.0611 Valid loss:0.3007 LR:0.010000000000000002
Training: Epoch[220/300] Iteration[050/782] Loss: 0.0522 Acc:98.22%
Training: Epoch[220/300] Iteration[100/782] Loss: 0.0539 Acc:98.16%
Training: Epoch[220/300] Iteration[150/782] Loss: 0.0595 Acc:97.99%
Training: Epoch[220/300] Iteration[200/782] Loss: 0.0597 Acc:98.00%
Training: Epoch[220/300] Iteration[250/782] Loss: 0.0589 Acc:98.03%
Training: Epoch[220/300] Iteration[300/782] Loss: 0.0596 Acc:97.99%
Training: Epoch[220/300] Iteration[350/782] Loss: 0.0611 Acc:97.92%
Training: Epoch[220/300] Iteration[400/782] Loss: 0.0622 Acc:97.86%
Training: Epoch[220/300] Iteration[450/782] Loss: 0.0612 Acc:97.91%
Training: Epoch[220/300] Iteration[500/782] Loss: 0.0618 Acc:97.86%
Training: Epoch[220/300] Iteration[550/782] Loss: 0.0619 Acc:97.85%
Training: Epoch[220/300] Iteration[600/782] Loss: 0.0614 Acc:97.86%
Training: Epoch[220/300] Iteration[650/782] Loss: 0.0621 Acc:97.84%
Training: Epoch[220/300] Iteration[700/782] Loss: 0.0620 Acc:97.84%
Training: Epoch[220/300] Iteration[750/782] Loss: 0.0630 Acc:97.80%
Epoch[220/300] Train Acc: 97.79% Valid Acc:92.34% Train loss:0.0631 Valid loss:0.2743 LR:0.010000000000000002
Training: Epoch[221/300] Iteration[050/782] Loss: 0.0656 Acc:97.56%
Training: Epoch[221/300] Iteration[100/782] Loss: 0.0626 Acc:97.67%
Training: Epoch[221/300] Iteration[150/782] Loss: 0.0622 Acc:97.69%
Training: Epoch[221/300] Iteration[200/782] Loss: 0.0608 Acc:97.78%
Training: Epoch[221/300] Iteration[250/782] Loss: 0.0599 Acc:97.81%
Training: Epoch[221/300] Iteration[300/782] Loss: 0.0612 Acc:97.81%
Training: Epoch[221/300] Iteration[350/782] Loss: 0.0623 Acc:97.75%
Training: Epoch[221/300] Iteration[400/782] Loss: 0.0631 Acc:97.72%
Training: Epoch[221/300] Iteration[450/782] Loss: 0.0638 Acc:97.66%
Training: Epoch[221/300] Iteration[500/782] Loss: 0.0627 Acc:97.72%
Training: Epoch[221/300] Iteration[550/782] Loss: 0.0631 Acc:97.72%
Training: Epoch[221/300] Iteration[600/782] Loss: 0.0630 Acc:97.75%
Training: Epoch[221/300] Iteration[650/782] Loss: 0.0632 Acc:97.75%
Training: Epoch[221/300] Iteration[700/782] Loss: 0.0633 Acc:97.74%
Training: Epoch[221/300] Iteration[750/782] Loss: 0.0634 Acc:97.74%
Epoch[221/300] Train Acc: 97.74% Valid Acc:91.56% Train loss:0.0638 Valid loss:0.3064 LR:0.010000000000000002
Training: Epoch[222/300] Iteration[050/782] Loss: 0.0591 Acc:97.75%
Training: Epoch[222/300] Iteration[100/782] Loss: 0.0596 Acc:97.83%
Training: Epoch[222/300] Iteration[150/782] Loss: 0.0577 Acc:97.83%
Training: Epoch[222/300] Iteration[200/782] Loss: 0.0602 Acc:97.83%
Training: Epoch[222/300] Iteration[250/782] Loss: 0.0614 Acc:97.79%
Training: Epoch[222/300] Iteration[300/782] Loss: 0.0627 Acc:97.74%
Training: Epoch[222/300] Iteration[350/782] Loss: 0.0632 Acc:97.74%
Training: Epoch[222/300] Iteration[400/782] Loss: 0.0640 Acc:97.71%
Training: Epoch[222/300] Iteration[450/782] Loss: 0.0643 Acc:97.71%
Training: Epoch[222/300] Iteration[500/782] Loss: 0.0655 Acc:97.68%
Training: Epoch[222/300] Iteration[550/782] Loss: 0.0669 Acc:97.62%
Training: Epoch[222/300] Iteration[600/782] Loss: 0.0664 Acc:97.62%
Training: Epoch[222/300] Iteration[650/782] Loss: 0.0662 Acc:97.64%
Training: Epoch[222/300] Iteration[700/782] Loss: 0.0658 Acc:97.67%
Training: Epoch[222/300] Iteration[750/782] Loss: 0.0654 Acc:97.69%
Epoch[222/300] Train Acc: 97.67% Valid Acc:91.99% Train loss:0.0657 Valid loss:0.2940 LR:0.010000000000000002
Training: Epoch[223/300] Iteration[050/782] Loss: 0.0576 Acc:97.75%
Training: Epoch[223/300] Iteration[100/782] Loss: 0.0576 Acc:97.80%
Training: Epoch[223/300] Iteration[150/782] Loss: 0.0590 Acc:97.86%
Training: Epoch[223/300] Iteration[200/782] Loss: 0.0602 Acc:97.89%
Training: Epoch[223/300] Iteration[250/782] Loss: 0.0627 Acc:97.78%
Training: Epoch[223/300] Iteration[300/782] Loss: 0.0626 Acc:97.76%
Training: Epoch[223/300] Iteration[350/782] Loss: 0.0618 Acc:97.81%
Training: Epoch[223/300] Iteration[400/782] Loss: 0.0604 Acc:97.89%
Training: Epoch[223/300] Iteration[450/782] Loss: 0.0602 Acc:97.90%
Training: Epoch[223/300] Iteration[500/782] Loss: 0.0611 Acc:97.88%
Training: Epoch[223/300] Iteration[550/782] Loss: 0.0614 Acc:97.86%
Training: Epoch[223/300] Iteration[600/782] Loss: 0.0618 Acc:97.84%
Training: Epoch[223/300] Iteration[650/782] Loss: 0.0617 Acc:97.84%
Training: Epoch[223/300] Iteration[700/782] Loss: 0.0617 Acc:97.83%
Training: Epoch[223/300] Iteration[750/782] Loss: 0.0616 Acc:97.85%
Epoch[223/300] Train Acc: 97.83% Valid Acc:91.64% Train loss:0.0621 Valid loss:0.3198 LR:0.010000000000000002
Training: Epoch[224/300] Iteration[050/782] Loss: 0.0671 Acc:98.00%
Training: Epoch[224/300] Iteration[100/782] Loss: 0.0627 Acc:98.03%
Training: Epoch[224/300] Iteration[150/782] Loss: 0.0602 Acc:98.02%
Training: Epoch[224/300] Iteration[200/782] Loss: 0.0596 Acc:98.06%
Training: Epoch[224/300] Iteration[250/782] Loss: 0.0613 Acc:97.99%
Training: Epoch[224/300] Iteration[300/782] Loss: 0.0598 Acc:98.05%
Training: Epoch[224/300] Iteration[350/782] Loss: 0.0593 Acc:98.01%
Training: Epoch[224/300] Iteration[400/782] Loss: 0.0580 Acc:98.06%
Training: Epoch[224/300] Iteration[450/782] Loss: 0.0591 Acc:98.00%
Training: Epoch[224/300] Iteration[500/782] Loss: 0.0591 Acc:98.02%
Training: Epoch[224/300] Iteration[550/782] Loss: 0.0602 Acc:97.99%
Training: Epoch[224/300] Iteration[600/782] Loss: 0.0610 Acc:97.94%
Training: Epoch[224/300] Iteration[650/782] Loss: 0.0603 Acc:97.97%
Training: Epoch[224/300] Iteration[700/782] Loss: 0.0609 Acc:97.95%
Training: Epoch[224/300] Iteration[750/782] Loss: 0.0616 Acc:97.92%
Epoch[224/300] Train Acc: 97.90% Valid Acc:92.43% Train loss:0.0618 Valid loss:0.2860 LR:0.010000000000000002
Training: Epoch[225/300] Iteration[050/782] Loss: 0.0550 Acc:97.97%
Training: Epoch[225/300] Iteration[100/782] Loss: 0.0554 Acc:98.11%
Training: Epoch[225/300] Iteration[150/782] Loss: 0.0571 Acc:98.06%
Training: Epoch[225/300] Iteration[200/782] Loss: 0.0577 Acc:98.02%
Training: Epoch[225/300] Iteration[250/782] Loss: 0.0565 Acc:98.09%
Training: Epoch[225/300] Iteration[300/782] Loss: 0.0574 Acc:98.07%
Training: Epoch[225/300] Iteration[350/782] Loss: 0.0593 Acc:98.00%
Training: Epoch[225/300] Iteration[400/782] Loss: 0.0621 Acc:97.87%
Training: Epoch[225/300] Iteration[450/782] Loss: 0.0621 Acc:97.89%
Training: Epoch[225/300] Iteration[500/782] Loss: 0.0622 Acc:97.88%
Training: Epoch[225/300] Iteration[550/782] Loss: 0.0620 Acc:97.86%
Training: Epoch[225/300] Iteration[600/782] Loss: 0.0625 Acc:97.85%
Training: Epoch[225/300] Iteration[650/782] Loss: 0.0622 Acc:97.85%
Training: Epoch[225/300] Iteration[700/782] Loss: 0.0630 Acc:97.80%
Training: Epoch[225/300] Iteration[750/782] Loss: 0.0629 Acc:97.80%
Epoch[225/300] Train Acc: 97.80% Valid Acc:92.19% Train loss:0.0631 Valid loss:0.2932 LR:0.010000000000000002
Training: Epoch[226/300] Iteration[050/782] Loss: 0.0482 Acc:98.34%
Training: Epoch[226/300] Iteration[100/782] Loss: 0.0482 Acc:98.41%
Training: Epoch[226/300] Iteration[150/782] Loss: 0.0496 Acc:98.36%
Training: Epoch[226/300] Iteration[200/782] Loss: 0.0494 Acc:98.33%
Training: Epoch[226/300] Iteration[250/782] Loss: 0.0489 Acc:98.33%
Training: Epoch[226/300] Iteration[300/782] Loss: 0.0481 Acc:98.38%
Training: Epoch[226/300] Iteration[350/782] Loss: 0.0474 Acc:98.41%
Training: Epoch[226/300] Iteration[400/782] Loss: 0.0459 Acc:98.48%
Training: Epoch[226/300] Iteration[450/782] Loss: 0.0461 Acc:98.48%
Training: Epoch[226/300] Iteration[500/782] Loss: 0.0457 Acc:98.47%
Training: Epoch[226/300] Iteration[550/782] Loss: 0.0449 Acc:98.49%
Training: Epoch[226/300] Iteration[600/782] Loss: 0.0442 Acc:98.54%
Training: Epoch[226/300] Iteration[650/782] Loss: 0.0434 Acc:98.57%
Training: Epoch[226/300] Iteration[700/782] Loss: 0.0430 Acc:98.58%
Training: Epoch[226/300] Iteration[750/782] Loss: 0.0426 Acc:98.61%
Epoch[226/300] Train Acc: 98.63% Valid Acc:92.59% Train loss:0.0425 Valid loss:0.2653 LR:0.0010000000000000002
Training: Epoch[227/300] Iteration[050/782] Loss: 0.0332 Acc:98.97%
Training: Epoch[227/300] Iteration[100/782] Loss: 0.0336 Acc:98.95%
Training: Epoch[227/300] Iteration[150/782] Loss: 0.0335 Acc:98.97%
Training: Epoch[227/300] Iteration[200/782] Loss: 0.0320 Acc:99.04%
Training: Epoch[227/300] Iteration[250/782] Loss: 0.0330 Acc:98.98%
Training: Epoch[227/300] Iteration[300/782] Loss: 0.0335 Acc:98.97%
Training: Epoch[227/300] Iteration[350/782] Loss: 0.0337 Acc:98.98%
Training: Epoch[227/300] Iteration[400/782] Loss: 0.0333 Acc:99.00%
Training: Epoch[227/300] Iteration[450/782] Loss: 0.0339 Acc:98.95%
Training: Epoch[227/300] Iteration[500/782] Loss: 0.0334 Acc:98.97%
Training: Epoch[227/300] Iteration[550/782] Loss: 0.0332 Acc:98.97%
Training: Epoch[227/300] Iteration[600/782] Loss: 0.0332 Acc:98.97%
Training: Epoch[227/300] Iteration[650/782] Loss: 0.0335 Acc:98.97%
Training: Epoch[227/300] Iteration[700/782] Loss: 0.0331 Acc:98.99%
Training: Epoch[227/300] Iteration[750/782] Loss: 0.0328 Acc:99.00%
Epoch[227/300] Train Acc: 99.01% Valid Acc:92.83% Train loss:0.0326 Valid loss:0.2589 LR:0.0010000000000000002
Training: Epoch[228/300] Iteration[050/782] Loss: 0.0263 Acc:99.38%
Training: Epoch[228/300] Iteration[100/782] Loss: 0.0292 Acc:99.22%
Training: Epoch[228/300] Iteration[150/782] Loss: 0.0312 Acc:99.11%
Training: Epoch[228/300] Iteration[200/782] Loss: 0.0316 Acc:99.11%
Training: Epoch[228/300] Iteration[250/782] Loss: 0.0308 Acc:99.11%
Training: Epoch[228/300] Iteration[300/782] Loss: 0.0303 Acc:99.12%
Training: Epoch[228/300] Iteration[350/782] Loss: 0.0301 Acc:99.13%
Training: Epoch[228/300] Iteration[400/782] Loss: 0.0307 Acc:99.10%
Training: Epoch[228/300] Iteration[450/782] Loss: 0.0302 Acc:99.13%
Training: Epoch[228/300] Iteration[500/782] Loss: 0.0304 Acc:99.14%
Training: Epoch[228/300] Iteration[550/782] Loss: 0.0304 Acc:99.14%
Training: Epoch[228/300] Iteration[600/782] Loss: 0.0304 Acc:99.14%
Training: Epoch[228/300] Iteration[650/782] Loss: 0.0305 Acc:99.12%
Training: Epoch[228/300] Iteration[700/782] Loss: 0.0306 Acc:99.11%
Training: Epoch[228/300] Iteration[750/782] Loss: 0.0303 Acc:99.12%
Epoch[228/300] Train Acc: 99.12% Valid Acc:93.03% Train loss:0.0305 Valid loss:0.2587 LR:0.0010000000000000002
Training: Epoch[229/300] Iteration[050/782] Loss: 0.0302 Acc:99.16%
Training: Epoch[229/300] Iteration[100/782] Loss: 0.0289 Acc:99.19%
Training: Epoch[229/300] Iteration[150/782] Loss: 0.0288 Acc:99.19%
Training: Epoch[229/300] Iteration[200/782] Loss: 0.0283 Acc:99.25%
Training: Epoch[229/300] Iteration[250/782] Loss: 0.0281 Acc:99.25%
Training: Epoch[229/300] Iteration[300/782] Loss: 0.0284 Acc:99.25%
Training: Epoch[229/300] Iteration[350/782] Loss: 0.0291 Acc:99.21%
Training: Epoch[229/300] Iteration[400/782] Loss: 0.0294 Acc:99.18%
Training: Epoch[229/300] Iteration[450/782] Loss: 0.0296 Acc:99.15%
Training: Epoch[229/300] Iteration[500/782] Loss: 0.0300 Acc:99.14%
Training: Epoch[229/300] Iteration[550/782] Loss: 0.0298 Acc:99.16%
Training: Epoch[229/300] Iteration[600/782] Loss: 0.0293 Acc:99.16%
Training: Epoch[229/300] Iteration[650/782] Loss: 0.0291 Acc:99.16%
Training: Epoch[229/300] Iteration[700/782] Loss: 0.0291 Acc:99.16%
Training: Epoch[229/300] Iteration[750/782] Loss: 0.0290 Acc:99.18%
Epoch[229/300] Train Acc: 99.18% Valid Acc:92.97% Train loss:0.0290 Valid loss:0.2634 LR:0.0010000000000000002
Training: Epoch[230/300] Iteration[050/782] Loss: 0.0332 Acc:98.97%
Training: Epoch[230/300] Iteration[100/782] Loss: 0.0277 Acc:99.28%
Training: Epoch[230/300] Iteration[150/782] Loss: 0.0257 Acc:99.34%
Training: Epoch[230/300] Iteration[200/782] Loss: 0.0270 Acc:99.27%
Training: Epoch[230/300] Iteration[250/782] Loss: 0.0265 Acc:99.28%
Training: Epoch[230/300] Iteration[300/782] Loss: 0.0265 Acc:99.29%
Training: Epoch[230/300] Iteration[350/782] Loss: 0.0265 Acc:99.28%
Training: Epoch[230/300] Iteration[400/782] Loss: 0.0265 Acc:99.28%
Training: Epoch[230/300] Iteration[450/782] Loss: 0.0262 Acc:99.29%
Training: Epoch[230/300] Iteration[500/782] Loss: 0.0260 Acc:99.31%
Training: Epoch[230/300] Iteration[550/782] Loss: 0.0267 Acc:99.27%
Training: Epoch[230/300] Iteration[600/782] Loss: 0.0268 Acc:99.28%
Training: Epoch[230/300] Iteration[650/782] Loss: 0.0265 Acc:99.28%
Training: Epoch[230/300] Iteration[700/782] Loss: 0.0263 Acc:99.29%
Training: Epoch[230/300] Iteration[750/782] Loss: 0.0263 Acc:99.28%
Epoch[230/300] Train Acc: 99.28% Valid Acc:93.06% Train loss:0.0263 Valid loss:0.2622 LR:0.0010000000000000002
Training: Epoch[231/300] Iteration[050/782] Loss: 0.0219 Acc:99.34%
Training: Epoch[231/300] Iteration[100/782] Loss: 0.0230 Acc:99.36%
Training: Epoch[231/300] Iteration[150/782] Loss: 0.0231 Acc:99.32%
Training: Epoch[231/300] Iteration[200/782] Loss: 0.0250 Acc:99.24%
Training: Epoch[231/300] Iteration[250/782] Loss: 0.0244 Acc:99.30%
Training: Epoch[231/300] Iteration[300/782] Loss: 0.0254 Acc:99.30%
Training: Epoch[231/300] Iteration[350/782] Loss: 0.0250 Acc:99.32%
Training: Epoch[231/300] Iteration[400/782] Loss: 0.0249 Acc:99.33%
Training: Epoch[231/300] Iteration[450/782] Loss: 0.0246 Acc:99.32%
Training: Epoch[231/300] Iteration[500/782] Loss: 0.0252 Acc:99.30%
Training: Epoch[231/300] Iteration[550/782] Loss: 0.0254 Acc:99.29%
Training: Epoch[231/300] Iteration[600/782] Loss: 0.0258 Acc:99.27%
Training: Epoch[231/300] Iteration[650/782] Loss: 0.0257 Acc:99.27%
Training: Epoch[231/300] Iteration[700/782] Loss: 0.0255 Acc:99.28%
Training: Epoch[231/300] Iteration[750/782] Loss: 0.0254 Acc:99.29%
Epoch[231/300] Train Acc: 99.29% Valid Acc:93.20% Train loss:0.0258 Valid loss:0.2574 LR:0.0010000000000000002
Training: Epoch[232/300] Iteration[050/782] Loss: 0.0234 Acc:99.34%
Training: Epoch[232/300] Iteration[100/782] Loss: 0.0262 Acc:99.28%
Training: Epoch[232/300] Iteration[150/782] Loss: 0.0248 Acc:99.28%
Training: Epoch[232/300] Iteration[200/782] Loss: 0.0243 Acc:99.30%
Training: Epoch[232/300] Iteration[250/782] Loss: 0.0244 Acc:99.26%
Training: Epoch[232/300] Iteration[300/782] Loss: 0.0244 Acc:99.30%
Training: Epoch[232/300] Iteration[350/782] Loss: 0.0241 Acc:99.30%
Training: Epoch[232/300] Iteration[400/782] Loss: 0.0238 Acc:99.32%
Training: Epoch[232/300] Iteration[450/782] Loss: 0.0239 Acc:99.33%
Training: Epoch[232/300] Iteration[500/782] Loss: 0.0243 Acc:99.32%
Training: Epoch[232/300] Iteration[550/782] Loss: 0.0243 Acc:99.33%
Training: Epoch[232/300] Iteration[600/782] Loss: 0.0245 Acc:99.33%
Training: Epoch[232/300] Iteration[650/782] Loss: 0.0244 Acc:99.33%
Training: Epoch[232/300] Iteration[700/782] Loss: 0.0246 Acc:99.32%
Training: Epoch[232/300] Iteration[750/782] Loss: 0.0244 Acc:99.33%
Epoch[232/300] Train Acc: 99.32% Valid Acc:93.16% Train loss:0.0251 Valid loss:0.2619 LR:0.0010000000000000002
Training: Epoch[233/300] Iteration[050/782] Loss: 0.0217 Acc:99.41%
Training: Epoch[233/300] Iteration[100/782] Loss: 0.0222 Acc:99.39%
Training: Epoch[233/300] Iteration[150/782] Loss: 0.0243 Acc:99.32%
Training: Epoch[233/300] Iteration[200/782] Loss: 0.0237 Acc:99.36%
Training: Epoch[233/300] Iteration[250/782] Loss: 0.0244 Acc:99.33%
Training: Epoch[233/300] Iteration[300/782] Loss: 0.0237 Acc:99.36%
Training: Epoch[233/300] Iteration[350/782] Loss: 0.0236 Acc:99.35%
Training: Epoch[233/300] Iteration[400/782] Loss: 0.0233 Acc:99.36%
Training: Epoch[233/300] Iteration[450/782] Loss: 0.0236 Acc:99.35%
Training: Epoch[233/300] Iteration[500/782] Loss: 0.0238 Acc:99.34%
Training: Epoch[233/300] Iteration[550/782] Loss: 0.0240 Acc:99.32%
Training: Epoch[233/300] Iteration[600/782] Loss: 0.0241 Acc:99.31%
Training: Epoch[233/300] Iteration[650/782] Loss: 0.0240 Acc:99.32%
Training: Epoch[233/300] Iteration[700/782] Loss: 0.0240 Acc:99.32%
Training: Epoch[233/300] Iteration[750/782] Loss: 0.0239 Acc:99.32%
Epoch[233/300] Train Acc: 99.32% Valid Acc:93.36% Train loss:0.0240 Valid loss:0.2565 LR:0.0010000000000000002
Training: Epoch[234/300] Iteration[050/782] Loss: 0.0255 Acc:99.25%
Training: Epoch[234/300] Iteration[100/782] Loss: 0.0247 Acc:99.36%
Training: Epoch[234/300] Iteration[150/782] Loss: 0.0234 Acc:99.40%
Training: Epoch[234/300] Iteration[200/782] Loss: 0.0232 Acc:99.36%
Training: Epoch[234/300] Iteration[250/782] Loss: 0.0227 Acc:99.41%
Training: Epoch[234/300] Iteration[300/782] Loss: 0.0237 Acc:99.35%
Training: Epoch[234/300] Iteration[350/782] Loss: 0.0235 Acc:99.37%
Training: Epoch[234/300] Iteration[400/782] Loss: 0.0234 Acc:99.37%
Training: Epoch[234/300] Iteration[450/782] Loss: 0.0229 Acc:99.40%
Training: Epoch[234/300] Iteration[500/782] Loss: 0.0227 Acc:99.42%
Training: Epoch[234/300] Iteration[550/782] Loss: 0.0224 Acc:99.43%
Training: Epoch[234/300] Iteration[600/782] Loss: 0.0225 Acc:99.42%
Training: Epoch[234/300] Iteration[650/782] Loss: 0.0227 Acc:99.41%
Training: Epoch[234/300] Iteration[700/782] Loss: 0.0229 Acc:99.40%
Training: Epoch[234/300] Iteration[750/782] Loss: 0.0231 Acc:99.39%
Epoch[234/300] Train Acc: 99.38% Valid Acc:93.26% Train loss:0.0233 Valid loss:0.2573 LR:0.0010000000000000002
Training: Epoch[235/300] Iteration[050/782] Loss: 0.0209 Acc:99.34%
Training: Epoch[235/300] Iteration[100/782] Loss: 0.0216 Acc:99.34%
Training: Epoch[235/300] Iteration[150/782] Loss: 0.0218 Acc:99.36%
Training: Epoch[235/300] Iteration[200/782] Loss: 0.0216 Acc:99.38%
Training: Epoch[235/300] Iteration[250/782] Loss: 0.0217 Acc:99.42%
Training: Epoch[235/300] Iteration[300/782] Loss: 0.0226 Acc:99.39%
Training: Epoch[235/300] Iteration[350/782] Loss: 0.0233 Acc:99.38%
Training: Epoch[235/300] Iteration[400/782] Loss: 0.0230 Acc:99.41%
Training: Epoch[235/300] Iteration[450/782] Loss: 0.0229 Acc:99.40%
Training: Epoch[235/300] Iteration[500/782] Loss: 0.0227 Acc:99.40%
Training: Epoch[235/300] Iteration[550/782] Loss: 0.0226 Acc:99.41%
Training: Epoch[235/300] Iteration[600/782] Loss: 0.0225 Acc:99.42%
Training: Epoch[235/300] Iteration[650/782] Loss: 0.0226 Acc:99.41%
Training: Epoch[235/300] Iteration[700/782] Loss: 0.0225 Acc:99.41%
Training: Epoch[235/300] Iteration[750/782] Loss: 0.0225 Acc:99.40%
Epoch[235/300] Train Acc: 99.40% Valid Acc:93.38% Train loss:0.0224 Valid loss:0.2563 LR:0.0010000000000000002
Training: Epoch[236/300] Iteration[050/782] Loss: 0.0222 Acc:99.31%
Training: Epoch[236/300] Iteration[100/782] Loss: 0.0219 Acc:99.38%
Training: Epoch[236/300] Iteration[150/782] Loss: 0.0229 Acc:99.32%
Training: Epoch[236/300] Iteration[200/782] Loss: 0.0220 Acc:99.38%
Training: Epoch[236/300] Iteration[250/782] Loss: 0.0220 Acc:99.38%
Training: Epoch[236/300] Iteration[300/782] Loss: 0.0216 Acc:99.41%
Training: Epoch[236/300] Iteration[350/782] Loss: 0.0219 Acc:99.40%
Training: Epoch[236/300] Iteration[400/782] Loss: 0.0223 Acc:99.40%
Training: Epoch[236/300] Iteration[450/782] Loss: 0.0229 Acc:99.37%
Training: Epoch[236/300] Iteration[500/782] Loss: 0.0230 Acc:99.37%
Training: Epoch[236/300] Iteration[550/782] Loss: 0.0225 Acc:99.39%
Training: Epoch[236/300] Iteration[600/782] Loss: 0.0224 Acc:99.38%
Training: Epoch[236/300] Iteration[650/782] Loss: 0.0221 Acc:99.39%
Training: Epoch[236/300] Iteration[700/782] Loss: 0.0217 Acc:99.42%
Training: Epoch[236/300] Iteration[750/782] Loss: 0.0218 Acc:99.42%
Epoch[236/300] Train Acc: 99.40% Valid Acc:93.17% Train loss:0.0223 Valid loss:0.2619 LR:0.0010000000000000002
Training: Epoch[237/300] Iteration[050/782] Loss: 0.0207 Acc:99.47%
Training: Epoch[237/300] Iteration[100/782] Loss: 0.0205 Acc:99.55%
Training: Epoch[237/300] Iteration[150/782] Loss: 0.0199 Acc:99.57%
Training: Epoch[237/300] Iteration[200/782] Loss: 0.0203 Acc:99.56%
Training: Epoch[237/300] Iteration[250/782] Loss: 0.0203 Acc:99.57%
Training: Epoch[237/300] Iteration[300/782] Loss: 0.0208 Acc:99.56%
Training: Epoch[237/300] Iteration[350/782] Loss: 0.0210 Acc:99.53%
Training: Epoch[237/300] Iteration[400/782] Loss: 0.0211 Acc:99.54%
Training: Epoch[237/300] Iteration[450/782] Loss: 0.0209 Acc:99.54%
Training: Epoch[237/300] Iteration[500/782] Loss: 0.0209 Acc:99.52%
Training: Epoch[237/300] Iteration[550/782] Loss: 0.0208 Acc:99.52%
Training: Epoch[237/300] Iteration[600/782] Loss: 0.0208 Acc:99.51%
Training: Epoch[237/300] Iteration[650/782] Loss: 0.0208 Acc:99.51%
Training: Epoch[237/300] Iteration[700/782] Loss: 0.0206 Acc:99.50%
Training: Epoch[237/300] Iteration[750/782] Loss: 0.0208 Acc:99.49%
Epoch[237/300] Train Acc: 99.49% Valid Acc:93.36% Train loss:0.0209 Valid loss:0.2578 LR:0.0010000000000000002
Training: Epoch[238/300] Iteration[050/782] Loss: 0.0214 Acc:99.31%
Training: Epoch[238/300] Iteration[100/782] Loss: 0.0208 Acc:99.38%
Training: Epoch[238/300] Iteration[150/782] Loss: 0.0213 Acc:99.42%
Training: Epoch[238/300] Iteration[200/782] Loss: 0.0214 Acc:99.43%
Training: Epoch[238/300] Iteration[250/782] Loss: 0.0212 Acc:99.42%
Training: Epoch[238/300] Iteration[300/782] Loss: 0.0215 Acc:99.42%
Training: Epoch[238/300] Iteration[350/782] Loss: 0.0213 Acc:99.41%
Training: Epoch[238/300] Iteration[400/782] Loss: 0.0206 Acc:99.44%
Training: Epoch[238/300] Iteration[450/782] Loss: 0.0204 Acc:99.44%
Training: Epoch[238/300] Iteration[500/782] Loss: 0.0205 Acc:99.45%
Training: Epoch[238/300] Iteration[550/782] Loss: 0.0207 Acc:99.44%
Training: Epoch[238/300] Iteration[600/782] Loss: 0.0205 Acc:99.45%
Training: Epoch[238/300] Iteration[650/782] Loss: 0.0204 Acc:99.45%
Training: Epoch[238/300] Iteration[700/782] Loss: 0.0204 Acc:99.44%
Training: Epoch[238/300] Iteration[750/782] Loss: 0.0204 Acc:99.45%
Epoch[238/300] Train Acc: 99.45% Valid Acc:93.10% Train loss:0.0204 Valid loss:0.2673 LR:0.0010000000000000002
Training: Epoch[239/300] Iteration[050/782] Loss: 0.0232 Acc:99.31%
Training: Epoch[239/300] Iteration[100/782] Loss: 0.0210 Acc:99.47%
Training: Epoch[239/300] Iteration[150/782] Loss: 0.0212 Acc:99.43%
Training: Epoch[239/300] Iteration[200/782] Loss: 0.0211 Acc:99.44%
Training: Epoch[239/300] Iteration[250/782] Loss: 0.0214 Acc:99.44%
Training: Epoch[239/300] Iteration[300/782] Loss: 0.0211 Acc:99.45%
Training: Epoch[239/300] Iteration[350/782] Loss: 0.0205 Acc:99.47%
Training: Epoch[239/300] Iteration[400/782] Loss: 0.0205 Acc:99.47%
Training: Epoch[239/300] Iteration[450/782] Loss: 0.0203 Acc:99.47%
Training: Epoch[239/300] Iteration[500/782] Loss: 0.0204 Acc:99.47%
Training: Epoch[239/300] Iteration[550/782] Loss: 0.0205 Acc:99.47%
Training: Epoch[239/300] Iteration[600/782] Loss: 0.0204 Acc:99.48%
Training: Epoch[239/300] Iteration[650/782] Loss: 0.0206 Acc:99.47%
Training: Epoch[239/300] Iteration[700/782] Loss: 0.0206 Acc:99.46%
Training: Epoch[239/300] Iteration[750/782] Loss: 0.0207 Acc:99.46%
Epoch[239/300] Train Acc: 99.44% Valid Acc:93.37% Train loss:0.0209 Valid loss:0.2602 LR:0.0010000000000000002
Training: Epoch[240/300] Iteration[050/782] Loss: 0.0204 Acc:99.59%
Training: Epoch[240/300] Iteration[100/782] Loss: 0.0217 Acc:99.52%
Training: Epoch[240/300] Iteration[150/782] Loss: 0.0222 Acc:99.43%
Training: Epoch[240/300] Iteration[200/782] Loss: 0.0207 Acc:99.48%
Training: Epoch[240/300] Iteration[250/782] Loss: 0.0201 Acc:99.51%
Training: Epoch[240/300] Iteration[300/782] Loss: 0.0199 Acc:99.53%
Training: Epoch[240/300] Iteration[350/782] Loss: 0.0196 Acc:99.55%
Training: Epoch[240/300] Iteration[400/782] Loss: 0.0196 Acc:99.55%
Training: Epoch[240/300] Iteration[450/782] Loss: 0.0195 Acc:99.55%
Training: Epoch[240/300] Iteration[500/782] Loss: 0.0195 Acc:99.54%
Training: Epoch[240/300] Iteration[550/782] Loss: 0.0192 Acc:99.56%
Training: Epoch[240/300] Iteration[600/782] Loss: 0.0194 Acc:99.55%
Training: Epoch[240/300] Iteration[650/782] Loss: 0.0193 Acc:99.55%
Training: Epoch[240/300] Iteration[700/782] Loss: 0.0197 Acc:99.52%
Training: Epoch[240/300] Iteration[750/782] Loss: 0.0198 Acc:99.52%
Epoch[240/300] Train Acc: 99.51% Valid Acc:93.12% Train loss:0.0202 Valid loss:0.2658 LR:0.0010000000000000002
Training: Epoch[241/300] Iteration[050/782] Loss: 0.0200 Acc:99.47%
Training: Epoch[241/300] Iteration[100/782] Loss: 0.0211 Acc:99.39%
Training: Epoch[241/300] Iteration[150/782] Loss: 0.0213 Acc:99.44%
Training: Epoch[241/300] Iteration[200/782] Loss: 0.0214 Acc:99.42%
Training: Epoch[241/300] Iteration[250/782] Loss: 0.0215 Acc:99.44%
Training: Epoch[241/300] Iteration[300/782] Loss: 0.0216 Acc:99.46%
Training: Epoch[241/300] Iteration[350/782] Loss: 0.0216 Acc:99.44%
Training: Epoch[241/300] Iteration[400/782] Loss: 0.0211 Acc:99.46%
Training: Epoch[241/300] Iteration[450/782] Loss: 0.0213 Acc:99.45%
Training: Epoch[241/300] Iteration[500/782] Loss: 0.0213 Acc:99.44%
Training: Epoch[241/300] Iteration[550/782] Loss: 0.0212 Acc:99.44%
Training: Epoch[241/300] Iteration[600/782] Loss: 0.0209 Acc:99.45%
Training: Epoch[241/300] Iteration[650/782] Loss: 0.0210 Acc:99.45%
Training: Epoch[241/300] Iteration[700/782] Loss: 0.0209 Acc:99.45%
Training: Epoch[241/300] Iteration[750/782] Loss: 0.0208 Acc:99.46%
Epoch[241/300] Train Acc: 99.45% Valid Acc:93.34% Train loss:0.0208 Valid loss:0.2633 LR:0.0010000000000000002
Training: Epoch[242/300] Iteration[050/782] Loss: 0.0207 Acc:99.53%
Training: Epoch[242/300] Iteration[100/782] Loss: 0.0204 Acc:99.53%
Training: Epoch[242/300] Iteration[150/782] Loss: 0.0212 Acc:99.43%
Training: Epoch[242/300] Iteration[200/782] Loss: 0.0206 Acc:99.44%
Training: Epoch[242/300] Iteration[250/782] Loss: 0.0211 Acc:99.42%
Training: Epoch[242/300] Iteration[300/782] Loss: 0.0210 Acc:99.42%
Training: Epoch[242/300] Iteration[350/782] Loss: 0.0206 Acc:99.45%
Training: Epoch[242/300] Iteration[400/782] Loss: 0.0203 Acc:99.46%
Training: Epoch[242/300] Iteration[450/782] Loss: 0.0201 Acc:99.47%
Training: Epoch[242/300] Iteration[500/782] Loss: 0.0206 Acc:99.45%
Training: Epoch[242/300] Iteration[550/782] Loss: 0.0204 Acc:99.45%
Training: Epoch[242/300] Iteration[600/782] Loss: 0.0206 Acc:99.45%
Training: Epoch[242/300] Iteration[650/782] Loss: 0.0205 Acc:99.46%
Training: Epoch[242/300] Iteration[700/782] Loss: 0.0204 Acc:99.47%
Training: Epoch[242/300] Iteration[750/782] Loss: 0.0202 Acc:99.48%
Epoch[242/300] Train Acc: 99.47% Valid Acc:93.26% Train loss:0.0205 Valid loss:0.2659 LR:0.0010000000000000002
Training: Epoch[243/300] Iteration[050/782] Loss: 0.0215 Acc:99.28%
Training: Epoch[243/300] Iteration[100/782] Loss: 0.0196 Acc:99.52%
Training: Epoch[243/300] Iteration[150/782] Loss: 0.0209 Acc:99.44%
Training: Epoch[243/300] Iteration[200/782] Loss: 0.0204 Acc:99.44%
Training: Epoch[243/300] Iteration[250/782] Loss: 0.0199 Acc:99.47%
Training: Epoch[243/300] Iteration[300/782] Loss: 0.0199 Acc:99.47%
Training: Epoch[243/300] Iteration[350/782] Loss: 0.0200 Acc:99.49%
Training: Epoch[243/300] Iteration[400/782] Loss: 0.0202 Acc:99.49%
Training: Epoch[243/300] Iteration[450/782] Loss: 0.0200 Acc:99.49%
Training: Epoch[243/300] Iteration[500/782] Loss: 0.0196 Acc:99.51%
Training: Epoch[243/300] Iteration[550/782] Loss: 0.0196 Acc:99.51%
Training: Epoch[243/300] Iteration[600/782] Loss: 0.0195 Acc:99.51%
Training: Epoch[243/300] Iteration[650/782] Loss: 0.0197 Acc:99.49%
Training: Epoch[243/300] Iteration[700/782] Loss: 0.0196 Acc:99.48%
Training: Epoch[243/300] Iteration[750/782] Loss: 0.0196 Acc:99.49%
Epoch[243/300] Train Acc: 99.48% Valid Acc:93.37% Train loss:0.0199 Valid loss:0.2613 LR:0.0010000000000000002
Training: Epoch[244/300] Iteration[050/782] Loss: 0.0172 Acc:99.66%
Training: Epoch[244/300] Iteration[100/782] Loss: 0.0171 Acc:99.61%
Training: Epoch[244/300] Iteration[150/782] Loss: 0.0175 Acc:99.60%
Training: Epoch[244/300] Iteration[200/782] Loss: 0.0180 Acc:99.57%
Training: Epoch[244/300] Iteration[250/782] Loss: 0.0177 Acc:99.59%
Training: Epoch[244/300] Iteration[300/782] Loss: 0.0181 Acc:99.55%
Training: Epoch[244/300] Iteration[350/782] Loss: 0.0186 Acc:99.54%
Training: Epoch[244/300] Iteration[400/782] Loss: 0.0186 Acc:99.54%
Training: Epoch[244/300] Iteration[450/782] Loss: 0.0189 Acc:99.52%
Training: Epoch[244/300] Iteration[500/782] Loss: 0.0190 Acc:99.51%
Training: Epoch[244/300] Iteration[550/782] Loss: 0.0187 Acc:99.52%
Training: Epoch[244/300] Iteration[600/782] Loss: 0.0187 Acc:99.52%
Training: Epoch[244/300] Iteration[650/782] Loss: 0.0190 Acc:99.50%
Training: Epoch[244/300] Iteration[700/782] Loss: 0.0189 Acc:99.50%
Training: Epoch[244/300] Iteration[750/782] Loss: 0.0187 Acc:99.51%
Epoch[244/300] Train Acc: 99.51% Valid Acc:93.19% Train loss:0.0188 Valid loss:0.2643 LR:0.0010000000000000002
Training: Epoch[245/300] Iteration[050/782] Loss: 0.0176 Acc:99.53%
Training: Epoch[245/300] Iteration[100/782] Loss: 0.0169 Acc:99.56%
Training: Epoch[245/300] Iteration[150/782] Loss: 0.0184 Acc:99.50%
Training: Epoch[245/300] Iteration[200/782] Loss: 0.0176 Acc:99.53%
Training: Epoch[245/300] Iteration[250/782] Loss: 0.0171 Acc:99.56%
Training: Epoch[245/300] Iteration[300/782] Loss: 0.0176 Acc:99.58%
Training: Epoch[245/300] Iteration[350/782] Loss: 0.0177 Acc:99.58%
Training: Epoch[245/300] Iteration[400/782] Loss: 0.0175 Acc:99.60%
Training: Epoch[245/300] Iteration[450/782] Loss: 0.0177 Acc:99.60%
Training: Epoch[245/300] Iteration[500/782] Loss: 0.0180 Acc:99.58%
Training: Epoch[245/300] Iteration[550/782] Loss: 0.0181 Acc:99.57%
Training: Epoch[245/300] Iteration[600/782] Loss: 0.0187 Acc:99.55%
Training: Epoch[245/300] Iteration[650/782] Loss: 0.0186 Acc:99.56%
Training: Epoch[245/300] Iteration[700/782] Loss: 0.0185 Acc:99.56%
Training: Epoch[245/300] Iteration[750/782] Loss: 0.0186 Acc:99.56%
Epoch[245/300] Train Acc: 99.54% Valid Acc:93.35% Train loss:0.0189 Valid loss:0.2606 LR:0.0010000000000000002
Training: Epoch[246/300] Iteration[050/782] Loss: 0.0183 Acc:99.56%
Training: Epoch[246/300] Iteration[100/782] Loss: 0.0171 Acc:99.55%
Training: Epoch[246/300] Iteration[150/782] Loss: 0.0173 Acc:99.60%
Training: Epoch[246/300] Iteration[200/782] Loss: 0.0186 Acc:99.60%
Training: Epoch[246/300] Iteration[250/782] Loss: 0.0180 Acc:99.62%
Training: Epoch[246/300] Iteration[300/782] Loss: 0.0184 Acc:99.60%
Training: Epoch[246/300] Iteration[350/782] Loss: 0.0187 Acc:99.59%
Training: Epoch[246/300] Iteration[400/782] Loss: 0.0184 Acc:99.60%
Training: Epoch[246/300] Iteration[450/782] Loss: 0.0185 Acc:99.59%
Training: Epoch[246/300] Iteration[500/782] Loss: 0.0182 Acc:99.61%
Training: Epoch[246/300] Iteration[550/782] Loss: 0.0180 Acc:99.62%
Training: Epoch[246/300] Iteration[600/782] Loss: 0.0178 Acc:99.61%
Training: Epoch[246/300] Iteration[650/782] Loss: 0.0179 Acc:99.60%
Training: Epoch[246/300] Iteration[700/782] Loss: 0.0179 Acc:99.59%
Training: Epoch[246/300] Iteration[750/782] Loss: 0.0177 Acc:99.60%
Epoch[246/300] Train Acc: 99.60% Valid Acc:93.25% Train loss:0.0179 Valid loss:0.2684 LR:0.0010000000000000002
Training: Epoch[247/300] Iteration[050/782] Loss: 0.0195 Acc:99.41%
Training: Epoch[247/300] Iteration[100/782] Loss: 0.0190 Acc:99.55%
Training: Epoch[247/300] Iteration[150/782] Loss: 0.0195 Acc:99.49%
Training: Epoch[247/300] Iteration[200/782] Loss: 0.0196 Acc:99.48%
Training: Epoch[247/300] Iteration[250/782] Loss: 0.0193 Acc:99.51%
Training: Epoch[247/300] Iteration[300/782] Loss: 0.0189 Acc:99.53%
Training: Epoch[247/300] Iteration[350/782] Loss: 0.0187 Acc:99.54%
Training: Epoch[247/300] Iteration[400/782] Loss: 0.0183 Acc:99.55%
Training: Epoch[247/300] Iteration[450/782] Loss: 0.0182 Acc:99.54%
Training: Epoch[247/300] Iteration[500/782] Loss: 0.0184 Acc:99.53%
Training: Epoch[247/300] Iteration[550/782] Loss: 0.0184 Acc:99.53%
Training: Epoch[247/300] Iteration[600/782] Loss: 0.0184 Acc:99.53%
Training: Epoch[247/300] Iteration[650/782] Loss: 0.0186 Acc:99.52%
Training: Epoch[247/300] Iteration[700/782] Loss: 0.0183 Acc:99.54%
Training: Epoch[247/300] Iteration[750/782] Loss: 0.0183 Acc:99.54%
Epoch[247/300] Train Acc: 99.53% Valid Acc:93.19% Train loss:0.0185 Valid loss:0.2698 LR:0.0010000000000000002
Training: Epoch[248/300] Iteration[050/782] Loss: 0.0193 Acc:99.56%
Training: Epoch[248/300] Iteration[100/782] Loss: 0.0177 Acc:99.59%
Training: Epoch[248/300] Iteration[150/782] Loss: 0.0176 Acc:99.55%
Training: Epoch[248/300] Iteration[200/782] Loss: 0.0170 Acc:99.58%
Training: Epoch[248/300] Iteration[250/782] Loss: 0.0175 Acc:99.55%
Training: Epoch[248/300] Iteration[300/782] Loss: 0.0183 Acc:99.51%
Training: Epoch[248/300] Iteration[350/782] Loss: 0.0181 Acc:99.54%
Training: Epoch[248/300] Iteration[400/782] Loss: 0.0184 Acc:99.52%
Training: Epoch[248/300] Iteration[450/782] Loss: 0.0185 Acc:99.52%
Training: Epoch[248/300] Iteration[500/782] Loss: 0.0187 Acc:99.50%
Training: Epoch[248/300] Iteration[550/782] Loss: 0.0186 Acc:99.51%
Training: Epoch[248/300] Iteration[600/782] Loss: 0.0185 Acc:99.52%
Training: Epoch[248/300] Iteration[650/782] Loss: 0.0183 Acc:99.53%
Training: Epoch[248/300] Iteration[700/782] Loss: 0.0185 Acc:99.52%
Training: Epoch[248/300] Iteration[750/782] Loss: 0.0187 Acc:99.51%
Epoch[248/300] Train Acc: 99.51% Valid Acc:93.35% Train loss:0.0189 Valid loss:0.2635 LR:0.0010000000000000002
Training: Epoch[249/300] Iteration[050/782] Loss: 0.0163 Acc:99.56%
Training: Epoch[249/300] Iteration[100/782] Loss: 0.0173 Acc:99.56%
Training: Epoch[249/300] Iteration[150/782] Loss: 0.0172 Acc:99.55%
Training: Epoch[249/300] Iteration[200/782] Loss: 0.0172 Acc:99.52%
Training: Epoch[249/300] Iteration[250/782] Loss: 0.0169 Acc:99.56%
Training: Epoch[249/300] Iteration[300/782] Loss: 0.0175 Acc:99.55%
Training: Epoch[249/300] Iteration[350/782] Loss: 0.0178 Acc:99.54%
Training: Epoch[249/300] Iteration[400/782] Loss: 0.0181 Acc:99.52%
Training: Epoch[249/300] Iteration[450/782] Loss: 0.0183 Acc:99.50%
Training: Epoch[249/300] Iteration[500/782] Loss: 0.0181 Acc:99.50%
Training: Epoch[249/300] Iteration[550/782] Loss: 0.0178 Acc:99.52%
Training: Epoch[249/300] Iteration[600/782] Loss: 0.0182 Acc:99.51%
Training: Epoch[249/300] Iteration[650/782] Loss: 0.0182 Acc:99.51%
Training: Epoch[249/300] Iteration[700/782] Loss: 0.0184 Acc:99.49%
Training: Epoch[249/300] Iteration[750/782] Loss: 0.0185 Acc:99.50%
Epoch[249/300] Train Acc: 99.50% Valid Acc:93.30% Train loss:0.0185 Valid loss:0.2645 LR:0.0010000000000000002
Training: Epoch[250/300] Iteration[050/782] Loss: 0.0187 Acc:99.59%
Training: Epoch[250/300] Iteration[100/782] Loss: 0.0177 Acc:99.62%
Training: Epoch[250/300] Iteration[150/782] Loss: 0.0176 Acc:99.60%
Training: Epoch[250/300] Iteration[200/782] Loss: 0.0176 Acc:99.62%
Training: Epoch[250/300] Iteration[250/782] Loss: 0.0172 Acc:99.61%
Training: Epoch[250/300] Iteration[300/782] Loss: 0.0172 Acc:99.59%
Training: Epoch[250/300] Iteration[350/782] Loss: 0.0178 Acc:99.58%
Training: Epoch[250/300] Iteration[400/782] Loss: 0.0179 Acc:99.56%
Training: Epoch[250/300] Iteration[450/782] Loss: 0.0185 Acc:99.53%
Training: Epoch[250/300] Iteration[500/782] Loss: 0.0185 Acc:99.52%
Training: Epoch[250/300] Iteration[550/782] Loss: 0.0183 Acc:99.52%
Training: Epoch[250/300] Iteration[600/782] Loss: 0.0184 Acc:99.51%
Training: Epoch[250/300] Iteration[650/782] Loss: 0.0182 Acc:99.52%
Training: Epoch[250/300] Iteration[700/782] Loss: 0.0182 Acc:99.52%
Training: Epoch[250/300] Iteration[750/782] Loss: 0.0181 Acc:99.53%
Epoch[250/300] Train Acc: 99.53% Valid Acc:93.35% Train loss:0.0182 Valid loss:0.2686 LR:0.0010000000000000002
Training: Epoch[251/300] Iteration[050/782] Loss: 0.0178 Acc:99.53%
Training: Epoch[251/300] Iteration[100/782] Loss: 0.0179 Acc:99.58%
Training: Epoch[251/300] Iteration[150/782] Loss: 0.0164 Acc:99.62%
Training: Epoch[251/300] Iteration[200/782] Loss: 0.0170 Acc:99.59%
Training: Epoch[251/300] Iteration[250/782] Loss: 0.0171 Acc:99.60%
Training: Epoch[251/300] Iteration[300/782] Loss: 0.0172 Acc:99.59%
Training: Epoch[251/300] Iteration[350/782] Loss: 0.0174 Acc:99.58%
Training: Epoch[251/300] Iteration[400/782] Loss: 0.0172 Acc:99.59%
Training: Epoch[251/300] Iteration[450/782] Loss: 0.0173 Acc:99.59%
Training: Epoch[251/300] Iteration[500/782] Loss: 0.0175 Acc:99.58%
Training: Epoch[251/300] Iteration[550/782] Loss: 0.0176 Acc:99.56%
Training: Epoch[251/300] Iteration[600/782] Loss: 0.0178 Acc:99.55%
Training: Epoch[251/300] Iteration[650/782] Loss: 0.0179 Acc:99.53%
Training: Epoch[251/300] Iteration[700/782] Loss: 0.0179 Acc:99.54%
Training: Epoch[251/300] Iteration[750/782] Loss: 0.0176 Acc:99.54%
Epoch[251/300] Train Acc: 99.55% Valid Acc:93.33% Train loss:0.0177 Valid loss:0.2671 LR:0.0010000000000000002
Training: Epoch[252/300] Iteration[050/782] Loss: 0.0187 Acc:99.59%
Training: Epoch[252/300] Iteration[100/782] Loss: 0.0179 Acc:99.59%
Training: Epoch[252/300] Iteration[150/782] Loss: 0.0176 Acc:99.60%
Training: Epoch[252/300] Iteration[200/782] Loss: 0.0170 Acc:99.65%
Training: Epoch[252/300] Iteration[250/782] Loss: 0.0172 Acc:99.61%
Training: Epoch[252/300] Iteration[300/782] Loss: 0.0173 Acc:99.58%
Training: Epoch[252/300] Iteration[350/782] Loss: 0.0172 Acc:99.58%
Training: Epoch[252/300] Iteration[400/782] Loss: 0.0170 Acc:99.59%
Training: Epoch[252/300] Iteration[450/782] Loss: 0.0176 Acc:99.57%
Training: Epoch[252/300] Iteration[500/782] Loss: 0.0174 Acc:99.58%
Training: Epoch[252/300] Iteration[550/782] Loss: 0.0172 Acc:99.58%
Training: Epoch[252/300] Iteration[600/782] Loss: 0.0170 Acc:99.59%
Training: Epoch[252/300] Iteration[650/782] Loss: 0.0171 Acc:99.59%
Training: Epoch[252/300] Iteration[700/782] Loss: 0.0170 Acc:99.59%
Training: Epoch[252/300] Iteration[750/782] Loss: 0.0174 Acc:99.58%
Epoch[252/300] Train Acc: 99.57% Valid Acc:93.13% Train loss:0.0173 Valid loss:0.2682 LR:0.0010000000000000002
Training: Epoch[253/300] Iteration[050/782] Loss: 0.0201 Acc:99.41%
Training: Epoch[253/300] Iteration[100/782] Loss: 0.0189 Acc:99.48%
Training: Epoch[253/300] Iteration[150/782] Loss: 0.0183 Acc:99.50%
Training: Epoch[253/300] Iteration[200/782] Loss: 0.0179 Acc:99.52%
Training: Epoch[253/300] Iteration[250/782] Loss: 0.0175 Acc:99.55%
Training: Epoch[253/300] Iteration[300/782] Loss: 0.0176 Acc:99.53%
Training: Epoch[253/300] Iteration[350/782] Loss: 0.0173 Acc:99.57%
Training: Epoch[253/300] Iteration[400/782] Loss: 0.0174 Acc:99.58%
Training: Epoch[253/300] Iteration[450/782] Loss: 0.0175 Acc:99.58%
Training: Epoch[253/300] Iteration[500/782] Loss: 0.0174 Acc:99.58%
Training: Epoch[253/300] Iteration[550/782] Loss: 0.0176 Acc:99.58%
Training: Epoch[253/300] Iteration[600/782] Loss: 0.0178 Acc:99.57%
Training: Epoch[253/300] Iteration[650/782] Loss: 0.0181 Acc:99.56%
Training: Epoch[253/300] Iteration[700/782] Loss: 0.0182 Acc:99.56%
Training: Epoch[253/300] Iteration[750/782] Loss: 0.0180 Acc:99.55%
Epoch[253/300] Train Acc: 99.56% Valid Acc:93.24% Train loss:0.0180 Valid loss:0.2667 LR:0.0010000000000000002
Training: Epoch[254/300] Iteration[050/782] Loss: 0.0135 Acc:99.72%
Training: Epoch[254/300] Iteration[100/782] Loss: 0.0151 Acc:99.61%
Training: Epoch[254/300] Iteration[150/782] Loss: 0.0154 Acc:99.64%
Training: Epoch[254/300] Iteration[200/782] Loss: 0.0151 Acc:99.68%
Training: Epoch[254/300] Iteration[250/782] Loss: 0.0152 Acc:99.68%
Training: Epoch[254/300] Iteration[300/782] Loss: 0.0156 Acc:99.64%
Training: Epoch[254/300] Iteration[350/782] Loss: 0.0158 Acc:99.63%
Training: Epoch[254/300] Iteration[400/782] Loss: 0.0160 Acc:99.61%
Training: Epoch[254/300] Iteration[450/782] Loss: 0.0161 Acc:99.60%
Training: Epoch[254/300] Iteration[500/782] Loss: 0.0165 Acc:99.60%
Training: Epoch[254/300] Iteration[550/782] Loss: 0.0167 Acc:99.59%
Training: Epoch[254/300] Iteration[600/782] Loss: 0.0168 Acc:99.61%
Training: Epoch[254/300] Iteration[650/782] Loss: 0.0168 Acc:99.60%
Training: Epoch[254/300] Iteration[700/782] Loss: 0.0170 Acc:99.59%
Training: Epoch[254/300] Iteration[750/782] Loss: 0.0170 Acc:99.59%
Epoch[254/300] Train Acc: 99.60% Valid Acc:93.42% Train loss:0.0170 Valid loss:0.2666 LR:0.0010000000000000002
Training: Epoch[255/300] Iteration[050/782] Loss: 0.0155 Acc:99.66%
Training: Epoch[255/300] Iteration[100/782] Loss: 0.0153 Acc:99.69%
Training: Epoch[255/300] Iteration[150/782] Loss: 0.0153 Acc:99.67%
Training: Epoch[255/300] Iteration[200/782] Loss: 0.0155 Acc:99.62%
Training: Epoch[255/300] Iteration[250/782] Loss: 0.0158 Acc:99.62%
Training: Epoch[255/300] Iteration[300/782] Loss: 0.0158 Acc:99.62%
Training: Epoch[255/300] Iteration[350/782] Loss: 0.0158 Acc:99.62%
Training: Epoch[255/300] Iteration[400/782] Loss: 0.0159 Acc:99.62%
Training: Epoch[255/300] Iteration[450/782] Loss: 0.0158 Acc:99.61%
Training: Epoch[255/300] Iteration[500/782] Loss: 0.0156 Acc:99.61%
Training: Epoch[255/300] Iteration[550/782] Loss: 0.0160 Acc:99.60%
Training: Epoch[255/300] Iteration[600/782] Loss: 0.0159 Acc:99.61%
Training: Epoch[255/300] Iteration[650/782] Loss: 0.0159 Acc:99.61%
Training: Epoch[255/300] Iteration[700/782] Loss: 0.0157 Acc:99.62%
Training: Epoch[255/300] Iteration[750/782] Loss: 0.0157 Acc:99.61%
Epoch[255/300] Train Acc: 99.61% Valid Acc:93.31% Train loss:0.0158 Valid loss:0.2634 LR:0.0010000000000000002
Training: Epoch[256/300] Iteration[050/782] Loss: 0.0191 Acc:99.47%
Training: Epoch[256/300] Iteration[100/782] Loss: 0.0176 Acc:99.58%
Training: Epoch[256/300] Iteration[150/782] Loss: 0.0170 Acc:99.60%
Training: Epoch[256/300] Iteration[200/782] Loss: 0.0166 Acc:99.63%
Training: Epoch[256/300] Iteration[250/782] Loss: 0.0169 Acc:99.62%
Training: Epoch[256/300] Iteration[300/782] Loss: 0.0174 Acc:99.61%
Training: Epoch[256/300] Iteration[350/782] Loss: 0.0173 Acc:99.60%
Training: Epoch[256/300] Iteration[400/782] Loss: 0.0174 Acc:99.58%
Training: Epoch[256/300] Iteration[450/782] Loss: 0.0175 Acc:99.57%
Training: Epoch[256/300] Iteration[500/782] Loss: 0.0171 Acc:99.58%
Training: Epoch[256/300] Iteration[550/782] Loss: 0.0170 Acc:99.57%
Training: Epoch[256/300] Iteration[600/782] Loss: 0.0171 Acc:99.57%
Training: Epoch[256/300] Iteration[650/782] Loss: 0.0169 Acc:99.58%
Training: Epoch[256/300] Iteration[700/782] Loss: 0.0169 Acc:99.58%
Training: Epoch[256/300] Iteration[750/782] Loss: 0.0172 Acc:99.56%
Epoch[256/300] Train Acc: 99.56% Valid Acc:93.42% Train loss:0.0173 Valid loss:0.2686 LR:0.0010000000000000002
Training: Epoch[257/300] Iteration[050/782] Loss: 0.0163 Acc:99.62%
Training: Epoch[257/300] Iteration[100/782] Loss: 0.0176 Acc:99.58%
Training: Epoch[257/300] Iteration[150/782] Loss: 0.0176 Acc:99.56%
Training: Epoch[257/300] Iteration[200/782] Loss: 0.0168 Acc:99.58%
Training: Epoch[257/300] Iteration[250/782] Loss: 0.0171 Acc:99.57%
Training: Epoch[257/300] Iteration[300/782] Loss: 0.0164 Acc:99.60%
Training: Epoch[257/300] Iteration[350/782] Loss: 0.0163 Acc:99.61%
Training: Epoch[257/300] Iteration[400/782] Loss: 0.0164 Acc:99.59%
Training: Epoch[257/300] Iteration[450/782] Loss: 0.0166 Acc:99.60%
Training: Epoch[257/300] Iteration[500/782] Loss: 0.0167 Acc:99.60%
Training: Epoch[257/300] Iteration[550/782] Loss: 0.0166 Acc:99.61%
Training: Epoch[257/300] Iteration[600/782] Loss: 0.0166 Acc:99.61%
Training: Epoch[257/300] Iteration[650/782] Loss: 0.0167 Acc:99.61%
Training: Epoch[257/300] Iteration[700/782] Loss: 0.0167 Acc:99.61%
Training: Epoch[257/300] Iteration[750/782] Loss: 0.0167 Acc:99.61%
Epoch[257/300] Train Acc: 99.60% Valid Acc:93.35% Train loss:0.0166 Valid loss:0.2623 LR:0.0010000000000000002
Training: Epoch[258/300] Iteration[050/782] Loss: 0.0154 Acc:99.62%
Training: Epoch[258/300] Iteration[100/782] Loss: 0.0161 Acc:99.67%
Training: Epoch[258/300] Iteration[150/782] Loss: 0.0149 Acc:99.72%
Training: Epoch[258/300] Iteration[200/782] Loss: 0.0149 Acc:99.71%
Training: Epoch[258/300] Iteration[250/782] Loss: 0.0158 Acc:99.65%
Training: Epoch[258/300] Iteration[300/782] Loss: 0.0163 Acc:99.62%
Training: Epoch[258/300] Iteration[350/782] Loss: 0.0164 Acc:99.60%
Training: Epoch[258/300] Iteration[400/782] Loss: 0.0165 Acc:99.60%
Training: Epoch[258/300] Iteration[450/782] Loss: 0.0163 Acc:99.60%
Training: Epoch[258/300] Iteration[500/782] Loss: 0.0168 Acc:99.59%
Training: Epoch[258/300] Iteration[550/782] Loss: 0.0166 Acc:99.59%
Training: Epoch[258/300] Iteration[600/782] Loss: 0.0167 Acc:99.59%
Training: Epoch[258/300] Iteration[650/782] Loss: 0.0166 Acc:99.60%
Training: Epoch[258/300] Iteration[700/782] Loss: 0.0165 Acc:99.60%
Training: Epoch[258/300] Iteration[750/782] Loss: 0.0168 Acc:99.59%
Epoch[258/300] Train Acc: 99.60% Valid Acc:93.44% Train loss:0.0166 Valid loss:0.2648 LR:0.0010000000000000002
Training: Epoch[259/300] Iteration[050/782] Loss: 0.0173 Acc:99.50%
Training: Epoch[259/300] Iteration[100/782] Loss: 0.0167 Acc:99.55%
Training: Epoch[259/300] Iteration[150/782] Loss: 0.0173 Acc:99.58%
Training: Epoch[259/300] Iteration[200/782] Loss: 0.0172 Acc:99.60%
Training: Epoch[259/300] Iteration[250/782] Loss: 0.0170 Acc:99.61%
Training: Epoch[259/300] Iteration[300/782] Loss: 0.0168 Acc:99.62%
Training: Epoch[259/300] Iteration[350/782] Loss: 0.0165 Acc:99.63%
Training: Epoch[259/300] Iteration[400/782] Loss: 0.0162 Acc:99.63%
Training: Epoch[259/300] Iteration[450/782] Loss: 0.0164 Acc:99.62%
Training: Epoch[259/300] Iteration[500/782] Loss: 0.0165 Acc:99.62%
Training: Epoch[259/300] Iteration[550/782] Loss: 0.0165 Acc:99.62%
Training: Epoch[259/300] Iteration[600/782] Loss: 0.0164 Acc:99.62%
Training: Epoch[259/300] Iteration[650/782] Loss: 0.0166 Acc:99.61%
Training: Epoch[259/300] Iteration[700/782] Loss: 0.0163 Acc:99.62%
Training: Epoch[259/300] Iteration[750/782] Loss: 0.0162 Acc:99.62%
Epoch[259/300] Train Acc: 99.63% Valid Acc:93.40% Train loss:0.0161 Valid loss:0.2678 LR:0.0010000000000000002
Training: Epoch[260/300] Iteration[050/782] Loss: 0.0143 Acc:99.72%
Training: Epoch[260/300] Iteration[100/782] Loss: 0.0150 Acc:99.67%
Training: Epoch[260/300] Iteration[150/782] Loss: 0.0153 Acc:99.62%
Training: Epoch[260/300] Iteration[200/782] Loss: 0.0153 Acc:99.62%
Training: Epoch[260/300] Iteration[250/782] Loss: 0.0157 Acc:99.59%
Training: Epoch[260/300] Iteration[300/782] Loss: 0.0159 Acc:99.57%
Training: Epoch[260/300] Iteration[350/782] Loss: 0.0156 Acc:99.60%
Training: Epoch[260/300] Iteration[400/782] Loss: 0.0153 Acc:99.61%
Training: Epoch[260/300] Iteration[450/782] Loss: 0.0155 Acc:99.60%
Training: Epoch[260/300] Iteration[500/782] Loss: 0.0157 Acc:99.60%
Training: Epoch[260/300] Iteration[550/782] Loss: 0.0157 Acc:99.61%
Training: Epoch[260/300] Iteration[600/782] Loss: 0.0157 Acc:99.61%
Training: Epoch[260/300] Iteration[650/782] Loss: 0.0154 Acc:99.63%
Training: Epoch[260/300] Iteration[700/782] Loss: 0.0155 Acc:99.63%
Training: Epoch[260/300] Iteration[750/782] Loss: 0.0154 Acc:99.64%
Epoch[260/300] Train Acc: 99.63% Valid Acc:93.28% Train loss:0.0158 Valid loss:0.2672 LR:0.0010000000000000002
Training: Epoch[261/300] Iteration[050/782] Loss: 0.0214 Acc:99.34%
Training: Epoch[261/300] Iteration[100/782] Loss: 0.0185 Acc:99.45%
Training: Epoch[261/300] Iteration[150/782] Loss: 0.0178 Acc:99.52%
Training: Epoch[261/300] Iteration[200/782] Loss: 0.0171 Acc:99.55%
Training: Epoch[261/300] Iteration[250/782] Loss: 0.0173 Acc:99.58%
Training: Epoch[261/300] Iteration[300/782] Loss: 0.0170 Acc:99.60%
Training: Epoch[261/300] Iteration[350/782] Loss: 0.0160 Acc:99.63%
Training: Epoch[261/300] Iteration[400/782] Loss: 0.0161 Acc:99.62%
Training: Epoch[261/300] Iteration[450/782] Loss: 0.0159 Acc:99.62%
Training: Epoch[261/300] Iteration[500/782] Loss: 0.0162 Acc:99.61%
Training: Epoch[261/300] Iteration[550/782] Loss: 0.0159 Acc:99.62%
Training: Epoch[261/300] Iteration[600/782] Loss: 0.0161 Acc:99.62%
Training: Epoch[261/300] Iteration[650/782] Loss: 0.0160 Acc:99.61%
Training: Epoch[261/300] Iteration[700/782] Loss: 0.0162 Acc:99.60%
Training: Epoch[261/300] Iteration[750/782] Loss: 0.0162 Acc:99.61%
Epoch[261/300] Train Acc: 99.61% Valid Acc:93.23% Train loss:0.0163 Valid loss:0.2691 LR:0.0010000000000000002
Training: Epoch[262/300] Iteration[050/782] Loss: 0.0184 Acc:99.47%
Training: Epoch[262/300] Iteration[100/782] Loss: 0.0173 Acc:99.56%
Training: Epoch[262/300] Iteration[150/782] Loss: 0.0174 Acc:99.59%
Training: Epoch[262/300] Iteration[200/782] Loss: 0.0171 Acc:99.59%
Training: Epoch[262/300] Iteration[250/782] Loss: 0.0160 Acc:99.63%
Training: Epoch[262/300] Iteration[300/782] Loss: 0.0162 Acc:99.64%
Training: Epoch[262/300] Iteration[350/782] Loss: 0.0167 Acc:99.60%
Training: Epoch[262/300] Iteration[400/782] Loss: 0.0166 Acc:99.59%
Training: Epoch[262/300] Iteration[450/782] Loss: 0.0165 Acc:99.59%
Training: Epoch[262/300] Iteration[500/782] Loss: 0.0162 Acc:99.60%
Training: Epoch[262/300] Iteration[550/782] Loss: 0.0160 Acc:99.60%
Training: Epoch[262/300] Iteration[600/782] Loss: 0.0160 Acc:99.59%
Training: Epoch[262/300] Iteration[650/782] Loss: 0.0161 Acc:99.59%
Training: Epoch[262/300] Iteration[700/782] Loss: 0.0161 Acc:99.60%
Training: Epoch[262/300] Iteration[750/782] Loss: 0.0160 Acc:99.60%
Epoch[262/300] Train Acc: 99.60% Valid Acc:93.10% Train loss:0.0159 Valid loss:0.2719 LR:0.0010000000000000002
Training: Epoch[263/300] Iteration[050/782] Loss: 0.0215 Acc:99.41%
Training: Epoch[263/300] Iteration[100/782] Loss: 0.0193 Acc:99.55%
Training: Epoch[263/300] Iteration[150/782] Loss: 0.0188 Acc:99.50%
Training: Epoch[263/300] Iteration[200/782] Loss: 0.0180 Acc:99.55%
Training: Epoch[263/300] Iteration[250/782] Loss: 0.0169 Acc:99.59%
Training: Epoch[263/300] Iteration[300/782] Loss: 0.0166 Acc:99.60%
Training: Epoch[263/300] Iteration[350/782] Loss: 0.0162 Acc:99.62%
Training: Epoch[263/300] Iteration[400/782] Loss: 0.0160 Acc:99.63%
Training: Epoch[263/300] Iteration[450/782] Loss: 0.0160 Acc:99.62%
Training: Epoch[263/300] Iteration[500/782] Loss: 0.0160 Acc:99.62%
Training: Epoch[263/300] Iteration[550/782] Loss: 0.0159 Acc:99.62%
Training: Epoch[263/300] Iteration[600/782] Loss: 0.0157 Acc:99.64%
Training: Epoch[263/300] Iteration[650/782] Loss: 0.0159 Acc:99.64%
Training: Epoch[263/300] Iteration[700/782] Loss: 0.0159 Acc:99.64%
Training: Epoch[263/300] Iteration[750/782] Loss: 0.0159 Acc:99.63%
Epoch[263/300] Train Acc: 99.62% Valid Acc:93.38% Train loss:0.0161 Valid loss:0.2703 LR:0.0010000000000000002
Training: Epoch[264/300] Iteration[050/782] Loss: 0.0159 Acc:99.53%
Training: Epoch[264/300] Iteration[100/782] Loss: 0.0168 Acc:99.61%
Training: Epoch[264/300] Iteration[150/782] Loss: 0.0163 Acc:99.61%
Training: Epoch[264/300] Iteration[200/782] Loss: 0.0161 Acc:99.62%
Training: Epoch[264/300] Iteration[250/782] Loss: 0.0158 Acc:99.64%
Training: Epoch[264/300] Iteration[300/782] Loss: 0.0163 Acc:99.60%
Training: Epoch[264/300] Iteration[350/782] Loss: 0.0165 Acc:99.59%
Training: Epoch[264/300] Iteration[400/782] Loss: 0.0165 Acc:99.61%
Training: Epoch[264/300] Iteration[450/782] Loss: 0.0162 Acc:99.61%
Training: Epoch[264/300] Iteration[500/782] Loss: 0.0160 Acc:99.62%
Training: Epoch[264/300] Iteration[550/782] Loss: 0.0161 Acc:99.62%
Training: Epoch[264/300] Iteration[600/782] Loss: 0.0161 Acc:99.62%
Training: Epoch[264/300] Iteration[650/782] Loss: 0.0160 Acc:99.62%
Training: Epoch[264/300] Iteration[700/782] Loss: 0.0158 Acc:99.63%
Training: Epoch[264/300] Iteration[750/782] Loss: 0.0160 Acc:99.61%
Epoch[264/300] Train Acc: 99.61% Valid Acc:93.32% Train loss:0.0161 Valid loss:0.2713 LR:0.0010000000000000002
Training: Epoch[265/300] Iteration[050/782] Loss: 0.0118 Acc:99.81%
Training: Epoch[265/300] Iteration[100/782] Loss: 0.0147 Acc:99.67%
Training: Epoch[265/300] Iteration[150/782] Loss: 0.0139 Acc:99.66%
Training: Epoch[265/300] Iteration[200/782] Loss: 0.0148 Acc:99.62%
Training: Epoch[265/300] Iteration[250/782] Loss: 0.0154 Acc:99.62%
Training: Epoch[265/300] Iteration[300/782] Loss: 0.0154 Acc:99.63%
Training: Epoch[265/300] Iteration[350/782] Loss: 0.0153 Acc:99.63%
Training: Epoch[265/300] Iteration[400/782] Loss: 0.0152 Acc:99.61%
Training: Epoch[265/300] Iteration[450/782] Loss: 0.0149 Acc:99.64%
Training: Epoch[265/300] Iteration[500/782] Loss: 0.0147 Acc:99.64%
Training: Epoch[265/300] Iteration[550/782] Loss: 0.0146 Acc:99.65%
Training: Epoch[265/300] Iteration[600/782] Loss: 0.0145 Acc:99.66%
Training: Epoch[265/300] Iteration[650/782] Loss: 0.0144 Acc:99.66%
Training: Epoch[265/300] Iteration[700/782] Loss: 0.0145 Acc:99.66%
Training: Epoch[265/300] Iteration[750/782] Loss: 0.0145 Acc:99.66%
Epoch[265/300] Train Acc: 99.66% Valid Acc:93.34% Train loss:0.0145 Valid loss:0.2719 LR:0.0010000000000000002
Training: Epoch[266/300] Iteration[050/782] Loss: 0.0122 Acc:99.78%
Training: Epoch[266/300] Iteration[100/782] Loss: 0.0158 Acc:99.59%
Training: Epoch[266/300] Iteration[150/782] Loss: 0.0153 Acc:99.59%
Training: Epoch[266/300] Iteration[200/782] Loss: 0.0155 Acc:99.62%
Training: Epoch[266/300] Iteration[250/782] Loss: 0.0154 Acc:99.61%
Training: Epoch[266/300] Iteration[300/782] Loss: 0.0155 Acc:99.61%
Training: Epoch[266/300] Iteration[350/782] Loss: 0.0156 Acc:99.60%
Training: Epoch[266/300] Iteration[400/782] Loss: 0.0155 Acc:99.61%
Training: Epoch[266/300] Iteration[450/782] Loss: 0.0153 Acc:99.61%
Training: Epoch[266/300] Iteration[500/782] Loss: 0.0151 Acc:99.63%
Training: Epoch[266/300] Iteration[550/782] Loss: 0.0152 Acc:99.62%
Training: Epoch[266/300] Iteration[600/782] Loss: 0.0151 Acc:99.62%
Training: Epoch[266/300] Iteration[650/782] Loss: 0.0153 Acc:99.61%
Training: Epoch[266/300] Iteration[700/782] Loss: 0.0155 Acc:99.60%
Training: Epoch[266/300] Iteration[750/782] Loss: 0.0153 Acc:99.62%
Epoch[266/300] Train Acc: 99.63% Valid Acc:93.30% Train loss:0.0153 Valid loss:0.2693 LR:0.0010000000000000002
Training: Epoch[267/300] Iteration[050/782] Loss: 0.0141 Acc:99.66%
Training: Epoch[267/300] Iteration[100/782] Loss: 0.0151 Acc:99.64%
Training: Epoch[267/300] Iteration[150/782] Loss: 0.0151 Acc:99.62%
Training: Epoch[267/300] Iteration[200/782] Loss: 0.0151 Acc:99.68%
Training: Epoch[267/300] Iteration[250/782] Loss: 0.0159 Acc:99.62%
Training: Epoch[267/300] Iteration[300/782] Loss: 0.0159 Acc:99.63%
Training: Epoch[267/300] Iteration[350/782] Loss: 0.0162 Acc:99.62%
Training: Epoch[267/300] Iteration[400/782] Loss: 0.0160 Acc:99.62%
Training: Epoch[267/300] Iteration[450/782] Loss: 0.0159 Acc:99.63%
Training: Epoch[267/300] Iteration[500/782] Loss: 0.0157 Acc:99.63%
Training: Epoch[267/300] Iteration[550/782] Loss: 0.0156 Acc:99.63%
Training: Epoch[267/300] Iteration[600/782] Loss: 0.0163 Acc:99.60%
Training: Epoch[267/300] Iteration[650/782] Loss: 0.0161 Acc:99.60%
Training: Epoch[267/300] Iteration[700/782] Loss: 0.0161 Acc:99.60%
Training: Epoch[267/300] Iteration[750/782] Loss: 0.0161 Acc:99.60%
Epoch[267/300] Train Acc: 99.60% Valid Acc:93.19% Train loss:0.0162 Valid loss:0.2730 LR:0.0010000000000000002
Training: Epoch[268/300] Iteration[050/782] Loss: 0.0158 Acc:99.59%
Training: Epoch[268/300] Iteration[100/782] Loss: 0.0146 Acc:99.64%
Training: Epoch[268/300] Iteration[150/782] Loss: 0.0145 Acc:99.67%
Training: Epoch[268/300] Iteration[200/782] Loss: 0.0166 Acc:99.53%
Training: Epoch[268/300] Iteration[250/782] Loss: 0.0164 Acc:99.55%
Training: Epoch[268/300] Iteration[300/782] Loss: 0.0159 Acc:99.58%
Training: Epoch[268/300] Iteration[350/782] Loss: 0.0157 Acc:99.59%
Training: Epoch[268/300] Iteration[400/782] Loss: 0.0159 Acc:99.58%
Training: Epoch[268/300] Iteration[450/782] Loss: 0.0158 Acc:99.58%
Training: Epoch[268/300] Iteration[500/782] Loss: 0.0159 Acc:99.58%
Training: Epoch[268/300] Iteration[550/782] Loss: 0.0159 Acc:99.57%
Training: Epoch[268/300] Iteration[600/782] Loss: 0.0156 Acc:99.58%
Training: Epoch[268/300] Iteration[650/782] Loss: 0.0156 Acc:99.58%
Training: Epoch[268/300] Iteration[700/782] Loss: 0.0157 Acc:99.56%
Training: Epoch[268/300] Iteration[750/782] Loss: 0.0156 Acc:99.57%
Epoch[268/300] Train Acc: 99.58% Valid Acc:93.32% Train loss:0.0155 Valid loss:0.2744 LR:0.0010000000000000002
Training: Epoch[269/300] Iteration[050/782] Loss: 0.0196 Acc:99.53%
Training: Epoch[269/300] Iteration[100/782] Loss: 0.0161 Acc:99.66%
Training: Epoch[269/300] Iteration[150/782] Loss: 0.0165 Acc:99.62%
Training: Epoch[269/300] Iteration[200/782] Loss: 0.0152 Acc:99.69%
Training: Epoch[269/300] Iteration[250/782] Loss: 0.0149 Acc:99.69%
Training: Epoch[269/300] Iteration[300/782] Loss: 0.0151 Acc:99.68%
Training: Epoch[269/300] Iteration[350/782] Loss: 0.0150 Acc:99.68%
Training: Epoch[269/300] Iteration[400/782] Loss: 0.0149 Acc:99.68%
Training: Epoch[269/300] Iteration[450/782] Loss: 0.0148 Acc:99.68%
Training: Epoch[269/300] Iteration[500/782] Loss: 0.0149 Acc:99.67%
Training: Epoch[269/300] Iteration[550/782] Loss: 0.0147 Acc:99.67%
Training: Epoch[269/300] Iteration[600/782] Loss: 0.0150 Acc:99.67%
Training: Epoch[269/300] Iteration[650/782] Loss: 0.0152 Acc:99.65%
Training: Epoch[269/300] Iteration[700/782] Loss: 0.0151 Acc:99.66%
Training: Epoch[269/300] Iteration[750/782] Loss: 0.0150 Acc:99.67%
Epoch[269/300] Train Acc: 99.67% Valid Acc:93.17% Train loss:0.0154 Valid loss:0.2761 LR:0.0010000000000000002
Training: Epoch[270/300] Iteration[050/782] Loss: 0.0148 Acc:99.66%
Training: Epoch[270/300] Iteration[100/782] Loss: 0.0139 Acc:99.69%
Training: Epoch[270/300] Iteration[150/782] Loss: 0.0138 Acc:99.74%
Training: Epoch[270/300] Iteration[200/782] Loss: 0.0142 Acc:99.72%
Training: Epoch[270/300] Iteration[250/782] Loss: 0.0143 Acc:99.71%
Training: Epoch[270/300] Iteration[300/782] Loss: 0.0146 Acc:99.69%
Training: Epoch[270/300] Iteration[350/782] Loss: 0.0144 Acc:99.69%
Training: Epoch[270/300] Iteration[400/782] Loss: 0.0144 Acc:99.68%
Training: Epoch[270/300] Iteration[450/782] Loss: 0.0144 Acc:99.68%
Training: Epoch[270/300] Iteration[500/782] Loss: 0.0144 Acc:99.68%
Training: Epoch[270/300] Iteration[550/782] Loss: 0.0147 Acc:99.67%
Training: Epoch[270/300] Iteration[600/782] Loss: 0.0146 Acc:99.67%
Training: Epoch[270/300] Iteration[650/782] Loss: 0.0145 Acc:99.67%
Training: Epoch[270/300] Iteration[700/782] Loss: 0.0147 Acc:99.66%
Training: Epoch[270/300] Iteration[750/782] Loss: 0.0149 Acc:99.65%
Epoch[270/300] Train Acc: 99.65% Valid Acc:93.47% Train loss:0.0152 Valid loss:0.2693 LR:0.0010000000000000002
Training: Epoch[271/300] Iteration[050/782] Loss: 0.0135 Acc:99.81%
Training: Epoch[271/300] Iteration[100/782] Loss: 0.0133 Acc:99.77%
Training: Epoch[271/300] Iteration[150/782] Loss: 0.0135 Acc:99.75%
Training: Epoch[271/300] Iteration[200/782] Loss: 0.0134 Acc:99.74%
Training: Epoch[271/300] Iteration[250/782] Loss: 0.0137 Acc:99.74%
Training: Epoch[271/300] Iteration[300/782] Loss: 0.0143 Acc:99.72%
Training: Epoch[271/300] Iteration[350/782] Loss: 0.0146 Acc:99.71%
Training: Epoch[271/300] Iteration[400/782] Loss: 0.0145 Acc:99.70%
Training: Epoch[271/300] Iteration[450/782] Loss: 0.0146 Acc:99.70%
Training: Epoch[271/300] Iteration[500/782] Loss: 0.0145 Acc:99.70%
Training: Epoch[271/300] Iteration[550/782] Loss: 0.0145 Acc:99.70%
Training: Epoch[271/300] Iteration[600/782] Loss: 0.0146 Acc:99.70%
Training: Epoch[271/300] Iteration[650/782] Loss: 0.0145 Acc:99.70%
Training: Epoch[271/300] Iteration[700/782] Loss: 0.0148 Acc:99.68%
Training: Epoch[271/300] Iteration[750/782] Loss: 0.0150 Acc:99.67%
Epoch[271/300] Train Acc: 99.66% Valid Acc:93.34% Train loss:0.0155 Valid loss:0.2730 LR:0.0010000000000000002
Training: Epoch[272/300] Iteration[050/782] Loss: 0.0164 Acc:99.47%
Training: Epoch[272/300] Iteration[100/782] Loss: 0.0151 Acc:99.52%
Training: Epoch[272/300] Iteration[150/782] Loss: 0.0153 Acc:99.53%
Training: Epoch[272/300] Iteration[200/782] Loss: 0.0151 Acc:99.55%
Training: Epoch[272/300] Iteration[250/782] Loss: 0.0153 Acc:99.58%
Training: Epoch[272/300] Iteration[300/782] Loss: 0.0156 Acc:99.56%
Training: Epoch[272/300] Iteration[350/782] Loss: 0.0155 Acc:99.58%
Training: Epoch[272/300] Iteration[400/782] Loss: 0.0155 Acc:99.58%
Training: Epoch[272/300] Iteration[450/782] Loss: 0.0158 Acc:99.58%
Training: Epoch[272/300] Iteration[500/782] Loss: 0.0156 Acc:99.58%
Training: Epoch[272/300] Iteration[550/782] Loss: 0.0153 Acc:99.61%
Training: Epoch[272/300] Iteration[600/782] Loss: 0.0151 Acc:99.61%
Training: Epoch[272/300] Iteration[650/782] Loss: 0.0153 Acc:99.61%
Training: Epoch[272/300] Iteration[700/782] Loss: 0.0154 Acc:99.60%
Training: Epoch[272/300] Iteration[750/782] Loss: 0.0154 Acc:99.60%
Epoch[272/300] Train Acc: 99.58% Valid Acc:93.25% Train loss:0.0157 Valid loss:0.2744 LR:0.0010000000000000002
Training: Epoch[273/300] Iteration[050/782] Loss: 0.0167 Acc:99.53%
Training: Epoch[273/300] Iteration[100/782] Loss: 0.0164 Acc:99.55%
Training: Epoch[273/300] Iteration[150/782] Loss: 0.0149 Acc:99.61%
Training: Epoch[273/300] Iteration[200/782] Loss: 0.0153 Acc:99.59%
Training: Epoch[273/300] Iteration[250/782] Loss: 0.0152 Acc:99.61%
Training: Epoch[273/300] Iteration[300/782] Loss: 0.0151 Acc:99.62%
Training: Epoch[273/300] Iteration[350/782] Loss: 0.0151 Acc:99.61%
Training: Epoch[273/300] Iteration[400/782] Loss: 0.0150 Acc:99.62%
Training: Epoch[273/300] Iteration[450/782] Loss: 0.0150 Acc:99.61%
Training: Epoch[273/300] Iteration[500/782] Loss: 0.0150 Acc:99.61%
Training: Epoch[273/300] Iteration[550/782] Loss: 0.0151 Acc:99.61%
Training: Epoch[273/300] Iteration[600/782] Loss: 0.0151 Acc:99.62%
Training: Epoch[273/300] Iteration[650/782] Loss: 0.0149 Acc:99.63%
Training: Epoch[273/300] Iteration[700/782] Loss: 0.0150 Acc:99.62%
Training: Epoch[273/300] Iteration[750/782] Loss: 0.0150 Acc:99.62%
Epoch[273/300] Train Acc: 99.62% Valid Acc:93.46% Train loss:0.0152 Valid loss:0.2706 LR:0.0010000000000000002
Training: Epoch[274/300] Iteration[050/782] Loss: 0.0162 Acc:99.59%
Training: Epoch[274/300] Iteration[100/782] Loss: 0.0166 Acc:99.56%
Training: Epoch[274/300] Iteration[150/782] Loss: 0.0158 Acc:99.56%
Training: Epoch[274/300] Iteration[200/782] Loss: 0.0157 Acc:99.55%
Training: Epoch[274/300] Iteration[250/782] Loss: 0.0151 Acc:99.58%
Training: Epoch[274/300] Iteration[300/782] Loss: 0.0150 Acc:99.58%
Training: Epoch[274/300] Iteration[350/782] Loss: 0.0148 Acc:99.58%
Training: Epoch[274/300] Iteration[400/782] Loss: 0.0147 Acc:99.61%
Training: Epoch[274/300] Iteration[450/782] Loss: 0.0148 Acc:99.61%
Training: Epoch[274/300] Iteration[500/782] Loss: 0.0149 Acc:99.60%
Training: Epoch[274/300] Iteration[550/782] Loss: 0.0148 Acc:99.61%
Training: Epoch[274/300] Iteration[600/782] Loss: 0.0151 Acc:99.60%
Training: Epoch[274/300] Iteration[650/782] Loss: 0.0151 Acc:99.60%
Training: Epoch[274/300] Iteration[700/782] Loss: 0.0150 Acc:99.60%
Training: Epoch[274/300] Iteration[750/782] Loss: 0.0151 Acc:99.61%
Epoch[274/300] Train Acc: 99.61% Valid Acc:93.18% Train loss:0.0151 Valid loss:0.2764 LR:0.0010000000000000002
Training: Epoch[275/300] Iteration[050/782] Loss: 0.0134 Acc:99.69%
Training: Epoch[275/300] Iteration[100/782] Loss: 0.0136 Acc:99.64%
Training: Epoch[275/300] Iteration[150/782] Loss: 0.0144 Acc:99.64%
Training: Epoch[275/300] Iteration[200/782] Loss: 0.0146 Acc:99.64%
Training: Epoch[275/300] Iteration[250/782] Loss: 0.0154 Acc:99.62%
Training: Epoch[275/300] Iteration[300/782] Loss: 0.0154 Acc:99.64%
Training: Epoch[275/300] Iteration[350/782] Loss: 0.0156 Acc:99.65%
Training: Epoch[275/300] Iteration[400/782] Loss: 0.0156 Acc:99.64%
Training: Epoch[275/300] Iteration[450/782] Loss: 0.0151 Acc:99.65%
Training: Epoch[275/300] Iteration[500/782] Loss: 0.0149 Acc:99.67%
Training: Epoch[275/300] Iteration[550/782] Loss: 0.0149 Acc:99.66%
Training: Epoch[275/300] Iteration[600/782] Loss: 0.0148 Acc:99.66%
Training: Epoch[275/300] Iteration[650/782] Loss: 0.0148 Acc:99.67%
Training: Epoch[275/300] Iteration[700/782] Loss: 0.0148 Acc:99.67%
Training: Epoch[275/300] Iteration[750/782] Loss: 0.0148 Acc:99.67%
Epoch[275/300] Train Acc: 99.67% Valid Acc:93.42% Train loss:0.0148 Valid loss:0.2722 LR:0.0010000000000000002
Training: Epoch[276/300] Iteration[050/782] Loss: 0.0147 Acc:99.56%
Training: Epoch[276/300] Iteration[100/782] Loss: 0.0139 Acc:99.67%
Training: Epoch[276/300] Iteration[150/782] Loss: 0.0142 Acc:99.66%
Training: Epoch[276/300] Iteration[200/782] Loss: 0.0138 Acc:99.66%
Training: Epoch[276/300] Iteration[250/782] Loss: 0.0144 Acc:99.64%
Training: Epoch[276/300] Iteration[300/782] Loss: 0.0143 Acc:99.66%
Training: Epoch[276/300] Iteration[350/782] Loss: 0.0144 Acc:99.66%
Training: Epoch[276/300] Iteration[400/782] Loss: 0.0148 Acc:99.64%
Training: Epoch[276/300] Iteration[450/782] Loss: 0.0144 Acc:99.66%
Training: Epoch[276/300] Iteration[500/782] Loss: 0.0142 Acc:99.67%
Training: Epoch[276/300] Iteration[550/782] Loss: 0.0140 Acc:99.68%
Training: Epoch[276/300] Iteration[600/782] Loss: 0.0141 Acc:99.67%
Training: Epoch[276/300] Iteration[650/782] Loss: 0.0141 Acc:99.68%
Training: Epoch[276/300] Iteration[700/782] Loss: 0.0140 Acc:99.68%
Training: Epoch[276/300] Iteration[750/782] Loss: 0.0143 Acc:99.66%
Epoch[276/300] Train Acc: 99.66% Valid Acc:93.40% Train loss:0.0142 Valid loss:0.2750 LR:0.0010000000000000002
Training: Epoch[277/300] Iteration[050/782] Loss: 0.0160 Acc:99.56%
Training: Epoch[277/300] Iteration[100/782] Loss: 0.0170 Acc:99.48%
Training: Epoch[277/300] Iteration[150/782] Loss: 0.0171 Acc:99.50%
Training: Epoch[277/300] Iteration[200/782] Loss: 0.0160 Acc:99.55%
Training: Epoch[277/300] Iteration[250/782] Loss: 0.0153 Acc:99.59%
Training: Epoch[277/300] Iteration[300/782] Loss: 0.0149 Acc:99.64%
Training: Epoch[277/300] Iteration[350/782] Loss: 0.0146 Acc:99.65%
Training: Epoch[277/300] Iteration[400/782] Loss: 0.0145 Acc:99.67%
Training: Epoch[277/300] Iteration[450/782] Loss: 0.0147 Acc:99.66%
Training: Epoch[277/300] Iteration[500/782] Loss: 0.0148 Acc:99.66%
Training: Epoch[277/300] Iteration[550/782] Loss: 0.0146 Acc:99.67%
Training: Epoch[277/300] Iteration[600/782] Loss: 0.0146 Acc:99.66%
Training: Epoch[277/300] Iteration[650/782] Loss: 0.0146 Acc:99.65%
Training: Epoch[277/300] Iteration[700/782] Loss: 0.0145 Acc:99.65%
Training: Epoch[277/300] Iteration[750/782] Loss: 0.0145 Acc:99.65%
Epoch[277/300] Train Acc: 99.65% Valid Acc:93.38% Train loss:0.0146 Valid loss:0.2730 LR:0.0010000000000000002
Training: Epoch[278/300] Iteration[050/782] Loss: 0.0159 Acc:99.62%
Training: Epoch[278/300] Iteration[100/782] Loss: 0.0154 Acc:99.62%
Training: Epoch[278/300] Iteration[150/782] Loss: 0.0150 Acc:99.68%
Training: Epoch[278/300] Iteration[200/782] Loss: 0.0142 Acc:99.69%
Training: Epoch[278/300] Iteration[250/782] Loss: 0.0142 Acc:99.68%
Training: Epoch[278/300] Iteration[300/782] Loss: 0.0138 Acc:99.71%
Training: Epoch[278/300] Iteration[350/782] Loss: 0.0134 Acc:99.73%
Training: Epoch[278/300] Iteration[400/782] Loss: 0.0137 Acc:99.71%
Training: Epoch[278/300] Iteration[450/782] Loss: 0.0135 Acc:99.71%
Training: Epoch[278/300] Iteration[500/782] Loss: 0.0136 Acc:99.72%
Training: Epoch[278/300] Iteration[550/782] Loss: 0.0135 Acc:99.71%
Training: Epoch[278/300] Iteration[600/782] Loss: 0.0135 Acc:99.71%
Training: Epoch[278/300] Iteration[650/782] Loss: 0.0137 Acc:99.71%
Training: Epoch[278/300] Iteration[700/782] Loss: 0.0135 Acc:99.72%
Training: Epoch[278/300] Iteration[750/782] Loss: 0.0135 Acc:99.73%
Epoch[278/300] Train Acc: 99.73% Valid Acc:93.39% Train loss:0.0136 Valid loss:0.2744 LR:0.0010000000000000002
Training: Epoch[279/300] Iteration[050/782] Loss: 0.0145 Acc:99.66%
Training: Epoch[279/300] Iteration[100/782] Loss: 0.0140 Acc:99.66%
Training: Epoch[279/300] Iteration[150/782] Loss: 0.0144 Acc:99.67%
Training: Epoch[279/300] Iteration[200/782] Loss: 0.0155 Acc:99.61%
Training: Epoch[279/300] Iteration[250/782] Loss: 0.0158 Acc:99.61%
Training: Epoch[279/300] Iteration[300/782] Loss: 0.0155 Acc:99.61%
Training: Epoch[279/300] Iteration[350/782] Loss: 0.0156 Acc:99.59%
Training: Epoch[279/300] Iteration[400/782] Loss: 0.0152 Acc:99.62%
Training: Epoch[279/300] Iteration[450/782] Loss: 0.0153 Acc:99.61%
Training: Epoch[279/300] Iteration[500/782] Loss: 0.0148 Acc:99.64%
Training: Epoch[279/300] Iteration[550/782] Loss: 0.0147 Acc:99.64%
Training: Epoch[279/300] Iteration[600/782] Loss: 0.0149 Acc:99.64%
Training: Epoch[279/300] Iteration[650/782] Loss: 0.0146 Acc:99.64%
Training: Epoch[279/300] Iteration[700/782] Loss: 0.0147 Acc:99.64%
Training: Epoch[279/300] Iteration[750/782] Loss: 0.0147 Acc:99.64%
Epoch[279/300] Train Acc: 99.64% Valid Acc:93.33% Train loss:0.0149 Valid loss:0.2768 LR:0.0010000000000000002
Training: Epoch[280/300] Iteration[050/782] Loss: 0.0123 Acc:99.66%
Training: Epoch[280/300] Iteration[100/782] Loss: 0.0133 Acc:99.67%
Training: Epoch[280/300] Iteration[150/782] Loss: 0.0134 Acc:99.71%
Training: Epoch[280/300] Iteration[200/782] Loss: 0.0140 Acc:99.69%
Training: Epoch[280/300] Iteration[250/782] Loss: 0.0142 Acc:99.70%
Training: Epoch[280/300] Iteration[300/782] Loss: 0.0145 Acc:99.68%
Training: Epoch[280/300] Iteration[350/782] Loss: 0.0144 Acc:99.67%
Training: Epoch[280/300] Iteration[400/782] Loss: 0.0146 Acc:99.66%
Training: Epoch[280/300] Iteration[450/782] Loss: 0.0143 Acc:99.68%
Training: Epoch[280/300] Iteration[500/782] Loss: 0.0143 Acc:99.67%
Training: Epoch[280/300] Iteration[550/782] Loss: 0.0142 Acc:99.67%
Training: Epoch[280/300] Iteration[600/782] Loss: 0.0142 Acc:99.68%
Training: Epoch[280/300] Iteration[650/782] Loss: 0.0139 Acc:99.69%
Training: Epoch[280/300] Iteration[700/782] Loss: 0.0137 Acc:99.69%
Training: Epoch[280/300] Iteration[750/782] Loss: 0.0136 Acc:99.70%
Epoch[280/300] Train Acc: 99.69% Valid Acc:93.32% Train loss:0.0138 Valid loss:0.2761 LR:0.0010000000000000002
Training: Epoch[281/300] Iteration[050/782] Loss: 0.0121 Acc:99.78%
Training: Epoch[281/300] Iteration[100/782] Loss: 0.0132 Acc:99.69%
Training: Epoch[281/300] Iteration[150/782] Loss: 0.0130 Acc:99.69%
Training: Epoch[281/300] Iteration[200/782] Loss: 0.0131 Acc:99.69%
Training: Epoch[281/300] Iteration[250/782] Loss: 0.0133 Acc:99.69%
Training: Epoch[281/300] Iteration[300/782] Loss: 0.0127 Acc:99.73%
Training: Epoch[281/300] Iteration[350/782] Loss: 0.0127 Acc:99.74%
Training: Epoch[281/300] Iteration[400/782] Loss: 0.0128 Acc:99.74%
Training: Epoch[281/300] Iteration[450/782] Loss: 0.0129 Acc:99.74%
Training: Epoch[281/300] Iteration[500/782] Loss: 0.0133 Acc:99.72%
Training: Epoch[281/300] Iteration[550/782] Loss: 0.0132 Acc:99.72%
Training: Epoch[281/300] Iteration[600/782] Loss: 0.0129 Acc:99.73%
Training: Epoch[281/300] Iteration[650/782] Loss: 0.0129 Acc:99.73%
Training: Epoch[281/300] Iteration[700/782] Loss: 0.0128 Acc:99.73%
Training: Epoch[281/300] Iteration[750/782] Loss: 0.0130 Acc:99.72%
Epoch[281/300] Train Acc: 99.72% Valid Acc:93.29% Train loss:0.0131 Valid loss:0.2775 LR:0.0010000000000000002
Training: Epoch[282/300] Iteration[050/782] Loss: 0.0119 Acc:99.72%
Training: Epoch[282/300] Iteration[100/782] Loss: 0.0111 Acc:99.75%
Training: Epoch[282/300] Iteration[150/782] Loss: 0.0133 Acc:99.70%
Training: Epoch[282/300] Iteration[200/782] Loss: 0.0135 Acc:99.69%
Training: Epoch[282/300] Iteration[250/782] Loss: 0.0135 Acc:99.69%
Training: Epoch[282/300] Iteration[300/782] Loss: 0.0142 Acc:99.67%
Training: Epoch[282/300] Iteration[350/782] Loss: 0.0141 Acc:99.68%
Training: Epoch[282/300] Iteration[400/782] Loss: 0.0142 Acc:99.68%
Training: Epoch[282/300] Iteration[450/782] Loss: 0.0140 Acc:99.69%
Training: Epoch[282/300] Iteration[500/782] Loss: 0.0139 Acc:99.68%
Training: Epoch[282/300] Iteration[550/782] Loss: 0.0138 Acc:99.69%
Training: Epoch[282/300] Iteration[600/782] Loss: 0.0138 Acc:99.69%
Training: Epoch[282/300] Iteration[650/782] Loss: 0.0138 Acc:99.69%
Training: Epoch[282/300] Iteration[700/782] Loss: 0.0137 Acc:99.69%
Training: Epoch[282/300] Iteration[750/782] Loss: 0.0138 Acc:99.69%
Epoch[282/300] Train Acc: 99.70% Valid Acc:93.13% Train loss:0.0137 Valid loss:0.2836 LR:0.0010000000000000002
Training: Epoch[283/300] Iteration[050/782] Loss: 0.0152 Acc:99.56%
Training: Epoch[283/300] Iteration[100/782] Loss: 0.0156 Acc:99.56%
Training: Epoch[283/300] Iteration[150/782] Loss: 0.0166 Acc:99.59%
Training: Epoch[283/300] Iteration[200/782] Loss: 0.0154 Acc:99.63%
Training: Epoch[283/300] Iteration[250/782] Loss: 0.0150 Acc:99.64%
Training: Epoch[283/300] Iteration[300/782] Loss: 0.0147 Acc:99.64%
Training: Epoch[283/300] Iteration[350/782] Loss: 0.0143 Acc:99.66%
Training: Epoch[283/300] Iteration[400/782] Loss: 0.0142 Acc:99.66%
Training: Epoch[283/300] Iteration[450/782] Loss: 0.0144 Acc:99.65%
Training: Epoch[283/300] Iteration[500/782] Loss: 0.0146 Acc:99.64%
Training: Epoch[283/300] Iteration[550/782] Loss: 0.0146 Acc:99.63%
Training: Epoch[283/300] Iteration[600/782] Loss: 0.0145 Acc:99.63%
Training: Epoch[283/300] Iteration[650/782] Loss: 0.0144 Acc:99.64%
Training: Epoch[283/300] Iteration[700/782] Loss: 0.0143 Acc:99.65%
Training: Epoch[283/300] Iteration[750/782] Loss: 0.0143 Acc:99.65%
Epoch[283/300] Train Acc: 99.66% Valid Acc:93.37% Train loss:0.0142 Valid loss:0.2753 LR:0.0010000000000000002
Training: Epoch[284/300] Iteration[050/782] Loss: 0.0157 Acc:99.66%
Training: Epoch[284/300] Iteration[100/782] Loss: 0.0139 Acc:99.70%
Training: Epoch[284/300] Iteration[150/782] Loss: 0.0131 Acc:99.73%
Training: Epoch[284/300] Iteration[200/782] Loss: 0.0138 Acc:99.71%
Training: Epoch[284/300] Iteration[250/782] Loss: 0.0138 Acc:99.69%
Training: Epoch[284/300] Iteration[300/782] Loss: 0.0134 Acc:99.70%
Training: Epoch[284/300] Iteration[350/782] Loss: 0.0135 Acc:99.69%
Training: Epoch[284/300] Iteration[400/782] Loss: 0.0134 Acc:99.70%
Training: Epoch[284/300] Iteration[450/782] Loss: 0.0133 Acc:99.69%
Training: Epoch[284/300] Iteration[500/782] Loss: 0.0133 Acc:99.69%
Training: Epoch[284/300] Iteration[550/782] Loss: 0.0133 Acc:99.68%
Training: Epoch[284/300] Iteration[600/782] Loss: 0.0135 Acc:99.68%
Training: Epoch[284/300] Iteration[650/782] Loss: 0.0134 Acc:99.68%
Training: Epoch[284/300] Iteration[700/782] Loss: 0.0136 Acc:99.67%
Training: Epoch[284/300] Iteration[750/782] Loss: 0.0135 Acc:99.68%
Epoch[284/300] Train Acc: 99.68% Valid Acc:93.37% Train loss:0.0135 Valid loss:0.2756 LR:0.0010000000000000002
Training: Epoch[285/300] Iteration[050/782] Loss: 0.0139 Acc:99.62%
Training: Epoch[285/300] Iteration[100/782] Loss: 0.0128 Acc:99.72%
Training: Epoch[285/300] Iteration[150/782] Loss: 0.0129 Acc:99.71%
Training: Epoch[285/300] Iteration[200/782] Loss: 0.0133 Acc:99.68%
Training: Epoch[285/300] Iteration[250/782] Loss: 0.0131 Acc:99.69%
Training: Epoch[285/300] Iteration[300/782] Loss: 0.0135 Acc:99.64%
Training: Epoch[285/300] Iteration[350/782] Loss: 0.0131 Acc:99.67%
Training: Epoch[285/300] Iteration[400/782] Loss: 0.0135 Acc:99.68%
Training: Epoch[285/300] Iteration[450/782] Loss: 0.0131 Acc:99.70%
Training: Epoch[285/300] Iteration[500/782] Loss: 0.0132 Acc:99.69%
Training: Epoch[285/300] Iteration[550/782] Loss: 0.0132 Acc:99.70%
Training: Epoch[285/300] Iteration[600/782] Loss: 0.0134 Acc:99.69%
Training: Epoch[285/300] Iteration[650/782] Loss: 0.0135 Acc:99.69%
Training: Epoch[285/300] Iteration[700/782] Loss: 0.0136 Acc:99.68%
Training: Epoch[285/300] Iteration[750/782] Loss: 0.0134 Acc:99.69%
Epoch[285/300] Train Acc: 99.69% Valid Acc:93.25% Train loss:0.0135 Valid loss:0.2814 LR:0.0010000000000000002
Training: Epoch[286/300] Iteration[050/782] Loss: 0.0168 Acc:99.62%
Training: Epoch[286/300] Iteration[100/782] Loss: 0.0157 Acc:99.64%
Training: Epoch[286/300] Iteration[150/782] Loss: 0.0145 Acc:99.72%
Training: Epoch[286/300] Iteration[200/782] Loss: 0.0146 Acc:99.72%
Training: Epoch[286/300] Iteration[250/782] Loss: 0.0148 Acc:99.72%
Training: Epoch[286/300] Iteration[300/782] Loss: 0.0144 Acc:99.73%
Training: Epoch[286/300] Iteration[350/782] Loss: 0.0141 Acc:99.73%
Training: Epoch[286/300] Iteration[400/782] Loss: 0.0140 Acc:99.73%
Training: Epoch[286/300] Iteration[450/782] Loss: 0.0139 Acc:99.73%
Training: Epoch[286/300] Iteration[500/782] Loss: 0.0139 Acc:99.72%
Training: Epoch[286/300] Iteration[550/782] Loss: 0.0138 Acc:99.72%
Training: Epoch[286/300] Iteration[600/782] Loss: 0.0139 Acc:99.72%
Training: Epoch[286/300] Iteration[650/782] Loss: 0.0140 Acc:99.71%
Training: Epoch[286/300] Iteration[700/782] Loss: 0.0137 Acc:99.72%
Training: Epoch[286/300] Iteration[750/782] Loss: 0.0138 Acc:99.72%
Epoch[286/300] Train Acc: 99.71% Valid Acc:93.40% Train loss:0.0142 Valid loss:0.2752 LR:0.0010000000000000002
Training: Epoch[287/300] Iteration[050/782] Loss: 0.0132 Acc:99.72%
Training: Epoch[287/300] Iteration[100/782] Loss: 0.0147 Acc:99.64%
Training: Epoch[287/300] Iteration[150/782] Loss: 0.0154 Acc:99.61%
Training: Epoch[287/300] Iteration[200/782] Loss: 0.0153 Acc:99.65%
Training: Epoch[287/300] Iteration[250/782] Loss: 0.0143 Acc:99.69%
Training: Epoch[287/300] Iteration[300/782] Loss: 0.0146 Acc:99.67%
Training: Epoch[287/300] Iteration[350/782] Loss: 0.0151 Acc:99.65%
Training: Epoch[287/300] Iteration[400/782] Loss: 0.0151 Acc:99.64%
Training: Epoch[287/300] Iteration[450/782] Loss: 0.0150 Acc:99.65%
Training: Epoch[287/300] Iteration[500/782] Loss: 0.0150 Acc:99.63%
Training: Epoch[287/300] Iteration[550/782] Loss: 0.0149 Acc:99.64%
Training: Epoch[287/300] Iteration[600/782] Loss: 0.0148 Acc:99.64%
Training: Epoch[287/300] Iteration[650/782] Loss: 0.0147 Acc:99.64%
Training: Epoch[287/300] Iteration[700/782] Loss: 0.0147 Acc:99.64%
Training: Epoch[287/300] Iteration[750/782] Loss: 0.0146 Acc:99.65%
Epoch[287/300] Train Acc: 99.64% Valid Acc:93.35% Train loss:0.0148 Valid loss:0.2846 LR:0.0010000000000000002
Training: Epoch[288/300] Iteration[050/782] Loss: 0.0120 Acc:99.75%
Training: Epoch[288/300] Iteration[100/782] Loss: 0.0120 Acc:99.75%
Training: Epoch[288/300] Iteration[150/782] Loss: 0.0115 Acc:99.77%
Training: Epoch[288/300] Iteration[200/782] Loss: 0.0121 Acc:99.76%
Training: Epoch[288/300] Iteration[250/782] Loss: 0.0132 Acc:99.72%
Training: Epoch[288/300] Iteration[300/782] Loss: 0.0142 Acc:99.69%
Training: Epoch[288/300] Iteration[350/782] Loss: 0.0141 Acc:99.68%
Training: Epoch[288/300] Iteration[400/782] Loss: 0.0141 Acc:99.68%
Training: Epoch[288/300] Iteration[450/782] Loss: 0.0139 Acc:99.70%
Training: Epoch[288/300] Iteration[500/782] Loss: 0.0139 Acc:99.69%
Training: Epoch[288/300] Iteration[550/782] Loss: 0.0139 Acc:99.69%
Training: Epoch[288/300] Iteration[600/782] Loss: 0.0139 Acc:99.69%
Training: Epoch[288/300] Iteration[650/782] Loss: 0.0137 Acc:99.69%
Training: Epoch[288/300] Iteration[700/782] Loss: 0.0137 Acc:99.69%
Training: Epoch[288/300] Iteration[750/782] Loss: 0.0136 Acc:99.69%
Epoch[288/300] Train Acc: 99.69% Valid Acc:93.36% Train loss:0.0137 Valid loss:0.2779 LR:0.0010000000000000002
Training: Epoch[289/300] Iteration[050/782] Loss: 0.0131 Acc:99.75%
Training: Epoch[289/300] Iteration[100/782] Loss: 0.0128 Acc:99.72%
Training: Epoch[289/300] Iteration[150/782] Loss: 0.0126 Acc:99.70%
Training: Epoch[289/300] Iteration[200/782] Loss: 0.0138 Acc:99.67%
Training: Epoch[289/300] Iteration[250/782] Loss: 0.0140 Acc:99.66%
Training: Epoch[289/300] Iteration[300/782] Loss: 0.0137 Acc:99.69%
Training: Epoch[289/300] Iteration[350/782] Loss: 0.0140 Acc:99.67%
Training: Epoch[289/300] Iteration[400/782] Loss: 0.0139 Acc:99.68%
Training: Epoch[289/300] Iteration[450/782] Loss: 0.0140 Acc:99.68%
Training: Epoch[289/300] Iteration[500/782] Loss: 0.0136 Acc:99.70%
Training: Epoch[289/300] Iteration[550/782] Loss: 0.0136 Acc:99.70%
Training: Epoch[289/300] Iteration[600/782] Loss: 0.0135 Acc:99.71%
Training: Epoch[289/300] Iteration[650/782] Loss: 0.0136 Acc:99.70%
Training: Epoch[289/300] Iteration[700/782] Loss: 0.0136 Acc:99.69%
Training: Epoch[289/300] Iteration[750/782] Loss: 0.0135 Acc:99.70%
Epoch[289/300] Train Acc: 99.70% Valid Acc:93.16% Train loss:0.0135 Valid loss:0.2781 LR:0.0010000000000000002
Training: Epoch[290/300] Iteration[050/782] Loss: 0.0156 Acc:99.69%
Training: Epoch[290/300] Iteration[100/782] Loss: 0.0151 Acc:99.69%
Training: Epoch[290/300] Iteration[150/782] Loss: 0.0138 Acc:99.74%
Training: Epoch[290/300] Iteration[200/782] Loss: 0.0141 Acc:99.70%
Training: Epoch[290/300] Iteration[250/782] Loss: 0.0139 Acc:99.71%
Training: Epoch[290/300] Iteration[300/782] Loss: 0.0139 Acc:99.71%
Training: Epoch[290/300] Iteration[350/782] Loss: 0.0135 Acc:99.72%
Training: Epoch[290/300] Iteration[400/782] Loss: 0.0133 Acc:99.73%
Training: Epoch[290/300] Iteration[450/782] Loss: 0.0135 Acc:99.70%
Training: Epoch[290/300] Iteration[500/782] Loss: 0.0135 Acc:99.70%
Training: Epoch[290/300] Iteration[550/782] Loss: 0.0136 Acc:99.70%
Training: Epoch[290/300] Iteration[600/782] Loss: 0.0135 Acc:99.70%
Training: Epoch[290/300] Iteration[650/782] Loss: 0.0135 Acc:99.69%
Training: Epoch[290/300] Iteration[700/782] Loss: 0.0134 Acc:99.70%
Training: Epoch[290/300] Iteration[750/782] Loss: 0.0134 Acc:99.70%
Epoch[290/300] Train Acc: 99.69% Valid Acc:93.33% Train loss:0.0134 Valid loss:0.2794 LR:0.0010000000000000002
Training: Epoch[291/300] Iteration[050/782] Loss: 0.0127 Acc:99.66%
Training: Epoch[291/300] Iteration[100/782] Loss: 0.0127 Acc:99.69%
Training: Epoch[291/300] Iteration[150/782] Loss: 0.0116 Acc:99.76%
Training: Epoch[291/300] Iteration[200/782] Loss: 0.0114 Acc:99.77%
Training: Epoch[291/300] Iteration[250/782] Loss: 0.0119 Acc:99.76%
Training: Epoch[291/300] Iteration[300/782] Loss: 0.0118 Acc:99.75%
Training: Epoch[291/300] Iteration[350/782] Loss: 0.0122 Acc:99.72%
Training: Epoch[291/300] Iteration[400/782] Loss: 0.0125 Acc:99.72%
Training: Epoch[291/300] Iteration[450/782] Loss: 0.0127 Acc:99.71%
Training: Epoch[291/300] Iteration[500/782] Loss: 0.0125 Acc:99.70%
Training: Epoch[291/300] Iteration[550/782] Loss: 0.0126 Acc:99.69%
Training: Epoch[291/300] Iteration[600/782] Loss: 0.0123 Acc:99.71%
Training: Epoch[291/300] Iteration[650/782] Loss: 0.0122 Acc:99.71%
Training: Epoch[291/300] Iteration[700/782] Loss: 0.0124 Acc:99.71%
Training: Epoch[291/300] Iteration[750/782] Loss: 0.0124 Acc:99.71%
Epoch[291/300] Train Acc: 99.71% Valid Acc:93.43% Train loss:0.0124 Valid loss:0.2746 LR:0.0010000000000000002
Training: Epoch[292/300] Iteration[050/782] Loss: 0.0110 Acc:99.75%
Training: Epoch[292/300] Iteration[100/782] Loss: 0.0124 Acc:99.72%
Training: Epoch[292/300] Iteration[150/782] Loss: 0.0129 Acc:99.68%
Training: Epoch[292/300] Iteration[200/782] Loss: 0.0130 Acc:99.68%
Training: Epoch[292/300] Iteration[250/782] Loss: 0.0126 Acc:99.70%
Training: Epoch[292/300] Iteration[300/782] Loss: 0.0126 Acc:99.69%
Training: Epoch[292/300] Iteration[350/782] Loss: 0.0126 Acc:99.68%
Training: Epoch[292/300] Iteration[400/782] Loss: 0.0126 Acc:99.69%
Training: Epoch[292/300] Iteration[450/782] Loss: 0.0126 Acc:99.70%
Training: Epoch[292/300] Iteration[500/782] Loss: 0.0129 Acc:99.68%
Training: Epoch[292/300] Iteration[550/782] Loss: 0.0128 Acc:99.69%
Training: Epoch[292/300] Iteration[600/782] Loss: 0.0130 Acc:99.68%
Training: Epoch[292/300] Iteration[650/782] Loss: 0.0131 Acc:99.68%
Training: Epoch[292/300] Iteration[700/782] Loss: 0.0129 Acc:99.69%
Training: Epoch[292/300] Iteration[750/782] Loss: 0.0129 Acc:99.69%
Epoch[292/300] Train Acc: 99.70% Valid Acc:93.38% Train loss:0.0129 Valid loss:0.2727 LR:0.0010000000000000002
Training: Epoch[293/300] Iteration[050/782] Loss: 0.0095 Acc:99.88%
Training: Epoch[293/300] Iteration[100/782] Loss: 0.0122 Acc:99.78%
Training: Epoch[293/300] Iteration[150/782] Loss: 0.0123 Acc:99.75%
Training: Epoch[293/300] Iteration[200/782] Loss: 0.0128 Acc:99.75%
Training: Epoch[293/300] Iteration[250/782] Loss: 0.0124 Acc:99.76%
Training: Epoch[293/300] Iteration[300/782] Loss: 0.0123 Acc:99.76%
Training: Epoch[293/300] Iteration[350/782] Loss: 0.0124 Acc:99.75%
Training: Epoch[293/300] Iteration[400/782] Loss: 0.0125 Acc:99.74%
Training: Epoch[293/300] Iteration[450/782] Loss: 0.0124 Acc:99.74%
Training: Epoch[293/300] Iteration[500/782] Loss: 0.0127 Acc:99.73%
Training: Epoch[293/300] Iteration[550/782] Loss: 0.0129 Acc:99.72%
Training: Epoch[293/300] Iteration[600/782] Loss: 0.0131 Acc:99.70%
Training: Epoch[293/300] Iteration[650/782] Loss: 0.0129 Acc:99.71%
Training: Epoch[293/300] Iteration[700/782] Loss: 0.0130 Acc:99.71%
Training: Epoch[293/300] Iteration[750/782] Loss: 0.0130 Acc:99.71%
Epoch[293/300] Train Acc: 99.71% Valid Acc:93.36% Train loss:0.0131 Valid loss:0.2725 LR:0.0010000000000000002
Training: Epoch[294/300] Iteration[050/782] Loss: 0.0136 Acc:99.66%
Training: Epoch[294/300] Iteration[100/782] Loss: 0.0127 Acc:99.69%
Training: Epoch[294/300] Iteration[150/782] Loss: 0.0120 Acc:99.74%
Training: Epoch[294/300] Iteration[200/782] Loss: 0.0117 Acc:99.73%
Training: Epoch[294/300] Iteration[250/782] Loss: 0.0122 Acc:99.69%
Training: Epoch[294/300] Iteration[300/782] Loss: 0.0128 Acc:99.67%
Training: Epoch[294/300] Iteration[350/782] Loss: 0.0127 Acc:99.67%
Training: Epoch[294/300] Iteration[400/782] Loss: 0.0127 Acc:99.68%
Training: Epoch[294/300] Iteration[450/782] Loss: 0.0131 Acc:99.67%
Training: Epoch[294/300] Iteration[500/782] Loss: 0.0132 Acc:99.66%
Training: Epoch[294/300] Iteration[550/782] Loss: 0.0135 Acc:99.65%
Training: Epoch[294/300] Iteration[600/782] Loss: 0.0134 Acc:99.66%
Training: Epoch[294/300] Iteration[650/782] Loss: 0.0133 Acc:99.67%
Training: Epoch[294/300] Iteration[700/782] Loss: 0.0131 Acc:99.68%
Training: Epoch[294/300] Iteration[750/782] Loss: 0.0132 Acc:99.67%
Epoch[294/300] Train Acc: 99.68% Valid Acc:93.27% Train loss:0.0133 Valid loss:0.2795 LR:0.0010000000000000002
Training: Epoch[295/300] Iteration[050/782] Loss: 0.0163 Acc:99.69%
Training: Epoch[295/300] Iteration[100/782] Loss: 0.0139 Acc:99.73%
Training: Epoch[295/300] Iteration[150/782] Loss: 0.0129 Acc:99.75%
Training: Epoch[295/300] Iteration[200/782] Loss: 0.0131 Acc:99.73%
Training: Epoch[295/300] Iteration[250/782] Loss: 0.0134 Acc:99.72%
Training: Epoch[295/300] Iteration[300/782] Loss: 0.0133 Acc:99.72%
Training: Epoch[295/300] Iteration[350/782] Loss: 0.0131 Acc:99.72%
Training: Epoch[295/300] Iteration[400/782] Loss: 0.0133 Acc:99.73%
Training: Epoch[295/300] Iteration[450/782] Loss: 0.0134 Acc:99.71%
Training: Epoch[295/300] Iteration[500/782] Loss: 0.0134 Acc:99.71%
Training: Epoch[295/300] Iteration[550/782] Loss: 0.0130 Acc:99.72%
Training: Epoch[295/300] Iteration[600/782] Loss: 0.0130 Acc:99.72%
Training: Epoch[295/300] Iteration[650/782] Loss: 0.0132 Acc:99.71%
Training: Epoch[295/300] Iteration[700/782] Loss: 0.0132 Acc:99.71%
Training: Epoch[295/300] Iteration[750/782] Loss: 0.0133 Acc:99.71%
Epoch[295/300] Train Acc: 99.71% Valid Acc:93.33% Train loss:0.0133 Valid loss:0.2785 LR:0.0010000000000000002
Training: Epoch[296/300] Iteration[050/782] Loss: 0.0151 Acc:99.69%
Training: Epoch[296/300] Iteration[100/782] Loss: 0.0129 Acc:99.75%
Training: Epoch[296/300] Iteration[150/782] Loss: 0.0123 Acc:99.76%
Training: Epoch[296/300] Iteration[200/782] Loss: 0.0124 Acc:99.73%
Training: Epoch[296/300] Iteration[250/782] Loss: 0.0126 Acc:99.71%
Training: Epoch[296/300] Iteration[300/782] Loss: 0.0125 Acc:99.71%
Training: Epoch[296/300] Iteration[350/782] Loss: 0.0123 Acc:99.73%
Training: Epoch[296/300] Iteration[400/782] Loss: 0.0120 Acc:99.75%
Training: Epoch[296/300] Iteration[450/782] Loss: 0.0121 Acc:99.74%
Training: Epoch[296/300] Iteration[500/782] Loss: 0.0122 Acc:99.73%
Training: Epoch[296/300] Iteration[550/782] Loss: 0.0123 Acc:99.74%
Training: Epoch[296/300] Iteration[600/782] Loss: 0.0122 Acc:99.74%
Training: Epoch[296/300] Iteration[650/782] Loss: 0.0124 Acc:99.73%
Training: Epoch[296/300] Iteration[700/782] Loss: 0.0127 Acc:99.72%
Training: Epoch[296/300] Iteration[750/782] Loss: 0.0128 Acc:99.71%
Epoch[296/300] Train Acc: 99.71% Valid Acc:93.45% Train loss:0.0129 Valid loss:0.2795 LR:0.0010000000000000002
Training: Epoch[297/300] Iteration[050/782] Loss: 0.0121 Acc:99.75%
Training: Epoch[297/300] Iteration[100/782] Loss: 0.0127 Acc:99.72%
Training: Epoch[297/300] Iteration[150/782] Loss: 0.0124 Acc:99.73%
Training: Epoch[297/300] Iteration[200/782] Loss: 0.0121 Acc:99.75%
Training: Epoch[297/300] Iteration[250/782] Loss: 0.0120 Acc:99.76%
Training: Epoch[297/300] Iteration[300/782] Loss: 0.0116 Acc:99.78%
Training: Epoch[297/300] Iteration[350/782] Loss: 0.0121 Acc:99.76%
Training: Epoch[297/300] Iteration[400/782] Loss: 0.0124 Acc:99.74%
Training: Epoch[297/300] Iteration[450/782] Loss: 0.0123 Acc:99.73%
Training: Epoch[297/300] Iteration[500/782] Loss: 0.0120 Acc:99.74%
Training: Epoch[297/300] Iteration[550/782] Loss: 0.0120 Acc:99.74%
Training: Epoch[297/300] Iteration[600/782] Loss: 0.0123 Acc:99.74%
Training: Epoch[297/300] Iteration[650/782] Loss: 0.0121 Acc:99.75%
Training: Epoch[297/300] Iteration[700/782] Loss: 0.0122 Acc:99.75%
Training: Epoch[297/300] Iteration[750/782] Loss: 0.0123 Acc:99.74%
Epoch[297/300] Train Acc: 99.73% Valid Acc:93.45% Train loss:0.0125 Valid loss:0.2764 LR:0.0010000000000000002
Training: Epoch[298/300] Iteration[050/782] Loss: 0.0152 Acc:99.50%
Training: Epoch[298/300] Iteration[100/782] Loss: 0.0137 Acc:99.61%
Training: Epoch[298/300] Iteration[150/782] Loss: 0.0137 Acc:99.64%
Training: Epoch[298/300] Iteration[200/782] Loss: 0.0137 Acc:99.63%
Training: Epoch[298/300] Iteration[250/782] Loss: 0.0142 Acc:99.63%
Training: Epoch[298/300] Iteration[300/782] Loss: 0.0137 Acc:99.65%
Training: Epoch[298/300] Iteration[350/782] Loss: 0.0137 Acc:99.66%
Training: Epoch[298/300] Iteration[400/782] Loss: 0.0138 Acc:99.66%
Training: Epoch[298/300] Iteration[450/782] Loss: 0.0133 Acc:99.67%
Training: Epoch[298/300] Iteration[500/782] Loss: 0.0133 Acc:99.67%
Training: Epoch[298/300] Iteration[550/782] Loss: 0.0132 Acc:99.68%
Training: Epoch[298/300] Iteration[600/782] Loss: 0.0132 Acc:99.67%
Training: Epoch[298/300] Iteration[650/782] Loss: 0.0135 Acc:99.67%
Training: Epoch[298/300] Iteration[700/782] Loss: 0.0133 Acc:99.67%
Training: Epoch[298/300] Iteration[750/782] Loss: 0.0132 Acc:99.68%
Epoch[298/300] Train Acc: 99.67% Valid Acc:93.37% Train loss:0.0133 Valid loss:0.2778 LR:0.0010000000000000002
Training: Epoch[299/300] Iteration[050/782] Loss: 0.0132 Acc:99.66%
Training: Epoch[299/300] Iteration[100/782] Loss: 0.0128 Acc:99.69%
Training: Epoch[299/300] Iteration[150/782] Loss: 0.0120 Acc:99.74%
Training: Epoch[299/300] Iteration[200/782] Loss: 0.0124 Acc:99.70%
Training: Epoch[299/300] Iteration[250/782] Loss: 0.0127 Acc:99.67%
Training: Epoch[299/300] Iteration[300/782] Loss: 0.0129 Acc:99.66%
Training: Epoch[299/300] Iteration[350/782] Loss: 0.0128 Acc:99.66%
Training: Epoch[299/300] Iteration[400/782] Loss: 0.0126 Acc:99.68%
Training: Epoch[299/300] Iteration[450/782] Loss: 0.0126 Acc:99.69%
Training: Epoch[299/300] Iteration[500/782] Loss: 0.0125 Acc:99.69%
Training: Epoch[299/300] Iteration[550/782] Loss: 0.0127 Acc:99.70%
Training: Epoch[299/300] Iteration[600/782] Loss: 0.0128 Acc:99.69%
Training: Epoch[299/300] Iteration[650/782] Loss: 0.0129 Acc:99.69%
Training: Epoch[299/300] Iteration[700/782] Loss: 0.0128 Acc:99.69%
Training: Epoch[299/300] Iteration[750/782] Loss: 0.0126 Acc:99.70%
Epoch[299/300] Train Acc: 99.71% Valid Acc:93.50% Train loss:0.0125 Valid loss:0.2737 LR:0.0010000000000000002
Training: Epoch[300/300] Iteration[050/782] Loss: 0.0106 Acc:99.75%
Training: Epoch[300/300] Iteration[100/782] Loss: 0.0119 Acc:99.75%
Training: Epoch[300/300] Iteration[150/782] Loss: 0.0116 Acc:99.75%
Training: Epoch[300/300] Iteration[200/782] Loss: 0.0118 Acc:99.73%
Training: Epoch[300/300] Iteration[250/782] Loss: 0.0121 Acc:99.71%
Training: Epoch[300/300] Iteration[300/782] Loss: 0.0122 Acc:99.71%
Training: Epoch[300/300] Iteration[350/782] Loss: 0.0125 Acc:99.70%
Training: Epoch[300/300] Iteration[400/782] Loss: 0.0125 Acc:99.70%
Training: Epoch[300/300] Iteration[450/782] Loss: 0.0125 Acc:99.70%
Training: Epoch[300/300] Iteration[500/782] Loss: 0.0125 Acc:99.71%
Training: Epoch[300/300] Iteration[550/782] Loss: 0.0126 Acc:99.70%
Training: Epoch[300/300] Iteration[600/782] Loss: 0.0124 Acc:99.71%
Training: Epoch[300/300] Iteration[650/782] Loss: 0.0124 Acc:99.72%
Training: Epoch[300/300] Iteration[700/782] Loss: 0.0125 Acc:99.71%
Training: Epoch[300/300] Iteration[750/782] Loss: 0.0125 Acc:99.71%
Epoch[300/300] Train Acc: 99.71% Valid Acc:93.61% Train loss:0.0125 Valid loss:0.2816 LR:0.0010000000000000002
class:plane     , total num:5000.0, correct num:4988.0  Recall: 99.76% Precision: 99.68%
class:car       , total num:5000.0, correct num:4988.0  Recall: 99.76% Precision: 99.88%
class:bird      , total num:5000.0, correct num:4985.0  Recall: 99.70% Precision: 99.72%
class:cat       , total num:5000.0, correct num:4981.0  Recall: 99.62% Precision: 99.52%
class:deer      , total num:5000.0, correct num:4981.0  Recall: 99.62% Precision: 99.68%
class:dog       , total num:5000.0, correct num:4981.0  Recall: 99.62% Precision: 99.72%
class:frog      , total num:5000.0, correct num:4991.0  Recall: 99.82% Precision: 99.78%
class:horse     , total num:5000.0, correct num:4979.0  Recall: 99.58% Precision: 99.62%
class:ship      , total num:5000.0, correct num:4990.0  Recall: 99.80% Precision: 99.82%
class:truck     , total num:5000.0, correct num:4990.0  Recall: 99.80% Precision: 99.66%
class:plane     , total num:1000.0, correct num:955.0  Recall: 95.49% Precision: 91.91%
class:car       , total num:1000.0, correct num:962.0  Recall: 96.19% Precision: 97.85%
class:bird      , total num:1000.0, correct num:926.0  Recall: 92.59% Precision: 92.50%
class:cat       , total num:1000.0, correct num:848.0  Recall: 84.79% Precision: 88.42%
class:deer      , total num:1000.0, correct num:937.0  Recall: 93.69% Precision: 93.50%
class:dog       , total num:1000.0, correct num:903.0  Recall: 90.29% Precision: 88.43%
class:frog      , total num:1000.0, correct num:959.0  Recall: 95.89% Precision: 94.85%
class:horse     , total num:1000.0, correct num:948.0  Recall: 94.79% Precision: 96.82%
class:ship      , total num:1000.0, correct num:953.0  Recall: 95.29% Precision: 96.35%
class:truck     , total num:1000.0, correct num:970.0  Recall: 96.99% Precision: 95.46%
 done ~~~~ 07-31_16-59, best acc: 0.9361 in :299 epochs. 
07-31_16-59

Process finished with exit code 0
